{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ5PsT47T2fE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, precision_score, accuracy_score, f1_score, recall_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqBKJpCNT3m-",
        "outputId": "f1e934fa-4338-484a-80f8-41127fadc434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igi0Pc6ET-1R"
      },
      "source": [
        "Reading Padel Data :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGTR3XM2T9fe"
      },
      "outputs": [],
      "source": [
        "bitter_train_P = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Padel/Cleaned Dataset/bitterTrainCleaned.csv\")\n",
        "bitter_test_P = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Padel/Cleaned Dataset/bitterTestCleaned.csv\")\n",
        "sweet_train_P = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Padel/Cleaned Dataset/sweet_train_clean.csv\")\n",
        "sweet_test_P = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Padel/Cleaned Dataset/sweet_test_clean.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Bx79CdN64bn"
      },
      "source": [
        "Reading Mordred Data :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvkX4VzQ64bo"
      },
      "outputs": [],
      "source": [
        "bitter_train_M = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Mordred/Cleaned Data/bitter_train_v5.csv\")\n",
        "bitter_test_M = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Mordred/Cleaned Data/bitter_test_v5.csv\")\n",
        "sweet_train_M = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Mordred/Cleaned Data/sweet_train_v5.csv\")\n",
        "sweet_test_M = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Mordred/Cleaned Data/sweet_test_v5.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkEBpP_4tivD"
      },
      "source": [
        "Script :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeMEAuA9rrO-"
      },
      "outputs": [],
      "source": [
        "def findPredictions(x_Train, x_Test, y_Train, y_Test, data_type):\n",
        "\n",
        "  #Preparing data for PCA\n",
        "  pca2 = PCA(n_components=2)\n",
        "  x_pca2_data_train = pca2.fit_transform(x_Train)\n",
        "  x_pca2_data_test = pca2.fit_transform(x_Test)\n",
        "\n",
        "  pca10 = PCA(n_components=10)\n",
        "  x_pca10_data_train = pca10.fit_transform(x_Train)\n",
        "  x_pca10_data_test = pca10.fit_transform(x_Test)\n",
        "\n",
        "  \n",
        "  \n",
        "  #Preparing data for Correlation matrix on features\n",
        "  train_data = pd.concat([x_Train,y_Train],axis=1)\n",
        "  test_data = pd.concat([x_Test,y_Test],axis=1)\n",
        "  train_corr , test_corr = correlation_check(train_data, test_data,0.7)\n",
        "\n",
        "  if(data_type == 'Sweet'):\n",
        "    x_Train_corr = train_corr.drop(['Sweet'],axis=1)\n",
        "    x_Test_corr = test_corr.drop(['Sweet'],axis=1)\n",
        "\n",
        "  if(data_type == 'Bitter'):\n",
        "    x_Train_corr = train_corr.drop(['Bitter'],axis=1)\n",
        "    x_Test_corr = test_corr.drop(['Bitter'],axis=1)\n",
        "\n",
        "  \n",
        "  \n",
        "  #Preparing data for Correlation matrix on features and Labels\n",
        "\n",
        "  a = x_Train_corr.corr(method ='pearson').abs()\n",
        "  df_temp = a.head(1)\n",
        "  df_temp.fillna(0,inplace = True)\n",
        "\n",
        "  colList = []\n",
        "  for i in df_temp.columns:\n",
        "    if(df_temp[i].item() < 0.1):\n",
        "      colList.append(i)\n",
        "\n",
        "  for i in colList:\n",
        "    new_x_train_corr = x_Train_corr.drop(i,axis = 1)\n",
        "\n",
        "  for i in colList:\n",
        "    new_x_test_corr = x_Test_corr.drop(i,axis = 1)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #Preparing data for selectkBest\n",
        "  from sklearn.feature_selection import SelectKBest, f_classif\n",
        "  \n",
        "  X_new = SelectKBest(f_classif, k=200).fit(x_Train, y_Train)\n",
        "  cols = X_new.get_support(indices=True)\n",
        "  features_df_new_train = x_Train.iloc[:,cols]\n",
        "  features_df_new_test = x_Test.iloc[:,cols]\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  #Applying Models : \n",
        "  #---------------------\n",
        "\n",
        "  #1. Logistic Regression :\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "  clfLR1 = LogisticRegression(random_state=0)\n",
        "  \n",
        "  print(\"Logistic Regression : \")\n",
        "  print(\"------------------------\")\n",
        "  print()\n",
        "\n",
        "  \n",
        "  clfLR_Basic = clfLR1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfLR_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic),\" Recall: \",recall_score(y_Test, y_pred_Basic),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  clfLR2 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLRpca2 = clfLR2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfLRpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2),\" Recall: \",recall_score(y_Test, y_predPca2),\"  F1: \",f1_score(y_Test, y_predPca2, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  clfLR3 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLRpca10 = clfLR3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfLRpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10),\" Recall: \",recall_score(y_Test, y_predPca10),\"  F1: \",f1_score(y_Test, y_predPca10, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "  clfLR4 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_CMF = clfLR4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfLR_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF),\" Recall: \",recall_score(y_Test, y_pred_CMF),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  clfLR5 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_CMFL = clfLR5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfLR_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL),\" Recall: \",recall_score(y_Test, y_pred_CMFL),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "  clfLR6 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_selectK = clfLR6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfLR_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK),\" Recall: \",recall_score(y_Test, y_pred_selectK),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "  #=====================================================================================================================================================\n",
        "\n",
        "  #2. Random forgest :\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "  clfRF1 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=10, criterion='entropy', random_state=30)\n",
        "  \n",
        "  print(\"Random Forest : \")\n",
        "  print(\"----------------\")\n",
        "  print()\n",
        "\n",
        "  clfRF_Basic = clfRF1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfRF_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic),\" Recall: \",recall_score(y_Test, y_pred_Basic),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  clfRF2 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=10, criterion='entropy', random_state=30)\n",
        "\n",
        "\n",
        "  clfRFpca2 = clfRF2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfRFpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2),\" Recall: \",recall_score(y_Test, y_predPca2),\"  F1: \",f1_score(y_Test, y_predPca2, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  clfRF3 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=10, criterion='entropy', random_state=30)\n",
        "\n",
        "\n",
        "  clfRFpca10 = clfRF3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfRFpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10),\" Recall: \",recall_score(y_Test, y_predPca10),\"  F1: \",f1_score(y_Test, y_predPca10, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "  clfRF4 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=10, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfRF_CMF = clfRF4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfRF_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF),\" Recall: \",recall_score(y_Test, y_pred_CMF),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  clfRF5 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=10, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfLR_CMFL = clfRF5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfLR_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL),\" Recall: \",recall_score(y_Test, y_pred_CMFL),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "\n",
        "  clfRF6 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=10, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfRF_selectK = clfRF6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfRF_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK),\" Recall: \",recall_score(y_Test, y_pred_selectK),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #3. Adaboost\n",
        "  from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "  clfAB1 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  print(\"AdaBoost : \")\n",
        "  print(\"----------------\")\n",
        "  print()\n",
        "\n",
        "  clfAB_Basic = clfAB1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfAB_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic),\" Recall: \",recall_score(y_Test, y_pred_Basic),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  clfAB2 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfABpca2 = clfAB2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfABpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2),\" Recall: \",recall_score(y_Test, y_predPca2),\"  F1: \",f1_score(y_Test, y_predPca2, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  clfAB3 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfABpca10 = clfAB3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfABpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10),\" Recall: \",recall_score(y_Test, y_predPca10),\"  F1: \",f1_score(y_Test, y_predPca10, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "  clfAB4 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfAB_CMF = clfAB4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfAB_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF),\" Recall: \",recall_score(y_Test, y_pred_CMF),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  clfAB5 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfAB_CMFL = clfAB5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfAB_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL),\" Recall: \",recall_score(y_Test, y_pred_CMFL),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "  clfAB6 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "\n",
        "  clfAB_selectK = clfAB6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfAB_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK),\" Recall: \",recall_score(y_Test, y_pred_selectK),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "\n",
        "  \n",
        "  #4. XGBoostClassifier\n",
        "  import xgboost as xg\n",
        "\n",
        "  xgb_r1 = xg.XGBClassifier(max_depth=10)\n",
        "\n",
        "  print(\"XGBoostClassifier : \")\n",
        "  print(\"----------------\")\n",
        "  print()\n",
        "\n",
        "  clfXGB_Basic = xgb_r1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfXGB_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic),\" Recall: \",recall_score(y_Test, y_pred_Basic),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  xgb_r2 = xg.XGBClassifier(max_depth=10)\n",
        "\n",
        "  clfXGBpca2 = xgb_r2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfXGBpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2),\" Recall: \",recall_score(y_Test, y_predPca2),\"  F1: \",f1_score(y_Test, y_predPca2, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  xgb_r3 = xg.XGBClassifier(max_depth=10)\n",
        "\n",
        "\n",
        "  clfXGBpca10 = xgb_r3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfXGBpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10),\" Recall: \",recall_score(y_Test, y_predPca10),\"  F1: \",f1_score(y_Test, y_predPca10, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "  xgb_r4 = xg.XGBClassifier(max_depth=10)\n",
        "\n",
        "  clfXGB_CMF = xgb_r4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfXGB_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF),\" Recall: \",recall_score(y_Test, y_pred_CMF),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  xgb_r5 = xg.XGBClassifier(max_depth=10)\n",
        "\n",
        "  clfXGB_CMFL = xgb_r5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfXGB_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL),\" Recall: \",recall_score(y_Test, y_pred_CMFL),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "  xgb_r6 = xg.XGBClassifier(max_depth=10)\n",
        "\n",
        "  clfXGB_selectK = xgb_r6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfXGB_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK),\" Recall: \",recall_score(y_Test, y_pred_selectK),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='binary'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUu7_7CLximQ"
      },
      "source": [
        "Supporting Functions :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sqUZ5T_B7PS"
      },
      "outputs": [],
      "source": [
        "def correlation_check(traindata,testdata,thresh): # drop columns above certain threshold    \n",
        "        corr_matrix = traindata.corr()\n",
        "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "        to_drop = [column for column in upper.columns if any(upper[column] >thresh)]\n",
        "        trainset=traindata.drop(traindata[to_drop], axis=1)\n",
        "        testset=testdata.drop(testdata[to_drop],axis=1)\n",
        "        return trainset,testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKCtozYrtlpk"
      },
      "outputs": [],
      "source": [
        "def gridSearchOnLogReg(x, y):\n",
        "  grid={\n",
        "        \"C\":np.logspace(-3,3,7,1,0),\n",
        "        \"penalty\":[\"l1\",\"l2\",\"elasticnet\",\"none\"],\n",
        "        \"max_iter\":[50,80,100],\n",
        "        \"solver\":[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
        "        }\n",
        "  logreg=LogisticRegression()\n",
        "  logreg_cv=GridSearchCV(logreg,grid)\n",
        "  logreg_cv.fit(x,y)\n",
        "  return logreg_cv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hpxE-W7EbUC"
      },
      "source": [
        "RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=8, criterion='entropy', random_state=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWfYS61cAQX1"
      },
      "source": [
        "## **Padel :**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq8gERy6KUgv"
      },
      "source": [
        "Sweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6IDMWsD1l3Q"
      },
      "outputs": [],
      "source": [
        "y_train = sweet_train_P['Sweet']\n",
        "x_train = sweet_train_P.drop(['Sweet','Name','Name.1','Taste','Unnamed: 0'],axis=1)\n",
        "y_train.replace({True:1, False:0},inplace=True)\n",
        "y_test = sweet_test_P['Sweet']\n",
        "x_test = sweet_test_P.drop(['Sweet','Name','Name.1','Taste','Unnamed: 0'],axis=1)\n",
        "y_test.replace({True:1, False:0},inplace=True)\n",
        "y_train = y_train.to_frame()\n",
        "y_test = y_test.to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swnDAKdXBgob",
        "outputId": "73266a9e-25d7-49c3-fa78-a465f3920f53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression : \n",
            "------------------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8382352941176471  Recall:  0.5277777777777778   F1:  0.6477272727272728  Accuracy:  0.6149068322981367\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.6883116883116883  Recall:  0.9814814814814815   F1:  0.8091603053435115  Accuracy:  0.6894409937888198\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.6594202898550725  Recall:  0.8425925925925926   F1:  0.7398373983739838  Accuracy:  0.6024844720496895\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.7363636363636363  Recall:  0.75   F1:  0.7431192660550459  Accuracy:  0.6521739130434783\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.7297297297297297  Recall:  0.75   F1:  0.7397260273972601  Accuracy:  0.6459627329192547\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.92  Recall:  0.6388888888888888   F1:  0.7540983606557377  Accuracy:  0.7204968944099379\n",
            "\n",
            "Random Forest : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.896551724137931  Recall:  0.7222222222222222   F1:  0.7999999999999999  Accuracy:  0.7577639751552795\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.5  Recall:  0.009259259259259259   F1:  0.01818181818181818  Accuracy:  0.32919254658385094\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.6071428571428571  Recall:  0.3148148148148148   F1:  0.41463414634146345  Accuracy:  0.40372670807453415\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.9012345679012346  Recall:  0.6759259259259259   F1:  0.7724867724867724  Accuracy:  0.7329192546583851\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.9210526315789473  Recall:  0.6481481481481481   F1:  0.7608695652173912  Accuracy:  0.7267080745341615\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.9166666666666666  Recall:  0.7129629629629629   F1:  0.8020833333333334  Accuracy:  0.7639751552795031\n",
            "\n",
            "AdaBoost : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8681318681318682  Recall:  0.7314814814814815   F1:  0.7939698492462313  Accuracy:  0.7453416149068323\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.3333333333333333  Recall:  0.009259259259259259   F1:  0.018018018018018018  Accuracy:  0.32298136645962733\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.5645161290322581  Recall:  0.32407407407407407   F1:  0.4117647058823529  Accuracy:  0.37888198757763975\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8617021276595744  Recall:  0.75   F1:  0.8019801980198019  Accuracy:  0.7515527950310559\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.8617021276595744  Recall:  0.75   F1:  0.8019801980198019  Accuracy:  0.7515527950310559\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.8315789473684211  Recall:  0.7314814814814815   F1:  0.7783251231527094  Accuracy:  0.7204968944099379\n",
            "\n",
            "XGBoostClassifier : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8913043478260869  Recall:  0.7592592592592593   F1:  0.8200000000000001  Accuracy:  0.7763975155279503\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.5  Recall:  0.009259259259259259   F1:  0.01818181818181818  Accuracy:  0.32919254658385094\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.6410256410256411  Recall:  0.46296296296296297   F1:  0.5376344086021506  Accuracy:  0.4658385093167702\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8924731182795699  Recall:  0.7685185185185185   F1:  0.8258706467661692  Accuracy:  0.782608695652174\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.9010989010989011  Recall:  0.7592592592592593   F1:  0.8241206030150754  Accuracy:  0.782608695652174\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.8913043478260869  Recall:  0.7592592592592593   F1:  0.8200000000000001  Accuracy:  0.7763975155279503\n",
            "\n"
          ]
        }
      ],
      "source": [
        "findPredictions(x_train, x_test, y_train, y_test, \"Sweet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWDLrrpAKm1J"
      },
      "source": [
        "Bitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTEckM0QKm1J"
      },
      "outputs": [],
      "source": [
        "y_train = bitter_train_P['Bitter']\n",
        "x_train = bitter_train_P.drop(['Bitter','Name','Name.1','Taste'],axis=1)\n",
        "y_train.replace({True:1, False:0},inplace=True)\n",
        "y_test = bitter_test_P['Bitter']\n",
        "x_test = bitter_test_P.drop(['Bitter','Name','Name.1','Taste'],axis=1)\n",
        "y_test.replace({True:1, False:0},inplace=True)\n",
        "y_train = y_train.to_frame()\n",
        "y_test = y_test.to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDvdqdS6Km1K",
        "outputId": "fd2e8856-f30a-4730-d030-5146190dc6de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression : \n",
            "------------------------\n",
            "\n",
            "Basic ==>                          Precision:  0.7407407407407407  Recall:  0.5714285714285714   F1:  0.6451612903225806  Accuracy:  0.6140350877192983\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.14285714285714285  Recall:  0.009523809523809525   F1:  0.01785714285714286  Accuracy:  0.3567251461988304\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.375  Recall:  0.05714285714285714   F1:  0.09917355371900827  Accuracy:  0.36257309941520466\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8035714285714286  Recall:  0.42857142857142855   F1:  0.5590062111801243  Accuracy:  0.5847953216374269\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.8  Recall:  0.41904761904761906   F1:  0.55  Accuracy:  0.5789473684210527\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.7083333333333334  Recall:  0.4857142857142857   F1:  0.576271186440678  Accuracy:  0.5614035087719298\n",
            "\n",
            "Random Forest : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.9342105263157895  Recall:  0.6761904761904762   F1:  0.7845303867403315  Accuracy:  0.7719298245614035\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.6176470588235294  Recall:  1.0   F1:  0.7636363636363637  Accuracy:  0.6198830409356725\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.6153846153846154  Recall:  0.9904761904761905   F1:  0.759124087591241  Accuracy:  0.6140350877192983\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.9240506329113924  Recall:  0.6952380952380952   F1:  0.7934782608695652  Accuracy:  0.7777777777777778\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.9125  Recall:  0.6952380952380952   F1:  0.7891891891891892  Accuracy:  0.7719298245614035\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.925  Recall:  0.7047619047619048   F1:  0.8000000000000002  Accuracy:  0.783625730994152\n",
            "\n",
            "AdaBoost : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8095238095238095  Recall:  0.6476190476190476   F1:  0.7195767195767195  Accuracy:  0.6900584795321637\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.6227544910179641  Recall:  0.9904761904761905   F1:  0.7647058823529412  Accuracy:  0.6257309941520468\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.6666666666666666  Recall:  0.6666666666666666   F1:  0.6666666666666666  Accuracy:  0.5906432748538012\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.7931034482758621  Recall:  0.6571428571428571   F1:  0.71875  Accuracy:  0.6842105263157895\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.7931034482758621  Recall:  0.6571428571428571   F1:  0.71875  Accuracy:  0.6842105263157895\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.8588235294117647  Recall:  0.6952380952380952   F1:  0.7684210526315789  Accuracy:  0.7426900584795322\n",
            "\n",
            "XGBoostClassifier : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8586956521739131  Recall:  0.7523809523809524   F1:  0.802030456852792  Accuracy:  0.7719298245614035\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.6265060240963856  Recall:  0.9904761904761905   F1:  0.7675276752767527  Accuracy:  0.631578947368421\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.5855855855855856  Recall:  0.6190476190476191   F1:  0.6018518518518519  Accuracy:  0.49707602339181284\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.9069767441860465  Recall:  0.7428571428571429   F1:  0.8167539267015708  Accuracy:  0.7953216374269005\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.8588235294117647  Recall:  0.6952380952380952   F1:  0.7684210526315789  Accuracy:  0.7426900584795322\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.9195402298850575  Recall:  0.7619047619047619   F1:  0.8333333333333334  Accuracy:  0.8128654970760234\n",
            "\n"
          ]
        }
      ],
      "source": [
        "findPredictions(x_train, x_test, y_train, y_test, \"Bitter\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCPp5odqNKDL"
      },
      "source": [
        "## **Mordred**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj7DkgsCsWny"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB_MyE55NSVu"
      },
      "source": [
        "Sweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhNYUFHrNqgM"
      },
      "outputs": [],
      "source": [
        "y_train = sweet_train_M['Sweet']\n",
        "x_train = sweet_train_M.drop(['Sweet','Name','Taste'],axis=1)\n",
        "y_train.replace({True:1, False:0},inplace=True)\n",
        "y_test = sweet_test_M['Sweet']\n",
        "x_test = sweet_test_M.drop(['Sweet','Name','Taste'],axis=1)\n",
        "y_test.replace({True:1, False:0},inplace=True)\n",
        "y_train = y_train.to_frame()\n",
        "y_test = y_test.to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkCDcRgwNqgN",
        "outputId": "6ea9bea0-366f-48bb-daeb-22454b4dcaca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression : \n",
            "------------------------\n",
            "\n",
            "Basic ==>                          Precision:  0.0  Recall:  0.0   F1:  0.0  Accuracy:  0.32679738562091504\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.6644295302013423  Recall:  0.9611650485436893   F1:  0.7857142857142857  Accuracy:  0.6470588235294118\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.6644295302013423  Recall:  0.9611650485436893   F1:  0.7857142857142857  Accuracy:  0.6470588235294118\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.0  Recall:  0.0   F1:  0.0  Accuracy:  0.32679738562091504\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.0  Recall:  0.0   F1:  0.0  Accuracy:  0.32679738562091504\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.0  Recall:  0.0   F1:  0.0  Accuracy:  0.32679738562091504\n",
            "\n",
            "Random Forest : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8589743589743589  Recall:  0.6504854368932039   F1:  0.7403314917127072  Accuracy:  0.6928104575163399\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.0  Recall:  0.0   F1:  0.0  Accuracy:  0.32679738562091504\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.0  Recall:  0.0   F1:  0.0  Accuracy:  0.32679738562091504\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8732394366197183  Recall:  0.6019417475728155   F1:  0.7126436781609194  Accuracy:  0.673202614379085\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.8513513513513513  Recall:  0.6116504854368932   F1:  0.711864406779661  Accuracy:  0.6666666666666666\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.8421052631578947  Recall:  0.6213592233009708   F1:  0.7150837988826816  Accuracy:  0.6666666666666666\n",
            "\n",
            "AdaBoost : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8372093023255814  Recall:  0.6990291262135923   F1:  0.761904761904762  Accuracy:  0.7058823529411765\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.0  Recall:  0.0   F1:  0.0  Accuracy:  0.32679738562091504\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.5384615384615384  Recall:  0.27184466019417475   F1:  0.36129032258064514  Accuracy:  0.35294117647058826\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8275862068965517  Recall:  0.6990291262135923   F1:  0.7578947368421052  Accuracy:  0.6993464052287581\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.7922077922077922  Recall:  0.5922330097087378   F1:  0.6777777777777777  Accuracy:  0.6209150326797386\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.8089887640449438  Recall:  0.6990291262135923   F1:  0.75  Accuracy:  0.6862745098039216\n",
            "\n",
            "XGBoostClassifier : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8571428571428571  Recall:  0.6990291262135923   F1:  0.7700534759358288  Accuracy:  0.7189542483660131\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.0  Recall:  0.0   F1:  0.0  Accuracy:  0.32679738562091504\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.6111111111111112  Recall:  0.10679611650485436   F1:  0.18181818181818182  Accuracy:  0.35294117647058826\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8518518518518519  Recall:  0.6699029126213593   F1:  0.7500000000000001  Accuracy:  0.6993464052287581\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.8395061728395061  Recall:  0.6601941747572816   F1:  0.7391304347826088  Accuracy:  0.6862745098039216\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.8275862068965517  Recall:  0.6990291262135923   F1:  0.7578947368421052  Accuracy:  0.6993464052287581\n",
            "\n"
          ]
        }
      ],
      "source": [
        "findPredictions(x_train, x_test, y_train, y_test, \"Sweet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59c-AOzsTh-S"
      },
      "source": [
        "Bitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU5C1TwtTh-T"
      },
      "outputs": [],
      "source": [
        "y_train = bitter_train_M['Bitter']\n",
        "x_train = bitter_train_M.drop(['Bitter','Name','Taste'],axis=1)\n",
        "y_train.replace({True:1, False:0},inplace=True)\n",
        "y_test = bitter_test_M['Bitter']\n",
        "x_test = bitter_test_M.drop(['Bitter','Name','Taste'],axis=1)\n",
        "y_test.replace({True:1, False:0},inplace=True)\n",
        "y_train = y_train.to_frame()\n",
        "y_test = y_test.to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRetztm6T3sw",
        "outputId": "b90660bb-bea4-4f1b-8a74-79796663f091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression : \n",
            "------------------------\n",
            "\n",
            "Basic ==>                          Precision:  1.0  Recall:  0.009523809523809525   F1:  0.01886792452830189  Accuracy:  0.391812865497076\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.4864864864864865  Recall:  0.5142857142857142   F1:  0.5  Accuracy:  0.3684210526315789\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.5877192982456141  Recall:  0.638095238095238   F1:  0.6118721461187215  Accuracy:  0.5029239766081871\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.6140350877192983  Recall:  1.0   F1:  0.7608695652173912  Accuracy:  0.6140350877192983\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.6140350877192983  Recall:  1.0   F1:  0.7608695652173912  Accuracy:  0.6140350877192983\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.6140350877192983  Recall:  1.0   F1:  0.7608695652173912  Accuracy:  0.6140350877192983\n",
            "\n",
            "Random Forest : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8404255319148937  Recall:  0.7523809523809524   F1:  0.7939698492462312  Accuracy:  0.7602339181286549\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.0  Recall:  0.0   F1:  0.0  Accuracy:  0.38596491228070173\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.6118421052631579  Recall:  0.8857142857142857   F1:  0.7237354085603113  Accuracy:  0.5847953216374269\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8977272727272727  Recall:  0.7523809523809524   F1:  0.8186528497409326  Accuracy:  0.7953216374269005\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.851063829787234  Recall:  0.7619047619047619   F1:  0.8040201005025126  Accuracy:  0.7719298245614035\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.851063829787234  Recall:  0.7619047619047619   F1:  0.8040201005025126  Accuracy:  0.7719298245614035\n",
            "\n",
            "AdaBoost : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8735632183908046  Recall:  0.7238095238095238   F1:  0.7916666666666667  Accuracy:  0.7660818713450293\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.0  Recall:  0.0   F1:  0.0  Accuracy:  0.38596491228070173\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.6274509803921569  Recall:  0.3047619047619048   F1:  0.4102564102564103  Accuracy:  0.4619883040935672\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8648648648648649  Recall:  0.6095238095238096   F1:  0.7150837988826816  Accuracy:  0.7017543859649122\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.8648648648648649  Recall:  0.6095238095238096   F1:  0.7150837988826816  Accuracy:  0.7017543859649122\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.8020833333333334  Recall:  0.7333333333333333   F1:  0.7661691542288558  Accuracy:  0.7251461988304093\n",
            "\n",
            "XGBoostClassifier : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8842105263157894  Recall:  0.8   F1:  0.8400000000000001  Accuracy:  0.8128654970760234\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.0  Recall:  0.0   F1:  0.0  Accuracy:  0.38596491228070173\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.6782608695652174  Recall:  0.7428571428571429   F1:  0.7090909090909091  Accuracy:  0.6257309941520468\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8426966292134831  Recall:  0.7142857142857143   F1:  0.7731958762886597  Accuracy:  0.7426900584795322\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.8823529411764706  Recall:  0.7142857142857143   F1:  0.7894736842105262  Accuracy:  0.7660818713450293\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.8297872340425532  Recall:  0.7428571428571429   F1:  0.7839195979899497  Accuracy:  0.7485380116959064\n",
            "\n"
          ]
        }
      ],
      "source": [
        "findPredictions(x_train, x_test, y_train, y_test, \"Bitter\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvl0MZqc9yE2"
      },
      "source": [
        "**Boruta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LwNmHIrpwfj",
        "outputId": "a1374515-43a4-4ce4-84a4-3d2e2d86647e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.7/dist-packages (0.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from Boruta) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from Boruta) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from Boruta) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17.1->Boruta) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17.1->Boruta) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "pip install Boruta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjr14OwbpkpF"
      },
      "outputs": [],
      "source": [
        "from boruta import BorutaPy\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUX6xLemp8BU"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=8)\n",
        "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1, max_iter=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WvkVBnmAep5"
      },
      "outputs": [],
      "source": [
        "y_train = sweet_train_M['Sweet']\n",
        "x_train = sweet_train_M.drop(['Sweet','Name','Taste'],axis=1)\n",
        "\n",
        "y_train = y_train.to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGuD9bqSrDLD"
      },
      "outputs": [],
      "source": [
        "x = x_train.iloc[:,:].values\n",
        "y = y_train.iloc[:,:].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBGKTgDkw5bs"
      },
      "outputs": [],
      "source": [
        "y = y.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwKse6dwqq7x",
        "outputId": "4353f21c-4be3-4fc9-9b09-e3cc48385123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: \t1 / 200\n",
            "Confirmed: \t0\n",
            "Tentative: \t1613\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 200\n",
            "Confirmed: \t0\n",
            "Tentative: \t1613\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 200\n",
            "Confirmed: \t0\n",
            "Tentative: \t1613\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 200\n",
            "Confirmed: \t0\n",
            "Tentative: \t1613\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 200\n",
            "Confirmed: \t0\n",
            "Tentative: \t1613\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 200\n",
            "Confirmed: \t0\n",
            "Tentative: \t1613\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 200\n",
            "Confirmed: \t0\n",
            "Tentative: \t1613\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 200\n",
            "Confirmed: \t208\n",
            "Tentative: \t438\n",
            "Rejected: \t967\n",
            "Iteration: \t9 / 200\n",
            "Confirmed: \t208\n",
            "Tentative: \t438\n",
            "Rejected: \t967\n",
            "Iteration: \t10 / 200\n",
            "Confirmed: \t208\n",
            "Tentative: \t438\n",
            "Rejected: \t967\n",
            "Iteration: \t11 / 200\n",
            "Confirmed: \t208\n",
            "Tentative: \t438\n",
            "Rejected: \t967\n",
            "Iteration: \t12 / 200\n",
            "Confirmed: \t229\n",
            "Tentative: \t321\n",
            "Rejected: \t1063\n",
            "Iteration: \t13 / 200\n",
            "Confirmed: \t229\n",
            "Tentative: \t321\n",
            "Rejected: \t1063\n",
            "Iteration: \t14 / 200\n",
            "Confirmed: \t229\n",
            "Tentative: \t321\n",
            "Rejected: \t1063\n",
            "Iteration: \t15 / 200\n",
            "Confirmed: \t229\n",
            "Tentative: \t321\n",
            "Rejected: \t1063\n",
            "Iteration: \t16 / 200\n",
            "Confirmed: \t230\n",
            "Tentative: \t261\n",
            "Rejected: \t1122\n",
            "Iteration: \t17 / 200\n",
            "Confirmed: \t230\n",
            "Tentative: \t261\n",
            "Rejected: \t1122\n",
            "Iteration: \t18 / 200\n",
            "Confirmed: \t230\n",
            "Tentative: \t261\n",
            "Rejected: \t1122\n",
            "Iteration: \t19 / 200\n",
            "Confirmed: \t230\n",
            "Tentative: \t236\n",
            "Rejected: \t1147\n",
            "Iteration: \t20 / 200\n",
            "Confirmed: \t230\n",
            "Tentative: \t236\n",
            "Rejected: \t1147\n",
            "Iteration: \t21 / 200\n",
            "Confirmed: \t230\n",
            "Tentative: \t236\n",
            "Rejected: \t1147\n",
            "Iteration: \t22 / 200\n",
            "Confirmed: \t231\n",
            "Tentative: \t235\n",
            "Rejected: \t1147\n",
            "Iteration: \t23 / 200\n",
            "Confirmed: \t231\n",
            "Tentative: \t235\n",
            "Rejected: \t1147\n",
            "Iteration: \t24 / 200\n",
            "Confirmed: \t231\n",
            "Tentative: \t227\n",
            "Rejected: \t1155\n",
            "Iteration: \t25 / 200\n",
            "Confirmed: \t231\n",
            "Tentative: \t227\n",
            "Rejected: \t1155\n",
            "Iteration: \t26 / 200\n",
            "Confirmed: \t232\n",
            "Tentative: \t206\n",
            "Rejected: \t1175\n",
            "Iteration: \t27 / 200\n",
            "Confirmed: \t232\n",
            "Tentative: \t206\n",
            "Rejected: \t1175\n",
            "Iteration: \t28 / 200\n",
            "Confirmed: \t232\n",
            "Tentative: \t206\n",
            "Rejected: \t1175\n",
            "Iteration: \t29 / 200\n",
            "Confirmed: \t235\n",
            "Tentative: \t203\n",
            "Rejected: \t1175\n",
            "Iteration: \t30 / 200\n",
            "Confirmed: \t235\n",
            "Tentative: \t193\n",
            "Rejected: \t1185\n",
            "Iteration: \t31 / 200\n",
            "Confirmed: \t235\n",
            "Tentative: \t193\n",
            "Rejected: \t1185\n",
            "Iteration: \t32 / 200\n",
            "Confirmed: \t235\n",
            "Tentative: \t181\n",
            "Rejected: \t1197\n",
            "Iteration: \t33 / 200\n",
            "Confirmed: \t235\n",
            "Tentative: \t181\n",
            "Rejected: \t1197\n",
            "Iteration: \t34 / 200\n",
            "Confirmed: \t237\n",
            "Tentative: \t164\n",
            "Rejected: \t1212\n",
            "Iteration: \t35 / 200\n",
            "Confirmed: \t237\n",
            "Tentative: \t164\n",
            "Rejected: \t1212\n",
            "Iteration: \t36 / 200\n",
            "Confirmed: \t237\n",
            "Tentative: \t164\n",
            "Rejected: \t1212\n",
            "Iteration: \t37 / 200\n",
            "Confirmed: \t238\n",
            "Tentative: \t163\n",
            "Rejected: \t1212\n",
            "Iteration: \t38 / 200\n",
            "Confirmed: \t238\n",
            "Tentative: \t156\n",
            "Rejected: \t1219\n",
            "Iteration: \t39 / 200\n",
            "Confirmed: \t238\n",
            "Tentative: \t156\n",
            "Rejected: \t1219\n",
            "Iteration: \t40 / 200\n",
            "Confirmed: \t238\n",
            "Tentative: \t156\n",
            "Rejected: \t1219\n",
            "Iteration: \t41 / 200\n",
            "Confirmed: \t238\n",
            "Tentative: \t149\n",
            "Rejected: \t1226\n",
            "Iteration: \t42 / 200\n",
            "Confirmed: \t238\n",
            "Tentative: \t149\n",
            "Rejected: \t1226\n",
            "Iteration: \t43 / 200\n",
            "Confirmed: \t238\n",
            "Tentative: \t142\n",
            "Rejected: \t1233\n",
            "Iteration: \t44 / 200\n",
            "Confirmed: \t238\n",
            "Tentative: \t142\n",
            "Rejected: \t1233\n",
            "Iteration: \t45 / 200\n",
            "Confirmed: \t238\n",
            "Tentative: \t142\n",
            "Rejected: \t1233\n",
            "Iteration: \t46 / 200\n",
            "Confirmed: \t239\n",
            "Tentative: \t132\n",
            "Rejected: \t1242\n",
            "Iteration: \t47 / 200\n",
            "Confirmed: \t239\n",
            "Tentative: \t132\n",
            "Rejected: \t1242\n",
            "Iteration: \t48 / 200\n",
            "Confirmed: \t239\n",
            "Tentative: \t132\n",
            "Rejected: \t1242\n",
            "Iteration: \t49 / 200\n",
            "Confirmed: \t239\n",
            "Tentative: \t123\n",
            "Rejected: \t1251\n",
            "Iteration: \t50 / 200\n",
            "Confirmed: \t239\n",
            "Tentative: \t123\n",
            "Rejected: \t1251\n",
            "Iteration: \t51 / 200\n",
            "Confirmed: \t239\n",
            "Tentative: \t112\n",
            "Rejected: \t1262\n",
            "Iteration: \t52 / 200\n",
            "Confirmed: \t239\n",
            "Tentative: \t112\n",
            "Rejected: \t1262\n",
            "Iteration: \t53 / 200\n",
            "Confirmed: \t239\n",
            "Tentative: \t112\n",
            "Rejected: \t1262\n",
            "Iteration: \t54 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t111\n",
            "Rejected: \t1262\n",
            "Iteration: \t55 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t108\n",
            "Rejected: \t1265\n",
            "Iteration: \t56 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t108\n",
            "Rejected: \t1265\n",
            "Iteration: \t57 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t108\n",
            "Rejected: \t1265\n",
            "Iteration: \t58 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t107\n",
            "Rejected: \t1266\n",
            "Iteration: \t59 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t102\n",
            "Rejected: \t1271\n",
            "Iteration: \t60 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t102\n",
            "Rejected: \t1271\n",
            "Iteration: \t61 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t102\n",
            "Rejected: \t1271\n",
            "Iteration: \t62 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t102\n",
            "Rejected: \t1271\n",
            "Iteration: \t63 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t102\n",
            "Rejected: \t1271\n",
            "Iteration: \t64 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t101\n",
            "Rejected: \t1272\n",
            "Iteration: \t65 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t98\n",
            "Rejected: \t1275\n",
            "Iteration: \t66 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t98\n",
            "Rejected: \t1275\n",
            "Iteration: \t67 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t98\n",
            "Rejected: \t1275\n",
            "Iteration: \t68 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t97\n",
            "Rejected: \t1276\n",
            "Iteration: \t69 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t97\n",
            "Rejected: \t1276\n",
            "Iteration: \t70 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t95\n",
            "Rejected: \t1278\n",
            "Iteration: \t71 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t95\n",
            "Rejected: \t1278\n",
            "Iteration: \t72 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t93\n",
            "Rejected: \t1280\n",
            "Iteration: \t73 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t93\n",
            "Rejected: \t1280\n",
            "Iteration: \t74 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t93\n",
            "Rejected: \t1280\n",
            "Iteration: \t75 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t91\n",
            "Rejected: \t1282\n",
            "Iteration: \t76 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t91\n",
            "Rejected: \t1282\n",
            "Iteration: \t77 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t85\n",
            "Rejected: \t1288\n",
            "Iteration: \t78 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t85\n",
            "Rejected: \t1288\n",
            "Iteration: \t79 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t85\n",
            "Rejected: \t1288\n",
            "Iteration: \t80 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t83\n",
            "Rejected: \t1290\n",
            "Iteration: \t81 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t83\n",
            "Rejected: \t1290\n",
            "Iteration: \t82 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t83\n",
            "Rejected: \t1290\n",
            "Iteration: \t83 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t82\n",
            "Rejected: \t1291\n",
            "Iteration: \t84 / 200\n",
            "Confirmed: \t240\n",
            "Tentative: \t82\n",
            "Rejected: \t1291\n",
            "Iteration: \t85 / 200\n",
            "Confirmed: \t241\n",
            "Tentative: \t76\n",
            "Rejected: \t1296\n",
            "Iteration: \t86 / 200\n",
            "Confirmed: \t241\n",
            "Tentative: \t76\n",
            "Rejected: \t1296\n",
            "Iteration: \t87 / 200\n",
            "Confirmed: \t241\n",
            "Tentative: \t76\n",
            "Rejected: \t1296\n",
            "Iteration: \t88 / 200\n",
            "Confirmed: \t241\n",
            "Tentative: \t74\n",
            "Rejected: \t1298\n",
            "Iteration: \t89 / 200\n",
            "Confirmed: \t241\n",
            "Tentative: \t74\n",
            "Rejected: \t1298\n",
            "Iteration: \t90 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t70\n",
            "Rejected: \t1301\n",
            "Iteration: \t91 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t70\n",
            "Rejected: \t1301\n",
            "Iteration: \t92 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t70\n",
            "Rejected: \t1301\n",
            "Iteration: \t93 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t70\n",
            "Rejected: \t1301\n",
            "Iteration: \t94 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t70\n",
            "Rejected: \t1301\n",
            "Iteration: \t95 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t67\n",
            "Rejected: \t1304\n",
            "Iteration: \t96 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t67\n",
            "Rejected: \t1304\n",
            "Iteration: \t97 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t67\n",
            "Rejected: \t1304\n",
            "Iteration: \t98 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t67\n",
            "Rejected: \t1304\n",
            "Iteration: \t99 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t67\n",
            "Rejected: \t1304\n",
            "Iteration: \t100 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t66\n",
            "Rejected: \t1305\n",
            "Iteration: \t101 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t66\n",
            "Rejected: \t1305\n",
            "Iteration: \t102 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t66\n",
            "Rejected: \t1305\n",
            "Iteration: \t103 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t65\n",
            "Rejected: \t1306\n",
            "Iteration: \t104 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t65\n",
            "Rejected: \t1306\n",
            "Iteration: \t105 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t65\n",
            "Rejected: \t1306\n",
            "Iteration: \t106 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t65\n",
            "Rejected: \t1306\n",
            "Iteration: \t107 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t65\n",
            "Rejected: \t1306\n",
            "Iteration: \t108 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t65\n",
            "Rejected: \t1306\n",
            "Iteration: \t109 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t65\n",
            "Rejected: \t1306\n",
            "Iteration: \t110 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t111 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t112 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t113 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t114 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t115 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t116 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t117 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t118 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t119 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t120 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t121 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t64\n",
            "Rejected: \t1307\n",
            "Iteration: \t122 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t123 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t124 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t125 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t126 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t127 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t128 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t129 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t130 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t131 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t132 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t133 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t63\n",
            "Rejected: \t1308\n",
            "Iteration: \t134 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t62\n",
            "Rejected: \t1309\n",
            "Iteration: \t135 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t62\n",
            "Rejected: \t1309\n",
            "Iteration: \t136 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t62\n",
            "Rejected: \t1309\n",
            "Iteration: \t137 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t62\n",
            "Rejected: \t1309\n",
            "Iteration: \t138 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t62\n",
            "Rejected: \t1309\n",
            "Iteration: \t139 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t62\n",
            "Rejected: \t1309\n",
            "Iteration: \t140 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t62\n",
            "Rejected: \t1309\n",
            "Iteration: \t141 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t61\n",
            "Rejected: \t1310\n",
            "Iteration: \t142 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t61\n",
            "Rejected: \t1310\n",
            "Iteration: \t143 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t61\n",
            "Rejected: \t1310\n",
            "Iteration: \t144 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t61\n",
            "Rejected: \t1310\n",
            "Iteration: \t145 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t61\n",
            "Rejected: \t1310\n",
            "Iteration: \t146 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t61\n",
            "Rejected: \t1310\n",
            "Iteration: \t147 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t61\n",
            "Rejected: \t1310\n",
            "Iteration: \t148 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t61\n",
            "Rejected: \t1310\n",
            "Iteration: \t149 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t150 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t151 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t152 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t153 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t154 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t155 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t156 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t157 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t158 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t159 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t160 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t161 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t162 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t163 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t164 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t165 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t166 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t167 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t168 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t169 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t170 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t171 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t172 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t173 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t174 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t175 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t176 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t59\n",
            "Rejected: \t1312\n",
            "Iteration: \t177 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t178 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t179 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t180 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t181 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t182 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t183 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t184 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t185 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t186 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t187 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t188 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t58\n",
            "Rejected: \t1313\n",
            "Iteration: \t189 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t57\n",
            "Rejected: \t1314\n",
            "Iteration: \t190 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t57\n",
            "Rejected: \t1314\n",
            "Iteration: \t191 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t55\n",
            "Rejected: \t1316\n",
            "Iteration: \t192 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t55\n",
            "Rejected: \t1316\n",
            "Iteration: \t193 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t55\n",
            "Rejected: \t1316\n",
            "Iteration: \t194 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t55\n",
            "Rejected: \t1316\n",
            "Iteration: \t195 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t55\n",
            "Rejected: \t1316\n",
            "Iteration: \t196 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t54\n",
            "Rejected: \t1317\n",
            "Iteration: \t197 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t54\n",
            "Rejected: \t1317\n",
            "Iteration: \t198 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t54\n",
            "Rejected: \t1317\n",
            "Iteration: \t199 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t54\n",
            "Rejected: \t1317\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t200 / 200\n",
            "Confirmed: \t242\n",
            "Tentative: \t10\n",
            "Rejected: \t1317\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestClassifier(class_weight='balanced', max_depth=8,\n",
              "                                          n_estimators=304, n_jobs=-1,\n",
              "                                          random_state=RandomState(MT19937) at 0x7F1CAD158E20),\n",
              "         max_iter=200, n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7F1CAD158E20, verbose=2)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_selector.fit(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn_SHURptANk"
      },
      "outputs": [],
      "source": [
        "listA = []\n",
        "for i in range(0, len(feat_selector.support_)):\n",
        "  if  feat_selector.support_[i]== False:\n",
        "    listA.append(i)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqyRbD95Gm-i",
        "outputId": "212a0e55-6b9b-4096-92e4-4887e3ecbfd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1371"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(listA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3kI_iyOGpMm"
      },
      "outputs": [],
      "source": [
        "x_new = x_train.drop(x_train.columns[listA],\n",
        "                       axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "-Wf2p2pUH99P",
        "outputId": "87e3a861-e9af-4fb3-e681-61e653bc5fc2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f8884cb9-ab16-460a-ba77-c4fce2b21165\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nN</th>\n",
              "      <th>ATS2dv</th>\n",
              "      <th>ATS3s</th>\n",
              "      <th>ATS4s</th>\n",
              "      <th>ATS0Z</th>\n",
              "      <th>ATS0m</th>\n",
              "      <th>ATS3m</th>\n",
              "      <th>ATS0p</th>\n",
              "      <th>AATS0d</th>\n",
              "      <th>AATS3d</th>\n",
              "      <th>AATS4d</th>\n",
              "      <th>AATS0Z</th>\n",
              "      <th>AATS2Z</th>\n",
              "      <th>AATS0m</th>\n",
              "      <th>AATS1m</th>\n",
              "      <th>AATS0v</th>\n",
              "      <th>AATS1v</th>\n",
              "      <th>AATS2v</th>\n",
              "      <th>AATS3v</th>\n",
              "      <th>AATS4v</th>\n",
              "      <th>AATS0p</th>\n",
              "      <th>AATS1p</th>\n",
              "      <th>AATS2p</th>\n",
              "      <th>AATS3p</th>\n",
              "      <th>AATS4p</th>\n",
              "      <th>AATS0i</th>\n",
              "      <th>AATS1i</th>\n",
              "      <th>AATS3i</th>\n",
              "      <th>AATS4i</th>\n",
              "      <th>AATS5i</th>\n",
              "      <th>AATS7i</th>\n",
              "      <th>ATSC2c</th>\n",
              "      <th>ATSC3c</th>\n",
              "      <th>ATSC4c</th>\n",
              "      <th>ATSC5c</th>\n",
              "      <th>ATSC1d</th>\n",
              "      <th>ATSC0s</th>\n",
              "      <th>ATSC6Z</th>\n",
              "      <th>ATSC6m</th>\n",
              "      <th>ATSC6v</th>\n",
              "      <th>...</th>\n",
              "      <th>AMID_N</th>\n",
              "      <th>MID_O</th>\n",
              "      <th>AMID_O</th>\n",
              "      <th>MPC2</th>\n",
              "      <th>MPC3</th>\n",
              "      <th>MPC4</th>\n",
              "      <th>MPC5</th>\n",
              "      <th>MPC6</th>\n",
              "      <th>MPC7</th>\n",
              "      <th>MPC8</th>\n",
              "      <th>MPC9</th>\n",
              "      <th>TMPC10</th>\n",
              "      <th>piPC1</th>\n",
              "      <th>piPC2</th>\n",
              "      <th>piPC3</th>\n",
              "      <th>piPC4</th>\n",
              "      <th>piPC5</th>\n",
              "      <th>piPC6</th>\n",
              "      <th>piPC7</th>\n",
              "      <th>piPC8</th>\n",
              "      <th>piPC9</th>\n",
              "      <th>piPC10</th>\n",
              "      <th>TpiPC10</th>\n",
              "      <th>nRing</th>\n",
              "      <th>JGI3</th>\n",
              "      <th>MWC03</th>\n",
              "      <th>MWC04</th>\n",
              "      <th>MWC05</th>\n",
              "      <th>MWC06</th>\n",
              "      <th>MWC07</th>\n",
              "      <th>MWC08</th>\n",
              "      <th>MWC09</th>\n",
              "      <th>MWC10</th>\n",
              "      <th>TMWC10</th>\n",
              "      <th>SRW06</th>\n",
              "      <th>SRW08</th>\n",
              "      <th>SRW10</th>\n",
              "      <th>AMW</th>\n",
              "      <th>WPol</th>\n",
              "      <th>Zagreb2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>652.500000</td>\n",
              "      <td>629.083333</td>\n",
              "      <td>1158.0</td>\n",
              "      <td>4569.170871</td>\n",
              "      <td>9413.865359</td>\n",
              "      <td>50.323528</td>\n",
              "      <td>3.155556</td>\n",
              "      <td>2.830645</td>\n",
              "      <td>2.541353</td>\n",
              "      <td>25.733333</td>\n",
              "      <td>23.192771</td>\n",
              "      <td>101.537130</td>\n",
              "      <td>96.335918</td>\n",
              "      <td>181.029861</td>\n",
              "      <td>233.387037</td>\n",
              "      <td>201.265826</td>\n",
              "      <td>160.826674</td>\n",
              "      <td>144.999343</td>\n",
              "      <td>1.118301</td>\n",
              "      <td>1.445816</td>\n",
              "      <td>1.258039</td>\n",
              "      <td>1.017477</td>\n",
              "      <td>0.952669</td>\n",
              "      <td>169.548550</td>\n",
              "      <td>153.042175</td>\n",
              "      <td>166.058828</td>\n",
              "      <td>167.454386</td>\n",
              "      <td>169.891248</td>\n",
              "      <td>168.161237</td>\n",
              "      <td>-0.652482</td>\n",
              "      <td>1.204605</td>\n",
              "      <td>-0.670753</td>\n",
              "      <td>0.228861</td>\n",
              "      <td>12.975309</td>\n",
              "      <td>160.554938</td>\n",
              "      <td>-5.453827</td>\n",
              "      <td>-19.969966</td>\n",
              "      <td>125.602063</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.160229</td>\n",
              "      <td>0.876532</td>\n",
              "      <td>36</td>\n",
              "      <td>51</td>\n",
              "      <td>62</td>\n",
              "      <td>73</td>\n",
              "      <td>74</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>68</td>\n",
              "      <td>608</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.951244</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.304065</td>\n",
              "      <td>4.317488</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.234107</td>\n",
              "      <td>4.060443</td>\n",
              "      <td>6.411818</td>\n",
              "      <td>2</td>\n",
              "      <td>0.082526</td>\n",
              "      <td>5.686975</td>\n",
              "      <td>6.602588</td>\n",
              "      <td>7.513709</td>\n",
              "      <td>8.434464</td>\n",
              "      <td>9.350189</td>\n",
              "      <td>10.272738</td>\n",
              "      <td>11.190528</td>\n",
              "      <td>12.113908</td>\n",
              "      <td>122.960890</td>\n",
              "      <td>6.849066</td>\n",
              "      <td>8.525360</td>\n",
              "      <td>10.247042</td>\n",
              "      <td>7.602582</td>\n",
              "      <td>43</td>\n",
              "      <td>147.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>477.111111</td>\n",
              "      <td>509.601852</td>\n",
              "      <td>424.106996</td>\n",
              "      <td>1830.0</td>\n",
              "      <td>7568.326176</td>\n",
              "      <td>11909.663100</td>\n",
              "      <td>61.317277</td>\n",
              "      <td>3.309524</td>\n",
              "      <td>2.895652</td>\n",
              "      <td>2.603306</td>\n",
              "      <td>43.571429</td>\n",
              "      <td>27.100000</td>\n",
              "      <td>180.198242</td>\n",
              "      <td>118.231375</td>\n",
              "      <td>212.281739</td>\n",
              "      <td>255.059582</td>\n",
              "      <td>215.170710</td>\n",
              "      <td>179.685807</td>\n",
              "      <td>165.227306</td>\n",
              "      <td>1.459935</td>\n",
              "      <td>1.669930</td>\n",
              "      <td>1.435949</td>\n",
              "      <td>1.191106</td>\n",
              "      <td>1.173424</td>\n",
              "      <td>167.215625</td>\n",
              "      <td>150.288731</td>\n",
              "      <td>164.818253</td>\n",
              "      <td>165.667994</td>\n",
              "      <td>168.181859</td>\n",
              "      <td>166.072550</td>\n",
              "      <td>-0.461902</td>\n",
              "      <td>0.767067</td>\n",
              "      <td>-0.461966</td>\n",
              "      <td>0.177657</td>\n",
              "      <td>10.282880</td>\n",
              "      <td>111.512642</td>\n",
              "      <td>-8.217687</td>\n",
              "      <td>-35.280625</td>\n",
              "      <td>-9.450500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.925656</td>\n",
              "      <td>0.648942</td>\n",
              "      <td>36</td>\n",
              "      <td>51</td>\n",
              "      <td>62</td>\n",
              "      <td>73</td>\n",
              "      <td>74</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>68</td>\n",
              "      <td>608</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.951244</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.304065</td>\n",
              "      <td>4.317488</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.234107</td>\n",
              "      <td>4.060443</td>\n",
              "      <td>6.411818</td>\n",
              "      <td>2</td>\n",
              "      <td>0.082526</td>\n",
              "      <td>5.686975</td>\n",
              "      <td>6.602588</td>\n",
              "      <td>7.513709</td>\n",
              "      <td>8.434464</td>\n",
              "      <td>9.350189</td>\n",
              "      <td>10.272738</td>\n",
              "      <td>11.190528</td>\n",
              "      <td>12.113908</td>\n",
              "      <td>122.960890</td>\n",
              "      <td>6.849066</td>\n",
              "      <td>8.525360</td>\n",
              "      <td>10.247042</td>\n",
              "      <td>9.428918</td>\n",
              "      <td>43</td>\n",
              "      <td>147.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>327.027778</td>\n",
              "      <td>372.666667</td>\n",
              "      <td>940.0</td>\n",
              "      <td>3710.218949</td>\n",
              "      <td>5232.341659</td>\n",
              "      <td>52.683652</td>\n",
              "      <td>2.923077</td>\n",
              "      <td>2.697674</td>\n",
              "      <td>2.467391</td>\n",
              "      <td>24.102564</td>\n",
              "      <td>20.676923</td>\n",
              "      <td>95.133819</td>\n",
              "      <td>92.739769</td>\n",
              "      <td>206.598109</td>\n",
              "      <td>251.559891</td>\n",
              "      <td>206.377537</td>\n",
              "      <td>173.668198</td>\n",
              "      <td>157.736959</td>\n",
              "      <td>1.350863</td>\n",
              "      <td>1.675350</td>\n",
              "      <td>1.429224</td>\n",
              "      <td>1.235235</td>\n",
              "      <td>1.107106</td>\n",
              "      <td>165.471161</td>\n",
              "      <td>150.112578</td>\n",
              "      <td>161.777305</td>\n",
              "      <td>165.699596</td>\n",
              "      <td>164.954150</td>\n",
              "      <td>163.395314</td>\n",
              "      <td>0.145983</td>\n",
              "      <td>0.338385</td>\n",
              "      <td>-0.698717</td>\n",
              "      <td>0.537398</td>\n",
              "      <td>4.692308</td>\n",
              "      <td>117.287749</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>316.956515</td>\n",
              "      <td>387.214257</td>\n",
              "      <td>...</td>\n",
              "      <td>0.178784</td>\n",
              "      <td>8.731863</td>\n",
              "      <td>0.415803</td>\n",
              "      <td>27</td>\n",
              "      <td>30</td>\n",
              "      <td>33</td>\n",
              "      <td>37</td>\n",
              "      <td>32</td>\n",
              "      <td>31</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>301</td>\n",
              "      <td>3.332205</td>\n",
              "      <td>3.749504</td>\n",
              "      <td>4.020877</td>\n",
              "      <td>4.312476</td>\n",
              "      <td>4.722398</td>\n",
              "      <td>4.452165</td>\n",
              "      <td>4.599529</td>\n",
              "      <td>4.819273</td>\n",
              "      <td>4.884694</td>\n",
              "      <td>4.627421</td>\n",
              "      <td>6.767271</td>\n",
              "      <td>1</td>\n",
              "      <td>0.043981</td>\n",
              "      <td>5.351858</td>\n",
              "      <td>6.175867</td>\n",
              "      <td>6.978214</td>\n",
              "      <td>7.805882</td>\n",
              "      <td>8.618485</td>\n",
              "      <td>9.447229</td>\n",
              "      <td>10.264966</td>\n",
              "      <td>11.093995</td>\n",
              "      <td>112.311208</td>\n",
              "      <td>6.447306</td>\n",
              "      <td>7.951207</td>\n",
              "      <td>9.493487</td>\n",
              "      <td>7.541579</td>\n",
              "      <td>27</td>\n",
              "      <td>105.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>393.500000</td>\n",
              "      <td>344.166667</td>\n",
              "      <td>612.0</td>\n",
              "      <td>2413.585500</td>\n",
              "      <td>4575.372616</td>\n",
              "      <td>25.927979</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.460317</td>\n",
              "      <td>1.772727</td>\n",
              "      <td>25.500000</td>\n",
              "      <td>23.047619</td>\n",
              "      <td>100.566063</td>\n",
              "      <td>92.993879</td>\n",
              "      <td>175.518792</td>\n",
              "      <td>227.079812</td>\n",
              "      <td>198.191463</td>\n",
              "      <td>153.270562</td>\n",
              "      <td>114.014016</td>\n",
              "      <td>1.080332</td>\n",
              "      <td>1.407855</td>\n",
              "      <td>1.237989</td>\n",
              "      <td>0.975734</td>\n",
              "      <td>0.796130</td>\n",
              "      <td>170.520236</td>\n",
              "      <td>154.381429</td>\n",
              "      <td>166.741525</td>\n",
              "      <td>172.134683</td>\n",
              "      <td>178.032893</td>\n",
              "      <td>184.993831</td>\n",
              "      <td>-0.307929</td>\n",
              "      <td>0.683571</td>\n",
              "      <td>-0.379936</td>\n",
              "      <td>-0.025630</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>95.268229</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>176.254520</td>\n",
              "      <td>243.836186</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.677995</td>\n",
              "      <td>0.889833</td>\n",
              "      <td>18</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>135</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>2.944439</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>3.135494</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>2.890372</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.912655</td>\n",
              "      <td>1</td>\n",
              "      <td>0.065625</td>\n",
              "      <td>4.962845</td>\n",
              "      <td>5.849325</td>\n",
              "      <td>6.722630</td>\n",
              "      <td>7.610358</td>\n",
              "      <td>8.487764</td>\n",
              "      <td>9.375092</td>\n",
              "      <td>10.253827</td>\n",
              "      <td>11.140687</td>\n",
              "      <td>92.513402</td>\n",
              "      <td>6.163315</td>\n",
              "      <td>7.845024</td>\n",
              "      <td>9.569063</td>\n",
              "      <td>7.502641</td>\n",
              "      <td>20</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>518.000000</td>\n",
              "      <td>682.541667</td>\n",
              "      <td>614.847222</td>\n",
              "      <td>1158.0</td>\n",
              "      <td>4569.170871</td>\n",
              "      <td>9127.853377</td>\n",
              "      <td>50.323528</td>\n",
              "      <td>3.155556</td>\n",
              "      <td>2.661290</td>\n",
              "      <td>2.270677</td>\n",
              "      <td>25.733333</td>\n",
              "      <td>23.192771</td>\n",
              "      <td>101.537130</td>\n",
              "      <td>96.335918</td>\n",
              "      <td>181.029861</td>\n",
              "      <td>233.387037</td>\n",
              "      <td>201.265826</td>\n",
              "      <td>157.905783</td>\n",
              "      <td>132.343321</td>\n",
              "      <td>1.118301</td>\n",
              "      <td>1.445816</td>\n",
              "      <td>1.258039</td>\n",
              "      <td>1.008267</td>\n",
              "      <td>0.897097</td>\n",
              "      <td>169.548550</td>\n",
              "      <td>153.042175</td>\n",
              "      <td>166.015110</td>\n",
              "      <td>169.040621</td>\n",
              "      <td>171.734788</td>\n",
              "      <td>166.939623</td>\n",
              "      <td>-0.628096</td>\n",
              "      <td>1.224730</td>\n",
              "      <td>-0.715289</td>\n",
              "      <td>0.159067</td>\n",
              "      <td>10.975309</td>\n",
              "      <td>160.554938</td>\n",
              "      <td>87.169383</td>\n",
              "      <td>415.124614</td>\n",
              "      <td>512.973197</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.110824</td>\n",
              "      <td>0.874384</td>\n",
              "      <td>36</td>\n",
              "      <td>49</td>\n",
              "      <td>56</td>\n",
              "      <td>62</td>\n",
              "      <td>58</td>\n",
              "      <td>53</td>\n",
              "      <td>58</td>\n",
              "      <td>67</td>\n",
              "      <td>557</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.912023</td>\n",
              "      <td>4.043051</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.077537</td>\n",
              "      <td>3.988984</td>\n",
              "      <td>4.077537</td>\n",
              "      <td>4.219508</td>\n",
              "      <td>4.276666</td>\n",
              "      <td>6.324359</td>\n",
              "      <td>2</td>\n",
              "      <td>0.077405</td>\n",
              "      <td>5.673323</td>\n",
              "      <td>6.575076</td>\n",
              "      <td>7.467942</td>\n",
              "      <td>8.371242</td>\n",
              "      <td>9.267193</td>\n",
              "      <td>10.170725</td>\n",
              "      <td>11.068184</td>\n",
              "      <td>11.971710</td>\n",
              "      <td>122.361186</td>\n",
              "      <td>6.836259</td>\n",
              "      <td>8.493105</td>\n",
              "      <td>10.192007</td>\n",
              "      <td>7.602582</td>\n",
              "      <td>41</td>\n",
              "      <td>145.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2162</th>\n",
              "      <td>1</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>77.166667</td>\n",
              "      <td>374.0</td>\n",
              "      <td>1471.157473</td>\n",
              "      <td>1698.267489</td>\n",
              "      <td>25.377020</td>\n",
              "      <td>2.722222</td>\n",
              "      <td>2.468750</td>\n",
              "      <td>2.068966</td>\n",
              "      <td>20.777778</td>\n",
              "      <td>18.068966</td>\n",
              "      <td>81.730971</td>\n",
              "      <td>83.733809</td>\n",
              "      <td>205.782053</td>\n",
              "      <td>249.208791</td>\n",
              "      <td>199.761175</td>\n",
              "      <td>172.007401</td>\n",
              "      <td>139.293359</td>\n",
              "      <td>1.409834</td>\n",
              "      <td>1.732770</td>\n",
              "      <td>1.435561</td>\n",
              "      <td>1.283351</td>\n",
              "      <td>1.117860</td>\n",
              "      <td>163.806151</td>\n",
              "      <td>147.310599</td>\n",
              "      <td>163.635093</td>\n",
              "      <td>161.168289</td>\n",
              "      <td>162.830109</td>\n",
              "      <td>184.917652</td>\n",
              "      <td>-0.044889</td>\n",
              "      <td>0.081225</td>\n",
              "      <td>-0.072734</td>\n",
              "      <td>0.023068</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>24.989198</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>134.419914</td>\n",
              "      <td>397.674863</td>\n",
              "      <td>...</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>1.727010</td>\n",
              "      <td>0.191890</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>3.068053</td>\n",
              "      <td>3.504055</td>\n",
              "      <td>3.944006</td>\n",
              "      <td>4.328263</td>\n",
              "      <td>3.840795</td>\n",
              "      <td>3.056357</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.583496</td>\n",
              "      <td>1</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>4.465908</td>\n",
              "      <td>5.262690</td>\n",
              "      <td>6.033086</td>\n",
              "      <td>6.834109</td>\n",
              "      <td>7.608374</td>\n",
              "      <td>8.409831</td>\n",
              "      <td>9.185125</td>\n",
              "      <td>9.986495</td>\n",
              "      <td>79.499191</td>\n",
              "      <td>5.556828</td>\n",
              "      <td>7.062192</td>\n",
              "      <td>8.606851</td>\n",
              "      <td>6.837134</td>\n",
              "      <td>9</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2163</th>\n",
              "      <td>0</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>112.111111</td>\n",
              "      <td>95.500000</td>\n",
              "      <td>388.0</td>\n",
              "      <td>1529.913361</td>\n",
              "      <td>1732.115297</td>\n",
              "      <td>24.365611</td>\n",
              "      <td>2.823529</td>\n",
              "      <td>2.437500</td>\n",
              "      <td>1.766667</td>\n",
              "      <td>22.823529</td>\n",
              "      <td>20.038462</td>\n",
              "      <td>89.994904</td>\n",
              "      <td>88.180785</td>\n",
              "      <td>214.474695</td>\n",
              "      <td>260.148487</td>\n",
              "      <td>225.702851</td>\n",
              "      <td>173.980851</td>\n",
              "      <td>117.158084</td>\n",
              "      <td>1.433271</td>\n",
              "      <td>1.761870</td>\n",
              "      <td>1.584842</td>\n",
              "      <td>1.283753</td>\n",
              "      <td>0.936417</td>\n",
              "      <td>161.047311</td>\n",
              "      <td>146.079470</td>\n",
              "      <td>155.014611</td>\n",
              "      <td>165.020611</td>\n",
              "      <td>173.254972</td>\n",
              "      <td>185.050964</td>\n",
              "      <td>0.017422</td>\n",
              "      <td>0.040603</td>\n",
              "      <td>-0.074446</td>\n",
              "      <td>-0.044465</td>\n",
              "      <td>1.941176</td>\n",
              "      <td>40.392157</td>\n",
              "      <td>-2.373702</td>\n",
              "      <td>-13.886239</td>\n",
              "      <td>-30.988205</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.480679</td>\n",
              "      <td>0.386742</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>3.068053</td>\n",
              "      <td>3.504055</td>\n",
              "      <td>3.899444</td>\n",
              "      <td>4.385925</td>\n",
              "      <td>3.876396</td>\n",
              "      <td>2.784239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.579258</td>\n",
              "      <td>1</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>4.465908</td>\n",
              "      <td>5.252273</td>\n",
              "      <td>6.028279</td>\n",
              "      <td>6.816736</td>\n",
              "      <td>7.598399</td>\n",
              "      <td>8.386401</td>\n",
              "      <td>9.169831</td>\n",
              "      <td>9.957265</td>\n",
              "      <td>79.388664</td>\n",
              "      <td>5.556828</td>\n",
              "      <td>7.055313</td>\n",
              "      <td>8.590258</td>\n",
              "      <td>7.297202</td>\n",
              "      <td>9</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2164</th>\n",
              "      <td>1</td>\n",
              "      <td>244.000000</td>\n",
              "      <td>156.333333</td>\n",
              "      <td>158.666667</td>\n",
              "      <td>554.0</td>\n",
              "      <td>2192.478078</td>\n",
              "      <td>3088.803862</td>\n",
              "      <td>39.321520</td>\n",
              "      <td>3.347826</td>\n",
              "      <td>3.086957</td>\n",
              "      <td>2.756098</td>\n",
              "      <td>24.086957</td>\n",
              "      <td>22.432432</td>\n",
              "      <td>95.325134</td>\n",
              "      <td>98.698891</td>\n",
              "      <td>253.115716</td>\n",
              "      <td>294.149276</td>\n",
              "      <td>259.728419</td>\n",
              "      <td>210.713375</td>\n",
              "      <td>190.455121</td>\n",
              "      <td>1.709631</td>\n",
              "      <td>2.020918</td>\n",
              "      <td>1.823509</td>\n",
              "      <td>1.518599</td>\n",
              "      <td>1.366621</td>\n",
              "      <td>155.760108</td>\n",
              "      <td>140.845633</td>\n",
              "      <td>152.012987</td>\n",
              "      <td>155.402614</td>\n",
              "      <td>155.365994</td>\n",
              "      <td>165.115362</td>\n",
              "      <td>-0.084842</td>\n",
              "      <td>0.048049</td>\n",
              "      <td>-0.037491</td>\n",
              "      <td>0.021029</td>\n",
              "      <td>2.918715</td>\n",
              "      <td>34.637681</td>\n",
              "      <td>-40.049149</td>\n",
              "      <td>-193.673897</td>\n",
              "      <td>-379.304122</td>\n",
              "      <td>...</td>\n",
              "      <td>0.142679</td>\n",
              "      <td>1.785574</td>\n",
              "      <td>0.127541</td>\n",
              "      <td>19</td>\n",
              "      <td>24</td>\n",
              "      <td>28</td>\n",
              "      <td>32</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>20</td>\n",
              "      <td>16</td>\n",
              "      <td>228</td>\n",
              "      <td>3.135494</td>\n",
              "      <td>3.663562</td>\n",
              "      <td>4.226834</td>\n",
              "      <td>4.711780</td>\n",
              "      <td>5.192262</td>\n",
              "      <td>5.029621</td>\n",
              "      <td>5.364222</td>\n",
              "      <td>5.432903</td>\n",
              "      <td>5.614496</td>\n",
              "      <td>5.731874</td>\n",
              "      <td>7.380791</td>\n",
              "      <td>2</td>\n",
              "      <td>0.048611</td>\n",
              "      <td>5.043425</td>\n",
              "      <td>5.866468</td>\n",
              "      <td>6.693324</td>\n",
              "      <td>7.524561</td>\n",
              "      <td>8.356790</td>\n",
              "      <td>9.191056</td>\n",
              "      <td>10.025307</td>\n",
              "      <td>10.860786</td>\n",
              "      <td>96.795823</td>\n",
              "      <td>6.137727</td>\n",
              "      <td>7.690286</td>\n",
              "      <td>9.282754</td>\n",
              "      <td>7.959496</td>\n",
              "      <td>18</td>\n",
              "      <td>77.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2165</th>\n",
              "      <td>0</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>133.861111</td>\n",
              "      <td>100.500000</td>\n",
              "      <td>464.0</td>\n",
              "      <td>1822.505859</td>\n",
              "      <td>1810.708633</td>\n",
              "      <td>31.721863</td>\n",
              "      <td>2.695652</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>2.119048</td>\n",
              "      <td>20.173913</td>\n",
              "      <td>17.300000</td>\n",
              "      <td>79.239385</td>\n",
              "      <td>81.560434</td>\n",
              "      <td>200.758200</td>\n",
              "      <td>246.659266</td>\n",
              "      <td>187.961032</td>\n",
              "      <td>153.975425</td>\n",
              "      <td>135.422656</td>\n",
              "      <td>1.379211</td>\n",
              "      <td>1.725728</td>\n",
              "      <td>1.348699</td>\n",
              "      <td>1.156479</td>\n",
              "      <td>1.093426</td>\n",
              "      <td>162.220157</td>\n",
              "      <td>143.993713</td>\n",
              "      <td>161.301195</td>\n",
              "      <td>161.379540</td>\n",
              "      <td>163.145897</td>\n",
              "      <td>166.400287</td>\n",
              "      <td>0.081851</td>\n",
              "      <td>-0.146009</td>\n",
              "      <td>-0.116511</td>\n",
              "      <td>0.206536</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>37.637681</td>\n",
              "      <td>-15.939509</td>\n",
              "      <td>-72.856945</td>\n",
              "      <td>-16.437701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.688551</td>\n",
              "      <td>0.335323</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>2.740840</td>\n",
              "      <td>3.228826</td>\n",
              "      <td>3.522677</td>\n",
              "      <td>3.962003</td>\n",
              "      <td>3.852804</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.725693</td>\n",
              "      <td>3.725693</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.698142</td>\n",
              "      <td>1</td>\n",
              "      <td>0.063272</td>\n",
              "      <td>4.672829</td>\n",
              "      <td>5.484797</td>\n",
              "      <td>6.255750</td>\n",
              "      <td>7.069023</td>\n",
              "      <td>7.854381</td>\n",
              "      <td>8.666130</td>\n",
              "      <td>9.459619</td>\n",
              "      <td>10.269900</td>\n",
              "      <td>85.664256</td>\n",
              "      <td>5.739793</td>\n",
              "      <td>7.172425</td>\n",
              "      <td>8.645235</td>\n",
              "      <td>6.612336</td>\n",
              "      <td>9</td>\n",
              "      <td>53.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2166</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>530.0</td>\n",
              "      <td>2120.214214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>522.015634</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>424.042843</td>\n",
              "      <td>16.126992</td>\n",
              "      <td>632.176246</td>\n",
              "      <td>82.013631</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>104.403127</td>\n",
              "      <td>0.534768</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.621720</td>\n",
              "      <td>185.184277</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.480000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.793614</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2167 rows  242 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8884cb9-ab16-460a-ba77-c4fce2b21165')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8884cb9-ab16-460a-ba77-c4fce2b21165 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8884cb9-ab16-460a-ba77-c4fce2b21165');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      nN      ATS2dv       ATS3s  ...        AMW  WPol  Zagreb2\n",
              "0      0  532.000000  652.500000  ...   7.602582    43    147.0\n",
              "1      0  477.111111  509.601852  ...   9.428918    43    147.0\n",
              "2      2  348.000000  327.027778  ...   7.541579    27    105.0\n",
              "3      0  254.000000  393.500000  ...   7.502641    20     71.0\n",
              "4      0  518.000000  682.541667  ...   7.602582    41    145.0\n",
              "...   ..         ...         ...  ...        ...   ...      ...\n",
              "2162   1  123.000000  103.000000  ...   6.837134     9     43.0\n",
              "2163   0  128.000000  112.111111  ...   7.297202     9     43.0\n",
              "2164   1  244.000000  156.333333  ...   7.959496    18     77.0\n",
              "2165   0  139.000000  133.861111  ...   6.612336     9     53.0\n",
              "2166   0    0.000000    0.000000  ...  14.793614     0      0.0\n",
              "\n",
              "[2167 rows x 242 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW-JohcDOwIB"
      },
      "outputs": [],
      "source": [
        "y_test = sweet_test_M['Sweet']\n",
        "x_test = sweet_test_M.drop(['Sweet','Name','Taste'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIASmHdTO9jH"
      },
      "outputs": [],
      "source": [
        "y_test = y_test.to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX68VYaANmUC"
      },
      "outputs": [],
      "source": [
        "x_new_test = x_test.drop(x_test.columns[listA],\n",
        "                       axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "AioOpEyQNxqp",
        "outputId": "8e811552-1345-4ecb-e323-6624493e1de2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fa45a7ad-17d1-4521-9467-d73941cd2b9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nN</th>\n",
              "      <th>ATS2dv</th>\n",
              "      <th>ATS3s</th>\n",
              "      <th>ATS4s</th>\n",
              "      <th>ATS0Z</th>\n",
              "      <th>ATS0m</th>\n",
              "      <th>ATS3m</th>\n",
              "      <th>ATS0p</th>\n",
              "      <th>AATS0d</th>\n",
              "      <th>AATS3d</th>\n",
              "      <th>AATS4d</th>\n",
              "      <th>AATS0Z</th>\n",
              "      <th>AATS2Z</th>\n",
              "      <th>AATS0m</th>\n",
              "      <th>AATS1m</th>\n",
              "      <th>AATS0v</th>\n",
              "      <th>AATS1v</th>\n",
              "      <th>AATS2v</th>\n",
              "      <th>AATS3v</th>\n",
              "      <th>AATS4v</th>\n",
              "      <th>AATS0p</th>\n",
              "      <th>AATS1p</th>\n",
              "      <th>AATS2p</th>\n",
              "      <th>AATS3p</th>\n",
              "      <th>AATS4p</th>\n",
              "      <th>AATS0i</th>\n",
              "      <th>AATS1i</th>\n",
              "      <th>AATS3i</th>\n",
              "      <th>AATS4i</th>\n",
              "      <th>AATS5i</th>\n",
              "      <th>AATS7i</th>\n",
              "      <th>ATSC2c</th>\n",
              "      <th>ATSC3c</th>\n",
              "      <th>ATSC4c</th>\n",
              "      <th>ATSC5c</th>\n",
              "      <th>ATSC1d</th>\n",
              "      <th>ATSC0s</th>\n",
              "      <th>ATSC6Z</th>\n",
              "      <th>ATSC6m</th>\n",
              "      <th>ATSC6v</th>\n",
              "      <th>...</th>\n",
              "      <th>AMID_N</th>\n",
              "      <th>MID_O</th>\n",
              "      <th>AMID_O</th>\n",
              "      <th>MPC2</th>\n",
              "      <th>MPC3</th>\n",
              "      <th>MPC4</th>\n",
              "      <th>MPC5</th>\n",
              "      <th>MPC6</th>\n",
              "      <th>MPC7</th>\n",
              "      <th>MPC8</th>\n",
              "      <th>MPC9</th>\n",
              "      <th>TMPC10</th>\n",
              "      <th>piPC1</th>\n",
              "      <th>piPC2</th>\n",
              "      <th>piPC3</th>\n",
              "      <th>piPC4</th>\n",
              "      <th>piPC5</th>\n",
              "      <th>piPC6</th>\n",
              "      <th>piPC7</th>\n",
              "      <th>piPC8</th>\n",
              "      <th>piPC9</th>\n",
              "      <th>piPC10</th>\n",
              "      <th>TpiPC10</th>\n",
              "      <th>nRing</th>\n",
              "      <th>JGI3</th>\n",
              "      <th>MWC03</th>\n",
              "      <th>MWC04</th>\n",
              "      <th>MWC05</th>\n",
              "      <th>MWC06</th>\n",
              "      <th>MWC07</th>\n",
              "      <th>MWC08</th>\n",
              "      <th>MWC09</th>\n",
              "      <th>MWC10</th>\n",
              "      <th>TMWC10</th>\n",
              "      <th>SRW06</th>\n",
              "      <th>SRW08</th>\n",
              "      <th>SRW10</th>\n",
              "      <th>AMW</th>\n",
              "      <th>WPol</th>\n",
              "      <th>Zagreb2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>264.666667</td>\n",
              "      <td>321.879630</td>\n",
              "      <td>375.703704</td>\n",
              "      <td>1268.0</td>\n",
              "      <td>4982.059799</td>\n",
              "      <td>6262.950338</td>\n",
              "      <td>73.907442</td>\n",
              "      <td>2.614035</td>\n",
              "      <td>2.227941</td>\n",
              "      <td>2.012121</td>\n",
              "      <td>22.245614</td>\n",
              "      <td>18.788462</td>\n",
              "      <td>87.404558</td>\n",
              "      <td>83.558362</td>\n",
              "      <td>175.338892</td>\n",
              "      <td>223.299893</td>\n",
              "      <td>175.993860</td>\n",
              "      <td>149.859311</td>\n",
              "      <td>116.140023</td>\n",
              "      <td>1.296622</td>\n",
              "      <td>1.618120</td>\n",
              "      <td>1.354649</td>\n",
              "      <td>1.239443</td>\n",
              "      <td>0.938069</td>\n",
              "      <td>168.663989</td>\n",
              "      <td>151.396198</td>\n",
              "      <td>160.057177</td>\n",
              "      <td>171.281214</td>\n",
              "      <td>165.738477</td>\n",
              "      <td>163.361191</td>\n",
              "      <td>0.159971</td>\n",
              "      <td>-0.061525</td>\n",
              "      <td>-0.154919</td>\n",
              "      <td>0.311617</td>\n",
              "      <td>9.894737</td>\n",
              "      <td>77.072759</td>\n",
              "      <td>314.066482</td>\n",
              "      <td>1492.778791</td>\n",
              "      <td>2251.021667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.239219</td>\n",
              "      <td>7.359986</td>\n",
              "      <td>0.306666</td>\n",
              "      <td>34</td>\n",
              "      <td>36</td>\n",
              "      <td>42</td>\n",
              "      <td>27</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>25</td>\n",
              "      <td>318</td>\n",
              "      <td>3.258097</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.637586</td>\n",
              "      <td>3.806662</td>\n",
              "      <td>3.367296</td>\n",
              "      <td>3.332205</td>\n",
              "      <td>3.367296</td>\n",
              "      <td>3.433987</td>\n",
              "      <td>3.332205</td>\n",
              "      <td>3.258097</td>\n",
              "      <td>5.805135</td>\n",
              "      <td>1</td>\n",
              "      <td>0.113426</td>\n",
              "      <td>5.549076</td>\n",
              "      <td>6.444131</td>\n",
              "      <td>7.257708</td>\n",
              "      <td>8.172164</td>\n",
              "      <td>9.003685</td>\n",
              "      <td>9.935035</td>\n",
              "      <td>10.780060</td>\n",
              "      <td>11.725590</td>\n",
              "      <td>121.629623</td>\n",
              "      <td>6.829794</td>\n",
              "      <td>8.509363</td>\n",
              "      <td>10.256922</td>\n",
              "      <td>6.372266</td>\n",
              "      <td>27</td>\n",
              "      <td>128.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>434.000000</td>\n",
              "      <td>654.250000</td>\n",
              "      <td>643.888889</td>\n",
              "      <td>1160.0</td>\n",
              "      <td>4571.202999</td>\n",
              "      <td>8589.759775</td>\n",
              "      <td>51.212754</td>\n",
              "      <td>2.851064</td>\n",
              "      <td>2.603175</td>\n",
              "      <td>2.362319</td>\n",
              "      <td>24.680851</td>\n",
              "      <td>21.144578</td>\n",
              "      <td>97.259638</td>\n",
              "      <td>90.798347</td>\n",
              "      <td>174.649175</td>\n",
              "      <td>226.166478</td>\n",
              "      <td>191.396631</td>\n",
              "      <td>152.142943</td>\n",
              "      <td>138.329306</td>\n",
              "      <td>1.089633</td>\n",
              "      <td>1.421628</td>\n",
              "      <td>1.231107</td>\n",
              "      <td>0.994737</td>\n",
              "      <td>0.924393</td>\n",
              "      <td>170.202555</td>\n",
              "      <td>153.721352</td>\n",
              "      <td>166.302447</td>\n",
              "      <td>168.816659</td>\n",
              "      <td>168.959562</td>\n",
              "      <td>169.501042</td>\n",
              "      <td>-0.662971</td>\n",
              "      <td>1.107631</td>\n",
              "      <td>-0.544458</td>\n",
              "      <td>0.071001</td>\n",
              "      <td>10.191489</td>\n",
              "      <td>176.053191</td>\n",
              "      <td>-24.065188</td>\n",
              "      <td>-117.103836</td>\n",
              "      <td>-213.618083</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.739869</td>\n",
              "      <td>0.858255</td>\n",
              "      <td>32</td>\n",
              "      <td>42</td>\n",
              "      <td>46</td>\n",
              "      <td>53</td>\n",
              "      <td>54</td>\n",
              "      <td>50</td>\n",
              "      <td>46</td>\n",
              "      <td>39</td>\n",
              "      <td>433</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>3.496508</td>\n",
              "      <td>3.761200</td>\n",
              "      <td>3.850148</td>\n",
              "      <td>3.988984</td>\n",
              "      <td>4.007333</td>\n",
              "      <td>3.931826</td>\n",
              "      <td>3.850148</td>\n",
              "      <td>3.688879</td>\n",
              "      <td>3.258097</td>\n",
              "      <td>6.073045</td>\n",
              "      <td>1</td>\n",
              "      <td>0.059295</td>\n",
              "      <td>5.556828</td>\n",
              "      <td>6.424869</td>\n",
              "      <td>7.295056</td>\n",
              "      <td>8.170469</td>\n",
              "      <td>9.046762</td>\n",
              "      <td>9.925200</td>\n",
              "      <td>10.803954</td>\n",
              "      <td>11.683857</td>\n",
              "      <td>119.616526</td>\n",
              "      <td>6.688355</td>\n",
              "      <td>8.303752</td>\n",
              "      <td>9.968198</td>\n",
              "      <td>7.321955</td>\n",
              "      <td>39</td>\n",
              "      <td>129.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>428.000000</td>\n",
              "      <td>676.361111</td>\n",
              "      <td>663.638889</td>\n",
              "      <td>1160.0</td>\n",
              "      <td>4571.202999</td>\n",
              "      <td>8468.693766</td>\n",
              "      <td>51.212754</td>\n",
              "      <td>2.851064</td>\n",
              "      <td>2.492063</td>\n",
              "      <td>2.137681</td>\n",
              "      <td>24.680851</td>\n",
              "      <td>21.144578</td>\n",
              "      <td>97.259638</td>\n",
              "      <td>90.798347</td>\n",
              "      <td>174.649175</td>\n",
              "      <td>226.166478</td>\n",
              "      <td>191.396631</td>\n",
              "      <td>150.356217</td>\n",
              "      <td>129.443088</td>\n",
              "      <td>1.089633</td>\n",
              "      <td>1.421628</td>\n",
              "      <td>1.231107</td>\n",
              "      <td>0.986749</td>\n",
              "      <td>0.878757</td>\n",
              "      <td>170.202555</td>\n",
              "      <td>153.721352</td>\n",
              "      <td>166.259059</td>\n",
              "      <td>170.120488</td>\n",
              "      <td>171.211079</td>\n",
              "      <td>170.466790</td>\n",
              "      <td>-0.662283</td>\n",
              "      <td>1.126649</td>\n",
              "      <td>-0.537403</td>\n",
              "      <td>0.032920</td>\n",
              "      <td>9.191489</td>\n",
              "      <td>176.053191</td>\n",
              "      <td>15.739701</td>\n",
              "      <td>73.310736</td>\n",
              "      <td>47.808010</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.723213</td>\n",
              "      <td>0.857531</td>\n",
              "      <td>32</td>\n",
              "      <td>41</td>\n",
              "      <td>42</td>\n",
              "      <td>45</td>\n",
              "      <td>43</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>392</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>3.496508</td>\n",
              "      <td>3.737670</td>\n",
              "      <td>3.761200</td>\n",
              "      <td>3.828641</td>\n",
              "      <td>3.784190</td>\n",
              "      <td>3.663562</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.526361</td>\n",
              "      <td>5.973810</td>\n",
              "      <td>1</td>\n",
              "      <td>0.060855</td>\n",
              "      <td>5.549076</td>\n",
              "      <td>6.405228</td>\n",
              "      <td>7.261927</td>\n",
              "      <td>8.122371</td>\n",
              "      <td>8.983314</td>\n",
              "      <td>9.846017</td>\n",
              "      <td>10.709137</td>\n",
              "      <td>11.573409</td>\n",
              "      <td>119.160011</td>\n",
              "      <td>6.680855</td>\n",
              "      <td>8.283747</td>\n",
              "      <td>9.932901</td>\n",
              "      <td>7.321955</td>\n",
              "      <td>38</td>\n",
              "      <td>128.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>219.916667</td>\n",
              "      <td>185.666667</td>\n",
              "      <td>410.0</td>\n",
              "      <td>1611.089128</td>\n",
              "      <td>1966.301776</td>\n",
              "      <td>18.174545</td>\n",
              "      <td>2.222222</td>\n",
              "      <td>1.743590</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>22.777778</td>\n",
              "      <td>17.214286</td>\n",
              "      <td>89.504952</td>\n",
              "      <td>78.741107</td>\n",
              "      <td>159.470453</td>\n",
              "      <td>205.761349</td>\n",
              "      <td>164.089267</td>\n",
              "      <td>119.448125</td>\n",
              "      <td>92.036166</td>\n",
              "      <td>1.009697</td>\n",
              "      <td>1.326141</td>\n",
              "      <td>1.109793</td>\n",
              "      <td>0.836084</td>\n",
              "      <td>0.684056</td>\n",
              "      <td>172.119949</td>\n",
              "      <td>156.072281</td>\n",
              "      <td>170.501551</td>\n",
              "      <td>176.216465</td>\n",
              "      <td>182.379170</td>\n",
              "      <td>184.917652</td>\n",
              "      <td>-0.219335</td>\n",
              "      <td>0.378624</td>\n",
              "      <td>-0.175020</td>\n",
              "      <td>-0.012729</td>\n",
              "      <td>1.888889</td>\n",
              "      <td>74.641975</td>\n",
              "      <td>19.555556</td>\n",
              "      <td>93.749126</td>\n",
              "      <td>132.198175</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.798694</td>\n",
              "      <td>0.849837</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>1.609438</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046875</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.875197</td>\n",
              "      <td>5.609472</td>\n",
              "      <td>6.347389</td>\n",
              "      <td>7.085901</td>\n",
              "      <td>7.825245</td>\n",
              "      <td>8.564649</td>\n",
              "      <td>9.304286</td>\n",
              "      <td>72.189262</td>\n",
              "      <td>5.209486</td>\n",
              "      <td>6.642487</td>\n",
              "      <td>8.103192</td>\n",
              "      <td>6.780995</td>\n",
              "      <td>8</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1189.000000</td>\n",
              "      <td>1302.611111</td>\n",
              "      <td>1463.708333</td>\n",
              "      <td>2580.0</td>\n",
              "      <td>10150.424456</td>\n",
              "      <td>24297.097283</td>\n",
              "      <td>144.232646</td>\n",
              "      <td>3.293103</td>\n",
              "      <td>3.174263</td>\n",
              "      <td>2.707368</td>\n",
              "      <td>22.241379</td>\n",
              "      <td>20.792373</td>\n",
              "      <td>87.503659</td>\n",
              "      <td>89.054234</td>\n",
              "      <td>188.393973</td>\n",
              "      <td>244.945856</td>\n",
              "      <td>211.245372</td>\n",
              "      <td>178.576482</td>\n",
              "      <td>150.884097</td>\n",
              "      <td>1.243385</td>\n",
              "      <td>1.627610</td>\n",
              "      <td>1.433857</td>\n",
              "      <td>1.251932</td>\n",
              "      <td>1.107180</td>\n",
              "      <td>165.960067</td>\n",
              "      <td>147.856207</td>\n",
              "      <td>157.989833</td>\n",
              "      <td>161.973644</td>\n",
              "      <td>164.175074</td>\n",
              "      <td>162.077837</td>\n",
              "      <td>-0.793969</td>\n",
              "      <td>1.616018</td>\n",
              "      <td>-0.948455</td>\n",
              "      <td>0.252029</td>\n",
              "      <td>37.854935</td>\n",
              "      <td>284.355364</td>\n",
              "      <td>478.282996</td>\n",
              "      <td>2270.460414</td>\n",
              "      <td>2757.360945</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.463807</td>\n",
              "      <td>0.597568</td>\n",
              "      <td>99</td>\n",
              "      <td>146</td>\n",
              "      <td>199</td>\n",
              "      <td>271</td>\n",
              "      <td>347</td>\n",
              "      <td>431</td>\n",
              "      <td>544</td>\n",
              "      <td>691</td>\n",
              "      <td>3670</td>\n",
              "      <td>4.174387</td>\n",
              "      <td>4.644391</td>\n",
              "      <td>5.036953</td>\n",
              "      <td>5.342334</td>\n",
              "      <td>5.659482</td>\n",
              "      <td>5.908083</td>\n",
              "      <td>6.146329</td>\n",
              "      <td>6.378426</td>\n",
              "      <td>6.626718</td>\n",
              "      <td>6.797940</td>\n",
              "      <td>8.279190</td>\n",
              "      <td>7</td>\n",
              "      <td>0.065662</td>\n",
              "      <td>6.700731</td>\n",
              "      <td>7.653969</td>\n",
              "      <td>8.595080</td>\n",
              "      <td>9.554852</td>\n",
              "      <td>10.503395</td>\n",
              "      <td>11.468294</td>\n",
              "      <td>12.421914</td>\n",
              "      <td>13.391032</td>\n",
              "      <td>204.066919</td>\n",
              "      <td>7.893945</td>\n",
              "      <td>9.631219</td>\n",
              "      <td>11.421851</td>\n",
              "      <td>6.934293</td>\n",
              "      <td>123</td>\n",
              "      <td>406.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0</td>\n",
              "      <td>624.000000</td>\n",
              "      <td>443.500000</td>\n",
              "      <td>375.611111</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>3967.930590</td>\n",
              "      <td>8249.957008</td>\n",
              "      <td>51.671283</td>\n",
              "      <td>4.176471</td>\n",
              "      <td>3.894118</td>\n",
              "      <td>3.446809</td>\n",
              "      <td>29.411765</td>\n",
              "      <td>29.459016</td>\n",
              "      <td>116.703841</td>\n",
              "      <td>113.596930</td>\n",
              "      <td>242.367468</td>\n",
              "      <td>289.569200</td>\n",
              "      <td>277.713676</td>\n",
              "      <td>233.015563</td>\n",
              "      <td>196.601563</td>\n",
              "      <td>1.519744</td>\n",
              "      <td>1.814733</td>\n",
              "      <td>1.743045</td>\n",
              "      <td>1.481888</td>\n",
              "      <td>1.313979</td>\n",
              "      <td>159.384887</td>\n",
              "      <td>146.123753</td>\n",
              "      <td>152.777264</td>\n",
              "      <td>156.625280</td>\n",
              "      <td>157.196804</td>\n",
              "      <td>166.617489</td>\n",
              "      <td>-0.292867</td>\n",
              "      <td>0.954611</td>\n",
              "      <td>-0.445755</td>\n",
              "      <td>-0.510073</td>\n",
              "      <td>10.622837</td>\n",
              "      <td>97.434845</td>\n",
              "      <td>74.820069</td>\n",
              "      <td>339.920780</td>\n",
              "      <td>-63.761998</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.023861</td>\n",
              "      <td>0.591994</td>\n",
              "      <td>40</td>\n",
              "      <td>58</td>\n",
              "      <td>83</td>\n",
              "      <td>117</td>\n",
              "      <td>143</td>\n",
              "      <td>176</td>\n",
              "      <td>205</td>\n",
              "      <td>212</td>\n",
              "      <td>1296</td>\n",
              "      <td>3.465736</td>\n",
              "      <td>4.158883</td>\n",
              "      <td>4.753590</td>\n",
              "      <td>5.343530</td>\n",
              "      <td>5.930586</td>\n",
              "      <td>6.239301</td>\n",
              "      <td>6.609981</td>\n",
              "      <td>7.006667</td>\n",
              "      <td>7.293188</td>\n",
              "      <td>7.589012</td>\n",
              "      <td>8.797272</td>\n",
              "      <td>4</td>\n",
              "      <td>0.067077</td>\n",
              "      <td>5.789960</td>\n",
              "      <td>6.741701</td>\n",
              "      <td>7.679251</td>\n",
              "      <td>8.636752</td>\n",
              "      <td>9.583351</td>\n",
              "      <td>10.543366</td>\n",
              "      <td>11.494711</td>\n",
              "      <td>12.455885</td>\n",
              "      <td>124.800175</td>\n",
              "      <td>6.976348</td>\n",
              "      <td>8.697346</td>\n",
              "      <td>10.469965</td>\n",
              "      <td>8.942891</td>\n",
              "      <td>44</td>\n",
              "      <td>163.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0</td>\n",
              "      <td>888.000000</td>\n",
              "      <td>882.000000</td>\n",
              "      <td>984.916667</td>\n",
              "      <td>1902.0</td>\n",
              "      <td>7513.229457</td>\n",
              "      <td>14646.475593</td>\n",
              "      <td>99.421995</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.010101</td>\n",
              "      <td>2.703704</td>\n",
              "      <td>25.360000</td>\n",
              "      <td>23.250000</td>\n",
              "      <td>100.176393</td>\n",
              "      <td>98.174860</td>\n",
              "      <td>206.950327</td>\n",
              "      <td>257.270623</td>\n",
              "      <td>222.407481</td>\n",
              "      <td>181.278366</td>\n",
              "      <td>161.255642</td>\n",
              "      <td>1.325627</td>\n",
              "      <td>1.657321</td>\n",
              "      <td>1.450887</td>\n",
              "      <td>1.196369</td>\n",
              "      <td>1.094295</td>\n",
              "      <td>164.092877</td>\n",
              "      <td>148.096863</td>\n",
              "      <td>160.321959</td>\n",
              "      <td>162.815138</td>\n",
              "      <td>165.029645</td>\n",
              "      <td>160.623030</td>\n",
              "      <td>-0.445318</td>\n",
              "      <td>0.276465</td>\n",
              "      <td>0.826667</td>\n",
              "      <td>-1.015005</td>\n",
              "      <td>15.364800</td>\n",
              "      <td>217.888889</td>\n",
              "      <td>94.528889</td>\n",
              "      <td>450.127543</td>\n",
              "      <td>656.856109</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.901187</td>\n",
              "      <td>0.631736</td>\n",
              "      <td>64</td>\n",
              "      <td>85</td>\n",
              "      <td>106</td>\n",
              "      <td>130</td>\n",
              "      <td>144</td>\n",
              "      <td>155</td>\n",
              "      <td>182</td>\n",
              "      <td>210</td>\n",
              "      <td>1395</td>\n",
              "      <td>3.951244</td>\n",
              "      <td>4.477337</td>\n",
              "      <td>4.930870</td>\n",
              "      <td>5.358942</td>\n",
              "      <td>5.757718</td>\n",
              "      <td>5.883845</td>\n",
              "      <td>5.989588</td>\n",
              "      <td>6.298834</td>\n",
              "      <td>6.549293</td>\n",
              "      <td>6.845946</td>\n",
              "      <td>8.237694</td>\n",
              "      <td>4</td>\n",
              "      <td>0.058219</td>\n",
              "      <td>6.244167</td>\n",
              "      <td>7.134891</td>\n",
              "      <td>8.012018</td>\n",
              "      <td>8.905851</td>\n",
              "      <td>9.788245</td>\n",
              "      <td>10.684440</td>\n",
              "      <td>11.570147</td>\n",
              "      <td>12.468218</td>\n",
              "      <td>165.187873</td>\n",
              "      <td>7.389564</td>\n",
              "      <td>9.026538</td>\n",
              "      <td>10.711057</td>\n",
              "      <td>7.762598</td>\n",
              "      <td>73</td>\n",
              "      <td>257.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>0</td>\n",
              "      <td>1232.000000</td>\n",
              "      <td>1379.402778</td>\n",
              "      <td>1485.451389</td>\n",
              "      <td>2780.0</td>\n",
              "      <td>10916.498070</td>\n",
              "      <td>25526.984494</td>\n",
              "      <td>168.447097</td>\n",
              "      <td>3.179104</td>\n",
              "      <td>3.016317</td>\n",
              "      <td>2.595463</td>\n",
              "      <td>20.746269</td>\n",
              "      <td>19.458484</td>\n",
              "      <td>81.466404</td>\n",
              "      <td>85.189437</td>\n",
              "      <td>186.380100</td>\n",
              "      <td>243.193604</td>\n",
              "      <td>203.839236</td>\n",
              "      <td>171.607948</td>\n",
              "      <td>147.581898</td>\n",
              "      <td>1.257068</td>\n",
              "      <td>1.649722</td>\n",
              "      <td>1.413913</td>\n",
              "      <td>1.228548</td>\n",
              "      <td>1.107113</td>\n",
              "      <td>165.466335</td>\n",
              "      <td>146.804006</td>\n",
              "      <td>158.644010</td>\n",
              "      <td>161.943831</td>\n",
              "      <td>163.959398</td>\n",
              "      <td>161.257464</td>\n",
              "      <td>-0.738217</td>\n",
              "      <td>1.387151</td>\n",
              "      <td>-0.824367</td>\n",
              "      <td>0.209871</td>\n",
              "      <td>39.714413</td>\n",
              "      <td>257.034204</td>\n",
              "      <td>160.862553</td>\n",
              "      <td>786.583802</td>\n",
              "      <td>1673.961801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32.032179</td>\n",
              "      <td>0.516648</td>\n",
              "      <td>108</td>\n",
              "      <td>156</td>\n",
              "      <td>207</td>\n",
              "      <td>277</td>\n",
              "      <td>337</td>\n",
              "      <td>408</td>\n",
              "      <td>515</td>\n",
              "      <td>638</td>\n",
              "      <td>3536</td>\n",
              "      <td>4.276666</td>\n",
              "      <td>4.736198</td>\n",
              "      <td>5.129899</td>\n",
              "      <td>5.455321</td>\n",
              "      <td>5.777652</td>\n",
              "      <td>6.023448</td>\n",
              "      <td>6.222576</td>\n",
              "      <td>6.492240</td>\n",
              "      <td>6.732211</td>\n",
              "      <td>6.924612</td>\n",
              "      <td>8.388905</td>\n",
              "      <td>8</td>\n",
              "      <td>0.058707</td>\n",
              "      <td>6.783325</td>\n",
              "      <td>7.716461</td>\n",
              "      <td>8.641709</td>\n",
              "      <td>9.578380</td>\n",
              "      <td>10.509469</td>\n",
              "      <td>11.449549</td>\n",
              "      <td>12.384758</td>\n",
              "      <td>13.328009</td>\n",
              "      <td>217.263779</td>\n",
              "      <td>7.959625</td>\n",
              "      <td>9.666435</td>\n",
              "      <td>11.424193</td>\n",
              "      <td>6.600574</td>\n",
              "      <td>130</td>\n",
              "      <td>441.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>1</td>\n",
              "      <td>313.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1116.0</td>\n",
              "      <td>4536.565946</td>\n",
              "      <td>4095.105547</td>\n",
              "      <td>1887.903189</td>\n",
              "      <td>3.789474</td>\n",
              "      <td>3.222222</td>\n",
              "      <td>2.517241</td>\n",
              "      <td>58.736842</td>\n",
              "      <td>36.866667</td>\n",
              "      <td>238.766629</td>\n",
              "      <td>175.379072</td>\n",
              "      <td>643.641543</td>\n",
              "      <td>327.497999</td>\n",
              "      <td>284.005017</td>\n",
              "      <td>230.107412</td>\n",
              "      <td>189.305687</td>\n",
              "      <td>99.363326</td>\n",
              "      <td>3.646473</td>\n",
              "      <td>1.992587</td>\n",
              "      <td>1.596274</td>\n",
              "      <td>1.288434</td>\n",
              "      <td>152.149026</td>\n",
              "      <td>138.058750</td>\n",
              "      <td>152.721268</td>\n",
              "      <td>161.694523</td>\n",
              "      <td>173.412139</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.789474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>93.975467</td>\n",
              "      <td>466.566813</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>35</td>\n",
              "      <td>37</td>\n",
              "      <td>27</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>227</td>\n",
              "      <td>2.995732</td>\n",
              "      <td>3.676301</td>\n",
              "      <td>4.154969</td>\n",
              "      <td>4.735101</td>\n",
              "      <td>5.146404</td>\n",
              "      <td>5.072827</td>\n",
              "      <td>5.319804</td>\n",
              "      <td>5.182836</td>\n",
              "      <td>5.290474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.051450</td>\n",
              "      <td>2</td>\n",
              "      <td>0.110340</td>\n",
              "      <td>5.068904</td>\n",
              "      <td>5.998937</td>\n",
              "      <td>6.886532</td>\n",
              "      <td>7.815611</td>\n",
              "      <td>8.711608</td>\n",
              "      <td>9.637371</td>\n",
              "      <td>10.538025</td>\n",
              "      <td>11.460885</td>\n",
              "      <td>96.322565</td>\n",
              "      <td>6.251904</td>\n",
              "      <td>7.918265</td>\n",
              "      <td>9.630169</td>\n",
              "      <td>11.735292</td>\n",
              "      <td>18</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>0</td>\n",
              "      <td>691.000000</td>\n",
              "      <td>878.208333</td>\n",
              "      <td>966.486111</td>\n",
              "      <td>1894.0</td>\n",
              "      <td>7411.887956</td>\n",
              "      <td>16562.874924</td>\n",
              "      <td>129.187884</td>\n",
              "      <td>2.980392</td>\n",
              "      <td>3.022293</td>\n",
              "      <td>2.511312</td>\n",
              "      <td>18.568627</td>\n",
              "      <td>17.945813</td>\n",
              "      <td>72.665568</td>\n",
              "      <td>76.510883</td>\n",
              "      <td>182.092801</td>\n",
              "      <td>238.428751</td>\n",
              "      <td>202.929059</td>\n",
              "      <td>179.413977</td>\n",
              "      <td>147.494620</td>\n",
              "      <td>1.266548</td>\n",
              "      <td>1.678534</td>\n",
              "      <td>1.458997</td>\n",
              "      <td>1.342982</td>\n",
              "      <td>1.167861</td>\n",
              "      <td>165.020469</td>\n",
              "      <td>145.950967</td>\n",
              "      <td>154.622192</td>\n",
              "      <td>159.688818</td>\n",
              "      <td>161.688365</td>\n",
              "      <td>161.974403</td>\n",
              "      <td>0.042240</td>\n",
              "      <td>0.256828</td>\n",
              "      <td>-0.278276</td>\n",
              "      <td>0.042584</td>\n",
              "      <td>34.093426</td>\n",
              "      <td>178.163739</td>\n",
              "      <td>305.111111</td>\n",
              "      <td>1463.319545</td>\n",
              "      <td>1997.089896</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.208659</td>\n",
              "      <td>0.368379</td>\n",
              "      <td>76</td>\n",
              "      <td>102</td>\n",
              "      <td>139</td>\n",
              "      <td>189</td>\n",
              "      <td>247</td>\n",
              "      <td>310</td>\n",
              "      <td>385</td>\n",
              "      <td>464</td>\n",
              "      <td>2541</td>\n",
              "      <td>3.931826</td>\n",
              "      <td>4.418841</td>\n",
              "      <td>4.709530</td>\n",
              "      <td>5.023881</td>\n",
              "      <td>5.323010</td>\n",
              "      <td>5.613128</td>\n",
              "      <td>5.849325</td>\n",
              "      <td>6.061457</td>\n",
              "      <td>6.278521</td>\n",
              "      <td>6.464588</td>\n",
              "      <td>7.959276</td>\n",
              "      <td>4</td>\n",
              "      <td>0.069208</td>\n",
              "      <td>6.401917</td>\n",
              "      <td>7.362011</td>\n",
              "      <td>8.291797</td>\n",
              "      <td>9.261699</td>\n",
              "      <td>10.212405</td>\n",
              "      <td>11.189644</td>\n",
              "      <td>12.153974</td>\n",
              "      <td>13.136469</td>\n",
              "      <td>174.519304</td>\n",
              "      <td>7.614312</td>\n",
              "      <td>9.341982</td>\n",
              "      <td>11.134370</td>\n",
              "      <td>6.102040</td>\n",
              "      <td>88</td>\n",
              "      <td>301.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153 rows  242 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa45a7ad-17d1-4521-9467-d73941cd2b9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa45a7ad-17d1-4521-9467-d73941cd2b9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa45a7ad-17d1-4521-9467-d73941cd2b9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     nN       ATS2dv        ATS3s  ...        AMW  WPol  Zagreb2\n",
              "0     3   264.666667   321.879630  ...   6.372266    27    128.0\n",
              "1     0   434.000000   654.250000  ...   7.321955    39    129.0\n",
              "2     0   428.000000   676.361111  ...   7.321955    38    128.0\n",
              "3     0    92.000000   219.916667  ...   6.780995     8     31.0\n",
              "4     0  1189.000000  1302.611111  ...   6.934293   123    406.0\n",
              "..   ..          ...          ...  ...        ...   ...      ...\n",
              "148   0   624.000000   443.500000  ...   8.942891    44    163.0\n",
              "149   0   888.000000   882.000000  ...   7.762598    73    257.0\n",
              "150   0  1232.000000  1379.402778  ...   6.600574   130    441.0\n",
              "151   1   313.333333     0.000000  ...  11.735292    18     79.0\n",
              "152   0   691.000000   878.208333  ...   6.102040    88    301.0\n",
              "\n",
              "[153 rows x 242 columns]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_new_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "A0TbLmaVPCY-",
        "outputId": "c8cd8753-4ed4-4034-facf-031522e2ef3d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-34d8988c-f989-499f-a162-924429699277\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nN</th>\n",
              "      <th>ATS2dv</th>\n",
              "      <th>ATS3s</th>\n",
              "      <th>ATS4s</th>\n",
              "      <th>ATS0Z</th>\n",
              "      <th>ATS0m</th>\n",
              "      <th>ATS3m</th>\n",
              "      <th>ATS0p</th>\n",
              "      <th>AATS0d</th>\n",
              "      <th>AATS3d</th>\n",
              "      <th>AATS4d</th>\n",
              "      <th>AATS0Z</th>\n",
              "      <th>AATS2Z</th>\n",
              "      <th>AATS0m</th>\n",
              "      <th>AATS1m</th>\n",
              "      <th>AATS0v</th>\n",
              "      <th>AATS1v</th>\n",
              "      <th>AATS2v</th>\n",
              "      <th>AATS3v</th>\n",
              "      <th>AATS4v</th>\n",
              "      <th>AATS0p</th>\n",
              "      <th>AATS1p</th>\n",
              "      <th>AATS2p</th>\n",
              "      <th>AATS3p</th>\n",
              "      <th>AATS4p</th>\n",
              "      <th>AATS0i</th>\n",
              "      <th>AATS1i</th>\n",
              "      <th>AATS3i</th>\n",
              "      <th>AATS4i</th>\n",
              "      <th>AATS5i</th>\n",
              "      <th>AATS7i</th>\n",
              "      <th>ATSC2c</th>\n",
              "      <th>ATSC3c</th>\n",
              "      <th>ATSC4c</th>\n",
              "      <th>ATSC5c</th>\n",
              "      <th>ATSC1d</th>\n",
              "      <th>ATSC0s</th>\n",
              "      <th>ATSC6Z</th>\n",
              "      <th>ATSC6m</th>\n",
              "      <th>ATSC6v</th>\n",
              "      <th>...</th>\n",
              "      <th>AMID_N</th>\n",
              "      <th>MID_O</th>\n",
              "      <th>AMID_O</th>\n",
              "      <th>MPC2</th>\n",
              "      <th>MPC3</th>\n",
              "      <th>MPC4</th>\n",
              "      <th>MPC5</th>\n",
              "      <th>MPC6</th>\n",
              "      <th>MPC7</th>\n",
              "      <th>MPC8</th>\n",
              "      <th>MPC9</th>\n",
              "      <th>TMPC10</th>\n",
              "      <th>piPC1</th>\n",
              "      <th>piPC2</th>\n",
              "      <th>piPC3</th>\n",
              "      <th>piPC4</th>\n",
              "      <th>piPC5</th>\n",
              "      <th>piPC6</th>\n",
              "      <th>piPC7</th>\n",
              "      <th>piPC8</th>\n",
              "      <th>piPC9</th>\n",
              "      <th>piPC10</th>\n",
              "      <th>TpiPC10</th>\n",
              "      <th>nRing</th>\n",
              "      <th>JGI3</th>\n",
              "      <th>MWC03</th>\n",
              "      <th>MWC04</th>\n",
              "      <th>MWC05</th>\n",
              "      <th>MWC06</th>\n",
              "      <th>MWC07</th>\n",
              "      <th>MWC08</th>\n",
              "      <th>MWC09</th>\n",
              "      <th>MWC10</th>\n",
              "      <th>TMWC10</th>\n",
              "      <th>SRW06</th>\n",
              "      <th>SRW08</th>\n",
              "      <th>SRW10</th>\n",
              "      <th>AMW</th>\n",
              "      <th>WPol</th>\n",
              "      <th>Zagreb2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>532.000000</td>\n",
              "      <td>652.500000</td>\n",
              "      <td>629.083333</td>\n",
              "      <td>1158.0</td>\n",
              "      <td>4569.170871</td>\n",
              "      <td>9413.865359</td>\n",
              "      <td>50.323528</td>\n",
              "      <td>3.155556</td>\n",
              "      <td>2.830645</td>\n",
              "      <td>2.541353</td>\n",
              "      <td>25.733333</td>\n",
              "      <td>23.192771</td>\n",
              "      <td>101.537130</td>\n",
              "      <td>96.335918</td>\n",
              "      <td>181.029861</td>\n",
              "      <td>233.387037</td>\n",
              "      <td>201.265826</td>\n",
              "      <td>160.826674</td>\n",
              "      <td>144.999343</td>\n",
              "      <td>1.118301</td>\n",
              "      <td>1.445816</td>\n",
              "      <td>1.258039</td>\n",
              "      <td>1.017477</td>\n",
              "      <td>0.952669</td>\n",
              "      <td>169.548550</td>\n",
              "      <td>153.042175</td>\n",
              "      <td>166.058828</td>\n",
              "      <td>167.454386</td>\n",
              "      <td>169.891248</td>\n",
              "      <td>168.161237</td>\n",
              "      <td>-0.652482</td>\n",
              "      <td>1.204605</td>\n",
              "      <td>-0.670753</td>\n",
              "      <td>0.228861</td>\n",
              "      <td>12.975309</td>\n",
              "      <td>160.554938</td>\n",
              "      <td>-5.453827</td>\n",
              "      <td>-19.969966</td>\n",
              "      <td>125.602063</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.160229</td>\n",
              "      <td>0.876532</td>\n",
              "      <td>36</td>\n",
              "      <td>51</td>\n",
              "      <td>62</td>\n",
              "      <td>73</td>\n",
              "      <td>74</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>68</td>\n",
              "      <td>608</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.951244</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.304065</td>\n",
              "      <td>4.317488</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.234107</td>\n",
              "      <td>4.060443</td>\n",
              "      <td>6.411818</td>\n",
              "      <td>2</td>\n",
              "      <td>0.082526</td>\n",
              "      <td>5.686975</td>\n",
              "      <td>6.602588</td>\n",
              "      <td>7.513709</td>\n",
              "      <td>8.434464</td>\n",
              "      <td>9.350189</td>\n",
              "      <td>10.272738</td>\n",
              "      <td>11.190528</td>\n",
              "      <td>12.113908</td>\n",
              "      <td>122.960890</td>\n",
              "      <td>6.849066</td>\n",
              "      <td>8.525360</td>\n",
              "      <td>10.247042</td>\n",
              "      <td>7.602582</td>\n",
              "      <td>43</td>\n",
              "      <td>147.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>477.111111</td>\n",
              "      <td>509.601852</td>\n",
              "      <td>424.106996</td>\n",
              "      <td>1830.0</td>\n",
              "      <td>7568.326176</td>\n",
              "      <td>11909.663100</td>\n",
              "      <td>61.317277</td>\n",
              "      <td>3.309524</td>\n",
              "      <td>2.895652</td>\n",
              "      <td>2.603306</td>\n",
              "      <td>43.571429</td>\n",
              "      <td>27.100000</td>\n",
              "      <td>180.198242</td>\n",
              "      <td>118.231375</td>\n",
              "      <td>212.281739</td>\n",
              "      <td>255.059582</td>\n",
              "      <td>215.170710</td>\n",
              "      <td>179.685807</td>\n",
              "      <td>165.227306</td>\n",
              "      <td>1.459935</td>\n",
              "      <td>1.669930</td>\n",
              "      <td>1.435949</td>\n",
              "      <td>1.191106</td>\n",
              "      <td>1.173424</td>\n",
              "      <td>167.215625</td>\n",
              "      <td>150.288731</td>\n",
              "      <td>164.818253</td>\n",
              "      <td>165.667994</td>\n",
              "      <td>168.181859</td>\n",
              "      <td>166.072550</td>\n",
              "      <td>-0.461902</td>\n",
              "      <td>0.767067</td>\n",
              "      <td>-0.461966</td>\n",
              "      <td>0.177657</td>\n",
              "      <td>10.282880</td>\n",
              "      <td>111.512642</td>\n",
              "      <td>-8.217687</td>\n",
              "      <td>-35.280625</td>\n",
              "      <td>-9.450500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.925656</td>\n",
              "      <td>0.648942</td>\n",
              "      <td>36</td>\n",
              "      <td>51</td>\n",
              "      <td>62</td>\n",
              "      <td>73</td>\n",
              "      <td>74</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>68</td>\n",
              "      <td>608</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.951244</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.304065</td>\n",
              "      <td>4.317488</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.234107</td>\n",
              "      <td>4.060443</td>\n",
              "      <td>6.411818</td>\n",
              "      <td>2</td>\n",
              "      <td>0.082526</td>\n",
              "      <td>5.686975</td>\n",
              "      <td>6.602588</td>\n",
              "      <td>7.513709</td>\n",
              "      <td>8.434464</td>\n",
              "      <td>9.350189</td>\n",
              "      <td>10.272738</td>\n",
              "      <td>11.190528</td>\n",
              "      <td>12.113908</td>\n",
              "      <td>122.960890</td>\n",
              "      <td>6.849066</td>\n",
              "      <td>8.525360</td>\n",
              "      <td>10.247042</td>\n",
              "      <td>9.428918</td>\n",
              "      <td>43</td>\n",
              "      <td>147.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>327.027778</td>\n",
              "      <td>372.666667</td>\n",
              "      <td>940.0</td>\n",
              "      <td>3710.218949</td>\n",
              "      <td>5232.341659</td>\n",
              "      <td>52.683652</td>\n",
              "      <td>2.923077</td>\n",
              "      <td>2.697674</td>\n",
              "      <td>2.467391</td>\n",
              "      <td>24.102564</td>\n",
              "      <td>20.676923</td>\n",
              "      <td>95.133819</td>\n",
              "      <td>92.739769</td>\n",
              "      <td>206.598109</td>\n",
              "      <td>251.559891</td>\n",
              "      <td>206.377537</td>\n",
              "      <td>173.668198</td>\n",
              "      <td>157.736959</td>\n",
              "      <td>1.350863</td>\n",
              "      <td>1.675350</td>\n",
              "      <td>1.429224</td>\n",
              "      <td>1.235235</td>\n",
              "      <td>1.107106</td>\n",
              "      <td>165.471161</td>\n",
              "      <td>150.112578</td>\n",
              "      <td>161.777305</td>\n",
              "      <td>165.699596</td>\n",
              "      <td>164.954150</td>\n",
              "      <td>163.395314</td>\n",
              "      <td>0.145983</td>\n",
              "      <td>0.338385</td>\n",
              "      <td>-0.698717</td>\n",
              "      <td>0.537398</td>\n",
              "      <td>4.692308</td>\n",
              "      <td>117.287749</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>316.956515</td>\n",
              "      <td>387.214257</td>\n",
              "      <td>...</td>\n",
              "      <td>0.178784</td>\n",
              "      <td>8.731863</td>\n",
              "      <td>0.415803</td>\n",
              "      <td>27</td>\n",
              "      <td>30</td>\n",
              "      <td>33</td>\n",
              "      <td>37</td>\n",
              "      <td>32</td>\n",
              "      <td>31</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>301</td>\n",
              "      <td>3.332205</td>\n",
              "      <td>3.749504</td>\n",
              "      <td>4.020877</td>\n",
              "      <td>4.312476</td>\n",
              "      <td>4.722398</td>\n",
              "      <td>4.452165</td>\n",
              "      <td>4.599529</td>\n",
              "      <td>4.819273</td>\n",
              "      <td>4.884694</td>\n",
              "      <td>4.627421</td>\n",
              "      <td>6.767271</td>\n",
              "      <td>1</td>\n",
              "      <td>0.043981</td>\n",
              "      <td>5.351858</td>\n",
              "      <td>6.175867</td>\n",
              "      <td>6.978214</td>\n",
              "      <td>7.805882</td>\n",
              "      <td>8.618485</td>\n",
              "      <td>9.447229</td>\n",
              "      <td>10.264966</td>\n",
              "      <td>11.093995</td>\n",
              "      <td>112.311208</td>\n",
              "      <td>6.447306</td>\n",
              "      <td>7.951207</td>\n",
              "      <td>9.493487</td>\n",
              "      <td>7.541579</td>\n",
              "      <td>27</td>\n",
              "      <td>105.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>393.500000</td>\n",
              "      <td>344.166667</td>\n",
              "      <td>612.0</td>\n",
              "      <td>2413.585500</td>\n",
              "      <td>4575.372616</td>\n",
              "      <td>25.927979</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.460317</td>\n",
              "      <td>1.772727</td>\n",
              "      <td>25.500000</td>\n",
              "      <td>23.047619</td>\n",
              "      <td>100.566063</td>\n",
              "      <td>92.993879</td>\n",
              "      <td>175.518792</td>\n",
              "      <td>227.079812</td>\n",
              "      <td>198.191463</td>\n",
              "      <td>153.270562</td>\n",
              "      <td>114.014016</td>\n",
              "      <td>1.080332</td>\n",
              "      <td>1.407855</td>\n",
              "      <td>1.237989</td>\n",
              "      <td>0.975734</td>\n",
              "      <td>0.796130</td>\n",
              "      <td>170.520236</td>\n",
              "      <td>154.381429</td>\n",
              "      <td>166.741525</td>\n",
              "      <td>172.134683</td>\n",
              "      <td>178.032893</td>\n",
              "      <td>184.993831</td>\n",
              "      <td>-0.307929</td>\n",
              "      <td>0.683571</td>\n",
              "      <td>-0.379936</td>\n",
              "      <td>-0.025630</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>95.268229</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>176.254520</td>\n",
              "      <td>243.836186</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.677995</td>\n",
              "      <td>0.889833</td>\n",
              "      <td>18</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>135</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>2.944439</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>3.135494</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>2.890372</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.912655</td>\n",
              "      <td>1</td>\n",
              "      <td>0.065625</td>\n",
              "      <td>4.962845</td>\n",
              "      <td>5.849325</td>\n",
              "      <td>6.722630</td>\n",
              "      <td>7.610358</td>\n",
              "      <td>8.487764</td>\n",
              "      <td>9.375092</td>\n",
              "      <td>10.253827</td>\n",
              "      <td>11.140687</td>\n",
              "      <td>92.513402</td>\n",
              "      <td>6.163315</td>\n",
              "      <td>7.845024</td>\n",
              "      <td>9.569063</td>\n",
              "      <td>7.502641</td>\n",
              "      <td>20</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>518.000000</td>\n",
              "      <td>682.541667</td>\n",
              "      <td>614.847222</td>\n",
              "      <td>1158.0</td>\n",
              "      <td>4569.170871</td>\n",
              "      <td>9127.853377</td>\n",
              "      <td>50.323528</td>\n",
              "      <td>3.155556</td>\n",
              "      <td>2.661290</td>\n",
              "      <td>2.270677</td>\n",
              "      <td>25.733333</td>\n",
              "      <td>23.192771</td>\n",
              "      <td>101.537130</td>\n",
              "      <td>96.335918</td>\n",
              "      <td>181.029861</td>\n",
              "      <td>233.387037</td>\n",
              "      <td>201.265826</td>\n",
              "      <td>157.905783</td>\n",
              "      <td>132.343321</td>\n",
              "      <td>1.118301</td>\n",
              "      <td>1.445816</td>\n",
              "      <td>1.258039</td>\n",
              "      <td>1.008267</td>\n",
              "      <td>0.897097</td>\n",
              "      <td>169.548550</td>\n",
              "      <td>153.042175</td>\n",
              "      <td>166.015110</td>\n",
              "      <td>169.040621</td>\n",
              "      <td>171.734788</td>\n",
              "      <td>166.939623</td>\n",
              "      <td>-0.628096</td>\n",
              "      <td>1.224730</td>\n",
              "      <td>-0.715289</td>\n",
              "      <td>0.159067</td>\n",
              "      <td>10.975309</td>\n",
              "      <td>160.554938</td>\n",
              "      <td>87.169383</td>\n",
              "      <td>415.124614</td>\n",
              "      <td>512.973197</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.110824</td>\n",
              "      <td>0.874384</td>\n",
              "      <td>36</td>\n",
              "      <td>49</td>\n",
              "      <td>56</td>\n",
              "      <td>62</td>\n",
              "      <td>58</td>\n",
              "      <td>53</td>\n",
              "      <td>58</td>\n",
              "      <td>67</td>\n",
              "      <td>557</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.912023</td>\n",
              "      <td>4.043051</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.077537</td>\n",
              "      <td>3.988984</td>\n",
              "      <td>4.077537</td>\n",
              "      <td>4.219508</td>\n",
              "      <td>4.276666</td>\n",
              "      <td>6.324359</td>\n",
              "      <td>2</td>\n",
              "      <td>0.077405</td>\n",
              "      <td>5.673323</td>\n",
              "      <td>6.575076</td>\n",
              "      <td>7.467942</td>\n",
              "      <td>8.371242</td>\n",
              "      <td>9.267193</td>\n",
              "      <td>10.170725</td>\n",
              "      <td>11.068184</td>\n",
              "      <td>11.971710</td>\n",
              "      <td>122.361186</td>\n",
              "      <td>6.836259</td>\n",
              "      <td>8.493105</td>\n",
              "      <td>10.192007</td>\n",
              "      <td>7.602582</td>\n",
              "      <td>41</td>\n",
              "      <td>145.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2162</th>\n",
              "      <td>1</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>77.166667</td>\n",
              "      <td>374.0</td>\n",
              "      <td>1471.157473</td>\n",
              "      <td>1698.267489</td>\n",
              "      <td>25.377020</td>\n",
              "      <td>2.722222</td>\n",
              "      <td>2.468750</td>\n",
              "      <td>2.068966</td>\n",
              "      <td>20.777778</td>\n",
              "      <td>18.068966</td>\n",
              "      <td>81.730971</td>\n",
              "      <td>83.733809</td>\n",
              "      <td>205.782053</td>\n",
              "      <td>249.208791</td>\n",
              "      <td>199.761175</td>\n",
              "      <td>172.007401</td>\n",
              "      <td>139.293359</td>\n",
              "      <td>1.409834</td>\n",
              "      <td>1.732770</td>\n",
              "      <td>1.435561</td>\n",
              "      <td>1.283351</td>\n",
              "      <td>1.117860</td>\n",
              "      <td>163.806151</td>\n",
              "      <td>147.310599</td>\n",
              "      <td>163.635093</td>\n",
              "      <td>161.168289</td>\n",
              "      <td>162.830109</td>\n",
              "      <td>184.917652</td>\n",
              "      <td>-0.044889</td>\n",
              "      <td>0.081225</td>\n",
              "      <td>-0.072734</td>\n",
              "      <td>0.023068</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>24.989198</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>134.419914</td>\n",
              "      <td>397.674863</td>\n",
              "      <td>...</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>1.727010</td>\n",
              "      <td>0.191890</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>3.068053</td>\n",
              "      <td>3.504055</td>\n",
              "      <td>3.944006</td>\n",
              "      <td>4.328263</td>\n",
              "      <td>3.840795</td>\n",
              "      <td>3.056357</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.583496</td>\n",
              "      <td>1</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>4.465908</td>\n",
              "      <td>5.262690</td>\n",
              "      <td>6.033086</td>\n",
              "      <td>6.834109</td>\n",
              "      <td>7.608374</td>\n",
              "      <td>8.409831</td>\n",
              "      <td>9.185125</td>\n",
              "      <td>9.986495</td>\n",
              "      <td>79.499191</td>\n",
              "      <td>5.556828</td>\n",
              "      <td>7.062192</td>\n",
              "      <td>8.606851</td>\n",
              "      <td>6.837134</td>\n",
              "      <td>9</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2163</th>\n",
              "      <td>0</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>112.111111</td>\n",
              "      <td>95.500000</td>\n",
              "      <td>388.0</td>\n",
              "      <td>1529.913361</td>\n",
              "      <td>1732.115297</td>\n",
              "      <td>24.365611</td>\n",
              "      <td>2.823529</td>\n",
              "      <td>2.437500</td>\n",
              "      <td>1.766667</td>\n",
              "      <td>22.823529</td>\n",
              "      <td>20.038462</td>\n",
              "      <td>89.994904</td>\n",
              "      <td>88.180785</td>\n",
              "      <td>214.474695</td>\n",
              "      <td>260.148487</td>\n",
              "      <td>225.702851</td>\n",
              "      <td>173.980851</td>\n",
              "      <td>117.158084</td>\n",
              "      <td>1.433271</td>\n",
              "      <td>1.761870</td>\n",
              "      <td>1.584842</td>\n",
              "      <td>1.283753</td>\n",
              "      <td>0.936417</td>\n",
              "      <td>161.047311</td>\n",
              "      <td>146.079470</td>\n",
              "      <td>155.014611</td>\n",
              "      <td>165.020611</td>\n",
              "      <td>173.254972</td>\n",
              "      <td>185.050964</td>\n",
              "      <td>0.017422</td>\n",
              "      <td>0.040603</td>\n",
              "      <td>-0.074446</td>\n",
              "      <td>-0.044465</td>\n",
              "      <td>1.941176</td>\n",
              "      <td>40.392157</td>\n",
              "      <td>-2.373702</td>\n",
              "      <td>-13.886239</td>\n",
              "      <td>-30.988205</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.480679</td>\n",
              "      <td>0.386742</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>3.068053</td>\n",
              "      <td>3.504055</td>\n",
              "      <td>3.899444</td>\n",
              "      <td>4.385925</td>\n",
              "      <td>3.876396</td>\n",
              "      <td>2.784239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.579258</td>\n",
              "      <td>1</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>4.465908</td>\n",
              "      <td>5.252273</td>\n",
              "      <td>6.028279</td>\n",
              "      <td>6.816736</td>\n",
              "      <td>7.598399</td>\n",
              "      <td>8.386401</td>\n",
              "      <td>9.169831</td>\n",
              "      <td>9.957265</td>\n",
              "      <td>79.388664</td>\n",
              "      <td>5.556828</td>\n",
              "      <td>7.055313</td>\n",
              "      <td>8.590258</td>\n",
              "      <td>7.297202</td>\n",
              "      <td>9</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2164</th>\n",
              "      <td>1</td>\n",
              "      <td>244.000000</td>\n",
              "      <td>156.333333</td>\n",
              "      <td>158.666667</td>\n",
              "      <td>554.0</td>\n",
              "      <td>2192.478078</td>\n",
              "      <td>3088.803862</td>\n",
              "      <td>39.321520</td>\n",
              "      <td>3.347826</td>\n",
              "      <td>3.086957</td>\n",
              "      <td>2.756098</td>\n",
              "      <td>24.086957</td>\n",
              "      <td>22.432432</td>\n",
              "      <td>95.325134</td>\n",
              "      <td>98.698891</td>\n",
              "      <td>253.115716</td>\n",
              "      <td>294.149276</td>\n",
              "      <td>259.728419</td>\n",
              "      <td>210.713375</td>\n",
              "      <td>190.455121</td>\n",
              "      <td>1.709631</td>\n",
              "      <td>2.020918</td>\n",
              "      <td>1.823509</td>\n",
              "      <td>1.518599</td>\n",
              "      <td>1.366621</td>\n",
              "      <td>155.760108</td>\n",
              "      <td>140.845633</td>\n",
              "      <td>152.012987</td>\n",
              "      <td>155.402614</td>\n",
              "      <td>155.365994</td>\n",
              "      <td>165.115362</td>\n",
              "      <td>-0.084842</td>\n",
              "      <td>0.048049</td>\n",
              "      <td>-0.037491</td>\n",
              "      <td>0.021029</td>\n",
              "      <td>2.918715</td>\n",
              "      <td>34.637681</td>\n",
              "      <td>-40.049149</td>\n",
              "      <td>-193.673897</td>\n",
              "      <td>-379.304122</td>\n",
              "      <td>...</td>\n",
              "      <td>0.142679</td>\n",
              "      <td>1.785574</td>\n",
              "      <td>0.127541</td>\n",
              "      <td>19</td>\n",
              "      <td>24</td>\n",
              "      <td>28</td>\n",
              "      <td>32</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>20</td>\n",
              "      <td>16</td>\n",
              "      <td>228</td>\n",
              "      <td>3.135494</td>\n",
              "      <td>3.663562</td>\n",
              "      <td>4.226834</td>\n",
              "      <td>4.711780</td>\n",
              "      <td>5.192262</td>\n",
              "      <td>5.029621</td>\n",
              "      <td>5.364222</td>\n",
              "      <td>5.432903</td>\n",
              "      <td>5.614496</td>\n",
              "      <td>5.731874</td>\n",
              "      <td>7.380791</td>\n",
              "      <td>2</td>\n",
              "      <td>0.048611</td>\n",
              "      <td>5.043425</td>\n",
              "      <td>5.866468</td>\n",
              "      <td>6.693324</td>\n",
              "      <td>7.524561</td>\n",
              "      <td>8.356790</td>\n",
              "      <td>9.191056</td>\n",
              "      <td>10.025307</td>\n",
              "      <td>10.860786</td>\n",
              "      <td>96.795823</td>\n",
              "      <td>6.137727</td>\n",
              "      <td>7.690286</td>\n",
              "      <td>9.282754</td>\n",
              "      <td>7.959496</td>\n",
              "      <td>18</td>\n",
              "      <td>77.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2165</th>\n",
              "      <td>0</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>133.861111</td>\n",
              "      <td>100.500000</td>\n",
              "      <td>464.0</td>\n",
              "      <td>1822.505859</td>\n",
              "      <td>1810.708633</td>\n",
              "      <td>31.721863</td>\n",
              "      <td>2.695652</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>2.119048</td>\n",
              "      <td>20.173913</td>\n",
              "      <td>17.300000</td>\n",
              "      <td>79.239385</td>\n",
              "      <td>81.560434</td>\n",
              "      <td>200.758200</td>\n",
              "      <td>246.659266</td>\n",
              "      <td>187.961032</td>\n",
              "      <td>153.975425</td>\n",
              "      <td>135.422656</td>\n",
              "      <td>1.379211</td>\n",
              "      <td>1.725728</td>\n",
              "      <td>1.348699</td>\n",
              "      <td>1.156479</td>\n",
              "      <td>1.093426</td>\n",
              "      <td>162.220157</td>\n",
              "      <td>143.993713</td>\n",
              "      <td>161.301195</td>\n",
              "      <td>161.379540</td>\n",
              "      <td>163.145897</td>\n",
              "      <td>166.400287</td>\n",
              "      <td>0.081851</td>\n",
              "      <td>-0.146009</td>\n",
              "      <td>-0.116511</td>\n",
              "      <td>0.206536</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>37.637681</td>\n",
              "      <td>-15.939509</td>\n",
              "      <td>-72.856945</td>\n",
              "      <td>-16.437701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.688551</td>\n",
              "      <td>0.335323</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>2.740840</td>\n",
              "      <td>3.228826</td>\n",
              "      <td>3.522677</td>\n",
              "      <td>3.962003</td>\n",
              "      <td>3.852804</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.725693</td>\n",
              "      <td>3.725693</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.698142</td>\n",
              "      <td>1</td>\n",
              "      <td>0.063272</td>\n",
              "      <td>4.672829</td>\n",
              "      <td>5.484797</td>\n",
              "      <td>6.255750</td>\n",
              "      <td>7.069023</td>\n",
              "      <td>7.854381</td>\n",
              "      <td>8.666130</td>\n",
              "      <td>9.459619</td>\n",
              "      <td>10.269900</td>\n",
              "      <td>85.664256</td>\n",
              "      <td>5.739793</td>\n",
              "      <td>7.172425</td>\n",
              "      <td>8.645235</td>\n",
              "      <td>6.612336</td>\n",
              "      <td>9</td>\n",
              "      <td>53.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2166</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>530.0</td>\n",
              "      <td>2120.214214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>522.015634</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>424.042843</td>\n",
              "      <td>16.126992</td>\n",
              "      <td>632.176246</td>\n",
              "      <td>82.013631</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>104.403127</td>\n",
              "      <td>0.534768</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.621720</td>\n",
              "      <td>185.184277</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.480000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.793614</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2167 rows  242 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34d8988c-f989-499f-a162-924429699277')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34d8988c-f989-499f-a162-924429699277 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34d8988c-f989-499f-a162-924429699277');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      nN      ATS2dv       ATS3s  ...        AMW  WPol  Zagreb2\n",
              "0      0  532.000000  652.500000  ...   7.602582    43    147.0\n",
              "1      0  477.111111  509.601852  ...   9.428918    43    147.0\n",
              "2      2  348.000000  327.027778  ...   7.541579    27    105.0\n",
              "3      0  254.000000  393.500000  ...   7.502641    20     71.0\n",
              "4      0  518.000000  682.541667  ...   7.602582    41    145.0\n",
              "...   ..         ...         ...  ...        ...   ...      ...\n",
              "2162   1  123.000000  103.000000  ...   6.837134     9     43.0\n",
              "2163   0  128.000000  112.111111  ...   7.297202     9     43.0\n",
              "2164   1  244.000000  156.333333  ...   7.959496    18     77.0\n",
              "2165   0  139.000000  133.861111  ...   6.612336     9     53.0\n",
              "2166   0    0.000000    0.000000  ...  14.793614     0      0.0\n",
              "\n",
              "[2167 rows x 242 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "re7E-0-JPiJW",
        "outputId": "729ac93d-7248-4cf5-ebc1-c59606dae3d5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bde96d6a-9652-47f0-bd35-e0ff99d81cd4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2162</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2163</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2164</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2165</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2166</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2167 rows  1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bde96d6a-9652-47f0-bd35-e0ff99d81cd4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bde96d6a-9652-47f0-bd35-e0ff99d81cd4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bde96d6a-9652-47f0-bd35-e0ff99d81cd4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Sweet\n",
              "0      True\n",
              "1      True\n",
              "2      True\n",
              "3      True\n",
              "4      True\n",
              "...     ...\n",
              "2162  False\n",
              "2163  False\n",
              "2164  False\n",
              "2165  False\n",
              "2166  False\n",
              "\n",
              "[2167 rows x 1 columns]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrK1nxxlP6Mw"
      },
      "outputs": [],
      "source": [
        "df_test = x_new_test.join(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "hUtkZDGIQBiG",
        "outputId": "a8aa9d9d-5729-439f-ed23-b09ff840f96e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c24e4587-3f10-4c58-a94d-e22b23e25fe8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nN</th>\n",
              "      <th>ATS2dv</th>\n",
              "      <th>ATS3s</th>\n",
              "      <th>ATS4s</th>\n",
              "      <th>ATS0Z</th>\n",
              "      <th>ATS0m</th>\n",
              "      <th>ATS3m</th>\n",
              "      <th>ATS0p</th>\n",
              "      <th>AATS0d</th>\n",
              "      <th>AATS3d</th>\n",
              "      <th>AATS4d</th>\n",
              "      <th>AATS0Z</th>\n",
              "      <th>AATS2Z</th>\n",
              "      <th>AATS0m</th>\n",
              "      <th>AATS1m</th>\n",
              "      <th>AATS0v</th>\n",
              "      <th>AATS1v</th>\n",
              "      <th>AATS2v</th>\n",
              "      <th>AATS3v</th>\n",
              "      <th>AATS4v</th>\n",
              "      <th>AATS0p</th>\n",
              "      <th>AATS1p</th>\n",
              "      <th>AATS2p</th>\n",
              "      <th>AATS3p</th>\n",
              "      <th>AATS4p</th>\n",
              "      <th>AATS0i</th>\n",
              "      <th>AATS1i</th>\n",
              "      <th>AATS3i</th>\n",
              "      <th>AATS4i</th>\n",
              "      <th>AATS5i</th>\n",
              "      <th>AATS7i</th>\n",
              "      <th>ATSC2c</th>\n",
              "      <th>ATSC3c</th>\n",
              "      <th>ATSC4c</th>\n",
              "      <th>ATSC5c</th>\n",
              "      <th>ATSC1d</th>\n",
              "      <th>ATSC0s</th>\n",
              "      <th>ATSC6Z</th>\n",
              "      <th>ATSC6m</th>\n",
              "      <th>ATSC6v</th>\n",
              "      <th>...</th>\n",
              "      <th>MID_O</th>\n",
              "      <th>AMID_O</th>\n",
              "      <th>MPC2</th>\n",
              "      <th>MPC3</th>\n",
              "      <th>MPC4</th>\n",
              "      <th>MPC5</th>\n",
              "      <th>MPC6</th>\n",
              "      <th>MPC7</th>\n",
              "      <th>MPC8</th>\n",
              "      <th>MPC9</th>\n",
              "      <th>TMPC10</th>\n",
              "      <th>piPC1</th>\n",
              "      <th>piPC2</th>\n",
              "      <th>piPC3</th>\n",
              "      <th>piPC4</th>\n",
              "      <th>piPC5</th>\n",
              "      <th>piPC6</th>\n",
              "      <th>piPC7</th>\n",
              "      <th>piPC8</th>\n",
              "      <th>piPC9</th>\n",
              "      <th>piPC10</th>\n",
              "      <th>TpiPC10</th>\n",
              "      <th>nRing</th>\n",
              "      <th>JGI3</th>\n",
              "      <th>MWC03</th>\n",
              "      <th>MWC04</th>\n",
              "      <th>MWC05</th>\n",
              "      <th>MWC06</th>\n",
              "      <th>MWC07</th>\n",
              "      <th>MWC08</th>\n",
              "      <th>MWC09</th>\n",
              "      <th>MWC10</th>\n",
              "      <th>TMWC10</th>\n",
              "      <th>SRW06</th>\n",
              "      <th>SRW08</th>\n",
              "      <th>SRW10</th>\n",
              "      <th>AMW</th>\n",
              "      <th>WPol</th>\n",
              "      <th>Zagreb2</th>\n",
              "      <th>Sweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>264.666667</td>\n",
              "      <td>321.879630</td>\n",
              "      <td>375.703704</td>\n",
              "      <td>1268.0</td>\n",
              "      <td>4982.059799</td>\n",
              "      <td>6262.950338</td>\n",
              "      <td>73.907442</td>\n",
              "      <td>2.614035</td>\n",
              "      <td>2.227941</td>\n",
              "      <td>2.012121</td>\n",
              "      <td>22.245614</td>\n",
              "      <td>18.788462</td>\n",
              "      <td>87.404558</td>\n",
              "      <td>83.558362</td>\n",
              "      <td>175.338892</td>\n",
              "      <td>223.299893</td>\n",
              "      <td>175.993860</td>\n",
              "      <td>149.859311</td>\n",
              "      <td>116.140023</td>\n",
              "      <td>1.296622</td>\n",
              "      <td>1.618120</td>\n",
              "      <td>1.354649</td>\n",
              "      <td>1.239443</td>\n",
              "      <td>0.938069</td>\n",
              "      <td>168.663989</td>\n",
              "      <td>151.396198</td>\n",
              "      <td>160.057177</td>\n",
              "      <td>171.281214</td>\n",
              "      <td>165.738477</td>\n",
              "      <td>163.361191</td>\n",
              "      <td>0.159971</td>\n",
              "      <td>-0.061525</td>\n",
              "      <td>-0.154919</td>\n",
              "      <td>0.311617</td>\n",
              "      <td>9.894737</td>\n",
              "      <td>77.072759</td>\n",
              "      <td>314.066482</td>\n",
              "      <td>1492.778791</td>\n",
              "      <td>2251.021667</td>\n",
              "      <td>...</td>\n",
              "      <td>7.359986</td>\n",
              "      <td>0.306666</td>\n",
              "      <td>34</td>\n",
              "      <td>36</td>\n",
              "      <td>42</td>\n",
              "      <td>27</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>25</td>\n",
              "      <td>318</td>\n",
              "      <td>3.258097</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.637586</td>\n",
              "      <td>3.806662</td>\n",
              "      <td>3.367296</td>\n",
              "      <td>3.332205</td>\n",
              "      <td>3.367296</td>\n",
              "      <td>3.433987</td>\n",
              "      <td>3.332205</td>\n",
              "      <td>3.258097</td>\n",
              "      <td>5.805135</td>\n",
              "      <td>1</td>\n",
              "      <td>0.113426</td>\n",
              "      <td>5.549076</td>\n",
              "      <td>6.444131</td>\n",
              "      <td>7.257708</td>\n",
              "      <td>8.172164</td>\n",
              "      <td>9.003685</td>\n",
              "      <td>9.935035</td>\n",
              "      <td>10.780060</td>\n",
              "      <td>11.725590</td>\n",
              "      <td>121.629623</td>\n",
              "      <td>6.829794</td>\n",
              "      <td>8.509363</td>\n",
              "      <td>10.256922</td>\n",
              "      <td>6.372266</td>\n",
              "      <td>27</td>\n",
              "      <td>128.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>434.000000</td>\n",
              "      <td>654.250000</td>\n",
              "      <td>643.888889</td>\n",
              "      <td>1160.0</td>\n",
              "      <td>4571.202999</td>\n",
              "      <td>8589.759775</td>\n",
              "      <td>51.212754</td>\n",
              "      <td>2.851064</td>\n",
              "      <td>2.603175</td>\n",
              "      <td>2.362319</td>\n",
              "      <td>24.680851</td>\n",
              "      <td>21.144578</td>\n",
              "      <td>97.259638</td>\n",
              "      <td>90.798347</td>\n",
              "      <td>174.649175</td>\n",
              "      <td>226.166478</td>\n",
              "      <td>191.396631</td>\n",
              "      <td>152.142943</td>\n",
              "      <td>138.329306</td>\n",
              "      <td>1.089633</td>\n",
              "      <td>1.421628</td>\n",
              "      <td>1.231107</td>\n",
              "      <td>0.994737</td>\n",
              "      <td>0.924393</td>\n",
              "      <td>170.202555</td>\n",
              "      <td>153.721352</td>\n",
              "      <td>166.302447</td>\n",
              "      <td>168.816659</td>\n",
              "      <td>168.959562</td>\n",
              "      <td>169.501042</td>\n",
              "      <td>-0.662971</td>\n",
              "      <td>1.107631</td>\n",
              "      <td>-0.544458</td>\n",
              "      <td>0.071001</td>\n",
              "      <td>10.191489</td>\n",
              "      <td>176.053191</td>\n",
              "      <td>-24.065188</td>\n",
              "      <td>-117.103836</td>\n",
              "      <td>-213.618083</td>\n",
              "      <td>...</td>\n",
              "      <td>19.739869</td>\n",
              "      <td>0.858255</td>\n",
              "      <td>32</td>\n",
              "      <td>42</td>\n",
              "      <td>46</td>\n",
              "      <td>53</td>\n",
              "      <td>54</td>\n",
              "      <td>50</td>\n",
              "      <td>46</td>\n",
              "      <td>39</td>\n",
              "      <td>433</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>3.496508</td>\n",
              "      <td>3.761200</td>\n",
              "      <td>3.850148</td>\n",
              "      <td>3.988984</td>\n",
              "      <td>4.007333</td>\n",
              "      <td>3.931826</td>\n",
              "      <td>3.850148</td>\n",
              "      <td>3.688879</td>\n",
              "      <td>3.258097</td>\n",
              "      <td>6.073045</td>\n",
              "      <td>1</td>\n",
              "      <td>0.059295</td>\n",
              "      <td>5.556828</td>\n",
              "      <td>6.424869</td>\n",
              "      <td>7.295056</td>\n",
              "      <td>8.170469</td>\n",
              "      <td>9.046762</td>\n",
              "      <td>9.925200</td>\n",
              "      <td>10.803954</td>\n",
              "      <td>11.683857</td>\n",
              "      <td>119.616526</td>\n",
              "      <td>6.688355</td>\n",
              "      <td>8.303752</td>\n",
              "      <td>9.968198</td>\n",
              "      <td>7.321955</td>\n",
              "      <td>39</td>\n",
              "      <td>129.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>428.000000</td>\n",
              "      <td>676.361111</td>\n",
              "      <td>663.638889</td>\n",
              "      <td>1160.0</td>\n",
              "      <td>4571.202999</td>\n",
              "      <td>8468.693766</td>\n",
              "      <td>51.212754</td>\n",
              "      <td>2.851064</td>\n",
              "      <td>2.492063</td>\n",
              "      <td>2.137681</td>\n",
              "      <td>24.680851</td>\n",
              "      <td>21.144578</td>\n",
              "      <td>97.259638</td>\n",
              "      <td>90.798347</td>\n",
              "      <td>174.649175</td>\n",
              "      <td>226.166478</td>\n",
              "      <td>191.396631</td>\n",
              "      <td>150.356217</td>\n",
              "      <td>129.443088</td>\n",
              "      <td>1.089633</td>\n",
              "      <td>1.421628</td>\n",
              "      <td>1.231107</td>\n",
              "      <td>0.986749</td>\n",
              "      <td>0.878757</td>\n",
              "      <td>170.202555</td>\n",
              "      <td>153.721352</td>\n",
              "      <td>166.259059</td>\n",
              "      <td>170.120488</td>\n",
              "      <td>171.211079</td>\n",
              "      <td>170.466790</td>\n",
              "      <td>-0.662283</td>\n",
              "      <td>1.126649</td>\n",
              "      <td>-0.537403</td>\n",
              "      <td>0.032920</td>\n",
              "      <td>9.191489</td>\n",
              "      <td>176.053191</td>\n",
              "      <td>15.739701</td>\n",
              "      <td>73.310736</td>\n",
              "      <td>47.808010</td>\n",
              "      <td>...</td>\n",
              "      <td>19.723213</td>\n",
              "      <td>0.857531</td>\n",
              "      <td>32</td>\n",
              "      <td>41</td>\n",
              "      <td>42</td>\n",
              "      <td>45</td>\n",
              "      <td>43</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>392</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>3.496508</td>\n",
              "      <td>3.737670</td>\n",
              "      <td>3.761200</td>\n",
              "      <td>3.828641</td>\n",
              "      <td>3.784190</td>\n",
              "      <td>3.663562</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.526361</td>\n",
              "      <td>5.973810</td>\n",
              "      <td>1</td>\n",
              "      <td>0.060855</td>\n",
              "      <td>5.549076</td>\n",
              "      <td>6.405228</td>\n",
              "      <td>7.261927</td>\n",
              "      <td>8.122371</td>\n",
              "      <td>8.983314</td>\n",
              "      <td>9.846017</td>\n",
              "      <td>10.709137</td>\n",
              "      <td>11.573409</td>\n",
              "      <td>119.160011</td>\n",
              "      <td>6.680855</td>\n",
              "      <td>8.283747</td>\n",
              "      <td>9.932901</td>\n",
              "      <td>7.321955</td>\n",
              "      <td>38</td>\n",
              "      <td>128.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>219.916667</td>\n",
              "      <td>185.666667</td>\n",
              "      <td>410.0</td>\n",
              "      <td>1611.089128</td>\n",
              "      <td>1966.301776</td>\n",
              "      <td>18.174545</td>\n",
              "      <td>2.222222</td>\n",
              "      <td>1.743590</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>22.777778</td>\n",
              "      <td>17.214286</td>\n",
              "      <td>89.504952</td>\n",
              "      <td>78.741107</td>\n",
              "      <td>159.470453</td>\n",
              "      <td>205.761349</td>\n",
              "      <td>164.089267</td>\n",
              "      <td>119.448125</td>\n",
              "      <td>92.036166</td>\n",
              "      <td>1.009697</td>\n",
              "      <td>1.326141</td>\n",
              "      <td>1.109793</td>\n",
              "      <td>0.836084</td>\n",
              "      <td>0.684056</td>\n",
              "      <td>172.119949</td>\n",
              "      <td>156.072281</td>\n",
              "      <td>170.501551</td>\n",
              "      <td>176.216465</td>\n",
              "      <td>182.379170</td>\n",
              "      <td>184.917652</td>\n",
              "      <td>-0.219335</td>\n",
              "      <td>0.378624</td>\n",
              "      <td>-0.175020</td>\n",
              "      <td>-0.012729</td>\n",
              "      <td>1.888889</td>\n",
              "      <td>74.641975</td>\n",
              "      <td>19.555556</td>\n",
              "      <td>93.749126</td>\n",
              "      <td>132.198175</td>\n",
              "      <td>...</td>\n",
              "      <td>6.798694</td>\n",
              "      <td>0.849837</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>1.609438</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046875</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.875197</td>\n",
              "      <td>5.609472</td>\n",
              "      <td>6.347389</td>\n",
              "      <td>7.085901</td>\n",
              "      <td>7.825245</td>\n",
              "      <td>8.564649</td>\n",
              "      <td>9.304286</td>\n",
              "      <td>72.189262</td>\n",
              "      <td>5.209486</td>\n",
              "      <td>6.642487</td>\n",
              "      <td>8.103192</td>\n",
              "      <td>6.780995</td>\n",
              "      <td>8</td>\n",
              "      <td>31.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1189.000000</td>\n",
              "      <td>1302.611111</td>\n",
              "      <td>1463.708333</td>\n",
              "      <td>2580.0</td>\n",
              "      <td>10150.424456</td>\n",
              "      <td>24297.097283</td>\n",
              "      <td>144.232646</td>\n",
              "      <td>3.293103</td>\n",
              "      <td>3.174263</td>\n",
              "      <td>2.707368</td>\n",
              "      <td>22.241379</td>\n",
              "      <td>20.792373</td>\n",
              "      <td>87.503659</td>\n",
              "      <td>89.054234</td>\n",
              "      <td>188.393973</td>\n",
              "      <td>244.945856</td>\n",
              "      <td>211.245372</td>\n",
              "      <td>178.576482</td>\n",
              "      <td>150.884097</td>\n",
              "      <td>1.243385</td>\n",
              "      <td>1.627610</td>\n",
              "      <td>1.433857</td>\n",
              "      <td>1.251932</td>\n",
              "      <td>1.107180</td>\n",
              "      <td>165.960067</td>\n",
              "      <td>147.856207</td>\n",
              "      <td>157.989833</td>\n",
              "      <td>161.973644</td>\n",
              "      <td>164.175074</td>\n",
              "      <td>162.077837</td>\n",
              "      <td>-0.793969</td>\n",
              "      <td>1.616018</td>\n",
              "      <td>-0.948455</td>\n",
              "      <td>0.252029</td>\n",
              "      <td>37.854935</td>\n",
              "      <td>284.355364</td>\n",
              "      <td>478.282996</td>\n",
              "      <td>2270.460414</td>\n",
              "      <td>2757.360945</td>\n",
              "      <td>...</td>\n",
              "      <td>33.463807</td>\n",
              "      <td>0.597568</td>\n",
              "      <td>99</td>\n",
              "      <td>146</td>\n",
              "      <td>199</td>\n",
              "      <td>271</td>\n",
              "      <td>347</td>\n",
              "      <td>431</td>\n",
              "      <td>544</td>\n",
              "      <td>691</td>\n",
              "      <td>3670</td>\n",
              "      <td>4.174387</td>\n",
              "      <td>4.644391</td>\n",
              "      <td>5.036953</td>\n",
              "      <td>5.342334</td>\n",
              "      <td>5.659482</td>\n",
              "      <td>5.908083</td>\n",
              "      <td>6.146329</td>\n",
              "      <td>6.378426</td>\n",
              "      <td>6.626718</td>\n",
              "      <td>6.797940</td>\n",
              "      <td>8.279190</td>\n",
              "      <td>7</td>\n",
              "      <td>0.065662</td>\n",
              "      <td>6.700731</td>\n",
              "      <td>7.653969</td>\n",
              "      <td>8.595080</td>\n",
              "      <td>9.554852</td>\n",
              "      <td>10.503395</td>\n",
              "      <td>11.468294</td>\n",
              "      <td>12.421914</td>\n",
              "      <td>13.391032</td>\n",
              "      <td>204.066919</td>\n",
              "      <td>7.893945</td>\n",
              "      <td>9.631219</td>\n",
              "      <td>11.421851</td>\n",
              "      <td>6.934293</td>\n",
              "      <td>123</td>\n",
              "      <td>406.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0</td>\n",
              "      <td>624.000000</td>\n",
              "      <td>443.500000</td>\n",
              "      <td>375.611111</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>3967.930590</td>\n",
              "      <td>8249.957008</td>\n",
              "      <td>51.671283</td>\n",
              "      <td>4.176471</td>\n",
              "      <td>3.894118</td>\n",
              "      <td>3.446809</td>\n",
              "      <td>29.411765</td>\n",
              "      <td>29.459016</td>\n",
              "      <td>116.703841</td>\n",
              "      <td>113.596930</td>\n",
              "      <td>242.367468</td>\n",
              "      <td>289.569200</td>\n",
              "      <td>277.713676</td>\n",
              "      <td>233.015563</td>\n",
              "      <td>196.601563</td>\n",
              "      <td>1.519744</td>\n",
              "      <td>1.814733</td>\n",
              "      <td>1.743045</td>\n",
              "      <td>1.481888</td>\n",
              "      <td>1.313979</td>\n",
              "      <td>159.384887</td>\n",
              "      <td>146.123753</td>\n",
              "      <td>152.777264</td>\n",
              "      <td>156.625280</td>\n",
              "      <td>157.196804</td>\n",
              "      <td>166.617489</td>\n",
              "      <td>-0.292867</td>\n",
              "      <td>0.954611</td>\n",
              "      <td>-0.445755</td>\n",
              "      <td>-0.510073</td>\n",
              "      <td>10.622837</td>\n",
              "      <td>97.434845</td>\n",
              "      <td>74.820069</td>\n",
              "      <td>339.920780</td>\n",
              "      <td>-63.761998</td>\n",
              "      <td>...</td>\n",
              "      <td>13.023861</td>\n",
              "      <td>0.591994</td>\n",
              "      <td>40</td>\n",
              "      <td>58</td>\n",
              "      <td>83</td>\n",
              "      <td>117</td>\n",
              "      <td>143</td>\n",
              "      <td>176</td>\n",
              "      <td>205</td>\n",
              "      <td>212</td>\n",
              "      <td>1296</td>\n",
              "      <td>3.465736</td>\n",
              "      <td>4.158883</td>\n",
              "      <td>4.753590</td>\n",
              "      <td>5.343530</td>\n",
              "      <td>5.930586</td>\n",
              "      <td>6.239301</td>\n",
              "      <td>6.609981</td>\n",
              "      <td>7.006667</td>\n",
              "      <td>7.293188</td>\n",
              "      <td>7.589012</td>\n",
              "      <td>8.797272</td>\n",
              "      <td>4</td>\n",
              "      <td>0.067077</td>\n",
              "      <td>5.789960</td>\n",
              "      <td>6.741701</td>\n",
              "      <td>7.679251</td>\n",
              "      <td>8.636752</td>\n",
              "      <td>9.583351</td>\n",
              "      <td>10.543366</td>\n",
              "      <td>11.494711</td>\n",
              "      <td>12.455885</td>\n",
              "      <td>124.800175</td>\n",
              "      <td>6.976348</td>\n",
              "      <td>8.697346</td>\n",
              "      <td>10.469965</td>\n",
              "      <td>8.942891</td>\n",
              "      <td>44</td>\n",
              "      <td>163.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0</td>\n",
              "      <td>888.000000</td>\n",
              "      <td>882.000000</td>\n",
              "      <td>984.916667</td>\n",
              "      <td>1902.0</td>\n",
              "      <td>7513.229457</td>\n",
              "      <td>14646.475593</td>\n",
              "      <td>99.421995</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.010101</td>\n",
              "      <td>2.703704</td>\n",
              "      <td>25.360000</td>\n",
              "      <td>23.250000</td>\n",
              "      <td>100.176393</td>\n",
              "      <td>98.174860</td>\n",
              "      <td>206.950327</td>\n",
              "      <td>257.270623</td>\n",
              "      <td>222.407481</td>\n",
              "      <td>181.278366</td>\n",
              "      <td>161.255642</td>\n",
              "      <td>1.325627</td>\n",
              "      <td>1.657321</td>\n",
              "      <td>1.450887</td>\n",
              "      <td>1.196369</td>\n",
              "      <td>1.094295</td>\n",
              "      <td>164.092877</td>\n",
              "      <td>148.096863</td>\n",
              "      <td>160.321959</td>\n",
              "      <td>162.815138</td>\n",
              "      <td>165.029645</td>\n",
              "      <td>160.623030</td>\n",
              "      <td>-0.445318</td>\n",
              "      <td>0.276465</td>\n",
              "      <td>0.826667</td>\n",
              "      <td>-1.015005</td>\n",
              "      <td>15.364800</td>\n",
              "      <td>217.888889</td>\n",
              "      <td>94.528889</td>\n",
              "      <td>450.127543</td>\n",
              "      <td>656.856109</td>\n",
              "      <td>...</td>\n",
              "      <td>25.901187</td>\n",
              "      <td>0.631736</td>\n",
              "      <td>64</td>\n",
              "      <td>85</td>\n",
              "      <td>106</td>\n",
              "      <td>130</td>\n",
              "      <td>144</td>\n",
              "      <td>155</td>\n",
              "      <td>182</td>\n",
              "      <td>210</td>\n",
              "      <td>1395</td>\n",
              "      <td>3.951244</td>\n",
              "      <td>4.477337</td>\n",
              "      <td>4.930870</td>\n",
              "      <td>5.358942</td>\n",
              "      <td>5.757718</td>\n",
              "      <td>5.883845</td>\n",
              "      <td>5.989588</td>\n",
              "      <td>6.298834</td>\n",
              "      <td>6.549293</td>\n",
              "      <td>6.845946</td>\n",
              "      <td>8.237694</td>\n",
              "      <td>4</td>\n",
              "      <td>0.058219</td>\n",
              "      <td>6.244167</td>\n",
              "      <td>7.134891</td>\n",
              "      <td>8.012018</td>\n",
              "      <td>8.905851</td>\n",
              "      <td>9.788245</td>\n",
              "      <td>10.684440</td>\n",
              "      <td>11.570147</td>\n",
              "      <td>12.468218</td>\n",
              "      <td>165.187873</td>\n",
              "      <td>7.389564</td>\n",
              "      <td>9.026538</td>\n",
              "      <td>10.711057</td>\n",
              "      <td>7.762598</td>\n",
              "      <td>73</td>\n",
              "      <td>257.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>0</td>\n",
              "      <td>1232.000000</td>\n",
              "      <td>1379.402778</td>\n",
              "      <td>1485.451389</td>\n",
              "      <td>2780.0</td>\n",
              "      <td>10916.498070</td>\n",
              "      <td>25526.984494</td>\n",
              "      <td>168.447097</td>\n",
              "      <td>3.179104</td>\n",
              "      <td>3.016317</td>\n",
              "      <td>2.595463</td>\n",
              "      <td>20.746269</td>\n",
              "      <td>19.458484</td>\n",
              "      <td>81.466404</td>\n",
              "      <td>85.189437</td>\n",
              "      <td>186.380100</td>\n",
              "      <td>243.193604</td>\n",
              "      <td>203.839236</td>\n",
              "      <td>171.607948</td>\n",
              "      <td>147.581898</td>\n",
              "      <td>1.257068</td>\n",
              "      <td>1.649722</td>\n",
              "      <td>1.413913</td>\n",
              "      <td>1.228548</td>\n",
              "      <td>1.107113</td>\n",
              "      <td>165.466335</td>\n",
              "      <td>146.804006</td>\n",
              "      <td>158.644010</td>\n",
              "      <td>161.943831</td>\n",
              "      <td>163.959398</td>\n",
              "      <td>161.257464</td>\n",
              "      <td>-0.738217</td>\n",
              "      <td>1.387151</td>\n",
              "      <td>-0.824367</td>\n",
              "      <td>0.209871</td>\n",
              "      <td>39.714413</td>\n",
              "      <td>257.034204</td>\n",
              "      <td>160.862553</td>\n",
              "      <td>786.583802</td>\n",
              "      <td>1673.961801</td>\n",
              "      <td>...</td>\n",
              "      <td>32.032179</td>\n",
              "      <td>0.516648</td>\n",
              "      <td>108</td>\n",
              "      <td>156</td>\n",
              "      <td>207</td>\n",
              "      <td>277</td>\n",
              "      <td>337</td>\n",
              "      <td>408</td>\n",
              "      <td>515</td>\n",
              "      <td>638</td>\n",
              "      <td>3536</td>\n",
              "      <td>4.276666</td>\n",
              "      <td>4.736198</td>\n",
              "      <td>5.129899</td>\n",
              "      <td>5.455321</td>\n",
              "      <td>5.777652</td>\n",
              "      <td>6.023448</td>\n",
              "      <td>6.222576</td>\n",
              "      <td>6.492240</td>\n",
              "      <td>6.732211</td>\n",
              "      <td>6.924612</td>\n",
              "      <td>8.388905</td>\n",
              "      <td>8</td>\n",
              "      <td>0.058707</td>\n",
              "      <td>6.783325</td>\n",
              "      <td>7.716461</td>\n",
              "      <td>8.641709</td>\n",
              "      <td>9.578380</td>\n",
              "      <td>10.509469</td>\n",
              "      <td>11.449549</td>\n",
              "      <td>12.384758</td>\n",
              "      <td>13.328009</td>\n",
              "      <td>217.263779</td>\n",
              "      <td>7.959625</td>\n",
              "      <td>9.666435</td>\n",
              "      <td>11.424193</td>\n",
              "      <td>6.600574</td>\n",
              "      <td>130</td>\n",
              "      <td>441.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>1</td>\n",
              "      <td>313.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1116.0</td>\n",
              "      <td>4536.565946</td>\n",
              "      <td>4095.105547</td>\n",
              "      <td>1887.903189</td>\n",
              "      <td>3.789474</td>\n",
              "      <td>3.222222</td>\n",
              "      <td>2.517241</td>\n",
              "      <td>58.736842</td>\n",
              "      <td>36.866667</td>\n",
              "      <td>238.766629</td>\n",
              "      <td>175.379072</td>\n",
              "      <td>643.641543</td>\n",
              "      <td>327.497999</td>\n",
              "      <td>284.005017</td>\n",
              "      <td>230.107412</td>\n",
              "      <td>189.305687</td>\n",
              "      <td>99.363326</td>\n",
              "      <td>3.646473</td>\n",
              "      <td>1.992587</td>\n",
              "      <td>1.596274</td>\n",
              "      <td>1.288434</td>\n",
              "      <td>152.149026</td>\n",
              "      <td>138.058750</td>\n",
              "      <td>152.721268</td>\n",
              "      <td>161.694523</td>\n",
              "      <td>173.412139</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.789474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>93.975467</td>\n",
              "      <td>466.566813</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>35</td>\n",
              "      <td>37</td>\n",
              "      <td>27</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>227</td>\n",
              "      <td>2.995732</td>\n",
              "      <td>3.676301</td>\n",
              "      <td>4.154969</td>\n",
              "      <td>4.735101</td>\n",
              "      <td>5.146404</td>\n",
              "      <td>5.072827</td>\n",
              "      <td>5.319804</td>\n",
              "      <td>5.182836</td>\n",
              "      <td>5.290474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.051450</td>\n",
              "      <td>2</td>\n",
              "      <td>0.110340</td>\n",
              "      <td>5.068904</td>\n",
              "      <td>5.998937</td>\n",
              "      <td>6.886532</td>\n",
              "      <td>7.815611</td>\n",
              "      <td>8.711608</td>\n",
              "      <td>9.637371</td>\n",
              "      <td>10.538025</td>\n",
              "      <td>11.460885</td>\n",
              "      <td>96.322565</td>\n",
              "      <td>6.251904</td>\n",
              "      <td>7.918265</td>\n",
              "      <td>9.630169</td>\n",
              "      <td>11.735292</td>\n",
              "      <td>18</td>\n",
              "      <td>79.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>0</td>\n",
              "      <td>691.000000</td>\n",
              "      <td>878.208333</td>\n",
              "      <td>966.486111</td>\n",
              "      <td>1894.0</td>\n",
              "      <td>7411.887956</td>\n",
              "      <td>16562.874924</td>\n",
              "      <td>129.187884</td>\n",
              "      <td>2.980392</td>\n",
              "      <td>3.022293</td>\n",
              "      <td>2.511312</td>\n",
              "      <td>18.568627</td>\n",
              "      <td>17.945813</td>\n",
              "      <td>72.665568</td>\n",
              "      <td>76.510883</td>\n",
              "      <td>182.092801</td>\n",
              "      <td>238.428751</td>\n",
              "      <td>202.929059</td>\n",
              "      <td>179.413977</td>\n",
              "      <td>147.494620</td>\n",
              "      <td>1.266548</td>\n",
              "      <td>1.678534</td>\n",
              "      <td>1.458997</td>\n",
              "      <td>1.342982</td>\n",
              "      <td>1.167861</td>\n",
              "      <td>165.020469</td>\n",
              "      <td>145.950967</td>\n",
              "      <td>154.622192</td>\n",
              "      <td>159.688818</td>\n",
              "      <td>161.688365</td>\n",
              "      <td>161.974403</td>\n",
              "      <td>0.042240</td>\n",
              "      <td>0.256828</td>\n",
              "      <td>-0.278276</td>\n",
              "      <td>0.042584</td>\n",
              "      <td>34.093426</td>\n",
              "      <td>178.163739</td>\n",
              "      <td>305.111111</td>\n",
              "      <td>1463.319545</td>\n",
              "      <td>1997.089896</td>\n",
              "      <td>...</td>\n",
              "      <td>16.208659</td>\n",
              "      <td>0.368379</td>\n",
              "      <td>76</td>\n",
              "      <td>102</td>\n",
              "      <td>139</td>\n",
              "      <td>189</td>\n",
              "      <td>247</td>\n",
              "      <td>310</td>\n",
              "      <td>385</td>\n",
              "      <td>464</td>\n",
              "      <td>2541</td>\n",
              "      <td>3.931826</td>\n",
              "      <td>4.418841</td>\n",
              "      <td>4.709530</td>\n",
              "      <td>5.023881</td>\n",
              "      <td>5.323010</td>\n",
              "      <td>5.613128</td>\n",
              "      <td>5.849325</td>\n",
              "      <td>6.061457</td>\n",
              "      <td>6.278521</td>\n",
              "      <td>6.464588</td>\n",
              "      <td>7.959276</td>\n",
              "      <td>4</td>\n",
              "      <td>0.069208</td>\n",
              "      <td>6.401917</td>\n",
              "      <td>7.362011</td>\n",
              "      <td>8.291797</td>\n",
              "      <td>9.261699</td>\n",
              "      <td>10.212405</td>\n",
              "      <td>11.189644</td>\n",
              "      <td>12.153974</td>\n",
              "      <td>13.136469</td>\n",
              "      <td>174.519304</td>\n",
              "      <td>7.614312</td>\n",
              "      <td>9.341982</td>\n",
              "      <td>11.134370</td>\n",
              "      <td>6.102040</td>\n",
              "      <td>88</td>\n",
              "      <td>301.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153 rows  243 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c24e4587-3f10-4c58-a94d-e22b23e25fe8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c24e4587-3f10-4c58-a94d-e22b23e25fe8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c24e4587-3f10-4c58-a94d-e22b23e25fe8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     nN       ATS2dv        ATS3s        ATS4s  ...        AMW  WPol  Zagreb2  Sweet\n",
              "0     3   264.666667   321.879630   375.703704  ...   6.372266    27    128.0   True\n",
              "1     0   434.000000   654.250000   643.888889  ...   7.321955    39    129.0   True\n",
              "2     0   428.000000   676.361111   663.638889  ...   7.321955    38    128.0   True\n",
              "3     0    92.000000   219.916667   185.666667  ...   6.780995     8     31.0   True\n",
              "4     0  1189.000000  1302.611111  1463.708333  ...   6.934293   123    406.0   True\n",
              "..   ..          ...          ...          ...  ...        ...   ...      ...    ...\n",
              "148   0   624.000000   443.500000   375.611111  ...   8.942891    44    163.0   True\n",
              "149   0   888.000000   882.000000   984.916667  ...   7.762598    73    257.0   True\n",
              "150   0  1232.000000  1379.402778  1485.451389  ...   6.600574   130    441.0   True\n",
              "151   1   313.333333     0.000000     0.000000  ...  11.735292    18     79.0   True\n",
              "152   0   691.000000   878.208333   966.486111  ...   6.102040    88    301.0   True\n",
              "\n",
              "[153 rows x 243 columns]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWZDzJHz13zX"
      },
      "outputs": [],
      "source": [
        "df_test = df_test.drop(df_test.columns[0],\n",
        "                       axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "CuYlquth2ATu",
        "outputId": "1b0dd230-7314-4e5b-db71-56d4e8b2247c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d23b0324-35bf-42a2-9078-6f7cbf48ac08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ATS2dv</th>\n",
              "      <th>ATS3s</th>\n",
              "      <th>ATS4s</th>\n",
              "      <th>ATS0Z</th>\n",
              "      <th>ATS0m</th>\n",
              "      <th>ATS3m</th>\n",
              "      <th>ATS0p</th>\n",
              "      <th>AATS0d</th>\n",
              "      <th>AATS3d</th>\n",
              "      <th>AATS4d</th>\n",
              "      <th>AATS0Z</th>\n",
              "      <th>AATS2Z</th>\n",
              "      <th>AATS0m</th>\n",
              "      <th>AATS1m</th>\n",
              "      <th>AATS0v</th>\n",
              "      <th>AATS1v</th>\n",
              "      <th>AATS2v</th>\n",
              "      <th>AATS3v</th>\n",
              "      <th>AATS4v</th>\n",
              "      <th>AATS0p</th>\n",
              "      <th>AATS1p</th>\n",
              "      <th>AATS2p</th>\n",
              "      <th>AATS3p</th>\n",
              "      <th>AATS4p</th>\n",
              "      <th>AATS0i</th>\n",
              "      <th>AATS1i</th>\n",
              "      <th>AATS3i</th>\n",
              "      <th>AATS4i</th>\n",
              "      <th>AATS5i</th>\n",
              "      <th>AATS7i</th>\n",
              "      <th>ATSC2c</th>\n",
              "      <th>ATSC3c</th>\n",
              "      <th>ATSC4c</th>\n",
              "      <th>ATSC5c</th>\n",
              "      <th>ATSC1d</th>\n",
              "      <th>ATSC0s</th>\n",
              "      <th>ATSC6Z</th>\n",
              "      <th>ATSC6m</th>\n",
              "      <th>ATSC6v</th>\n",
              "      <th>ATSC3se</th>\n",
              "      <th>...</th>\n",
              "      <th>MID_O</th>\n",
              "      <th>AMID_O</th>\n",
              "      <th>MPC2</th>\n",
              "      <th>MPC3</th>\n",
              "      <th>MPC4</th>\n",
              "      <th>MPC5</th>\n",
              "      <th>MPC6</th>\n",
              "      <th>MPC7</th>\n",
              "      <th>MPC8</th>\n",
              "      <th>MPC9</th>\n",
              "      <th>TMPC10</th>\n",
              "      <th>piPC1</th>\n",
              "      <th>piPC2</th>\n",
              "      <th>piPC3</th>\n",
              "      <th>piPC4</th>\n",
              "      <th>piPC5</th>\n",
              "      <th>piPC6</th>\n",
              "      <th>piPC7</th>\n",
              "      <th>piPC8</th>\n",
              "      <th>piPC9</th>\n",
              "      <th>piPC10</th>\n",
              "      <th>TpiPC10</th>\n",
              "      <th>nRing</th>\n",
              "      <th>JGI3</th>\n",
              "      <th>MWC03</th>\n",
              "      <th>MWC04</th>\n",
              "      <th>MWC05</th>\n",
              "      <th>MWC06</th>\n",
              "      <th>MWC07</th>\n",
              "      <th>MWC08</th>\n",
              "      <th>MWC09</th>\n",
              "      <th>MWC10</th>\n",
              "      <th>TMWC10</th>\n",
              "      <th>SRW06</th>\n",
              "      <th>SRW08</th>\n",
              "      <th>SRW10</th>\n",
              "      <th>AMW</th>\n",
              "      <th>WPol</th>\n",
              "      <th>Zagreb2</th>\n",
              "      <th>Sweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264.666667</td>\n",
              "      <td>321.879630</td>\n",
              "      <td>375.703704</td>\n",
              "      <td>1268.0</td>\n",
              "      <td>4982.059799</td>\n",
              "      <td>6262.950338</td>\n",
              "      <td>73.907442</td>\n",
              "      <td>2.614035</td>\n",
              "      <td>2.227941</td>\n",
              "      <td>2.012121</td>\n",
              "      <td>22.245614</td>\n",
              "      <td>18.788462</td>\n",
              "      <td>87.404558</td>\n",
              "      <td>83.558362</td>\n",
              "      <td>175.338892</td>\n",
              "      <td>223.299893</td>\n",
              "      <td>175.993860</td>\n",
              "      <td>149.859311</td>\n",
              "      <td>116.140023</td>\n",
              "      <td>1.296622</td>\n",
              "      <td>1.618120</td>\n",
              "      <td>1.354649</td>\n",
              "      <td>1.239443</td>\n",
              "      <td>0.938069</td>\n",
              "      <td>168.663989</td>\n",
              "      <td>151.396198</td>\n",
              "      <td>160.057177</td>\n",
              "      <td>171.281214</td>\n",
              "      <td>165.738477</td>\n",
              "      <td>163.361191</td>\n",
              "      <td>0.159971</td>\n",
              "      <td>-0.061525</td>\n",
              "      <td>-0.154919</td>\n",
              "      <td>0.311617</td>\n",
              "      <td>9.894737</td>\n",
              "      <td>77.072759</td>\n",
              "      <td>314.066482</td>\n",
              "      <td>1492.778791</td>\n",
              "      <td>2251.021667</td>\n",
              "      <td>-1.003921</td>\n",
              "      <td>...</td>\n",
              "      <td>7.359986</td>\n",
              "      <td>0.306666</td>\n",
              "      <td>34</td>\n",
              "      <td>36</td>\n",
              "      <td>42</td>\n",
              "      <td>27</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>25</td>\n",
              "      <td>318</td>\n",
              "      <td>3.258097</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.637586</td>\n",
              "      <td>3.806662</td>\n",
              "      <td>3.367296</td>\n",
              "      <td>3.332205</td>\n",
              "      <td>3.367296</td>\n",
              "      <td>3.433987</td>\n",
              "      <td>3.332205</td>\n",
              "      <td>3.258097</td>\n",
              "      <td>5.805135</td>\n",
              "      <td>1</td>\n",
              "      <td>0.113426</td>\n",
              "      <td>5.549076</td>\n",
              "      <td>6.444131</td>\n",
              "      <td>7.257708</td>\n",
              "      <td>8.172164</td>\n",
              "      <td>9.003685</td>\n",
              "      <td>9.935035</td>\n",
              "      <td>10.780060</td>\n",
              "      <td>11.725590</td>\n",
              "      <td>121.629623</td>\n",
              "      <td>6.829794</td>\n",
              "      <td>8.509363</td>\n",
              "      <td>10.256922</td>\n",
              "      <td>6.372266</td>\n",
              "      <td>27</td>\n",
              "      <td>128.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>434.000000</td>\n",
              "      <td>654.250000</td>\n",
              "      <td>643.888889</td>\n",
              "      <td>1160.0</td>\n",
              "      <td>4571.202999</td>\n",
              "      <td>8589.759775</td>\n",
              "      <td>51.212754</td>\n",
              "      <td>2.851064</td>\n",
              "      <td>2.603175</td>\n",
              "      <td>2.362319</td>\n",
              "      <td>24.680851</td>\n",
              "      <td>21.144578</td>\n",
              "      <td>97.259638</td>\n",
              "      <td>90.798347</td>\n",
              "      <td>174.649175</td>\n",
              "      <td>226.166478</td>\n",
              "      <td>191.396631</td>\n",
              "      <td>152.142943</td>\n",
              "      <td>138.329306</td>\n",
              "      <td>1.089633</td>\n",
              "      <td>1.421628</td>\n",
              "      <td>1.231107</td>\n",
              "      <td>0.994737</td>\n",
              "      <td>0.924393</td>\n",
              "      <td>170.202555</td>\n",
              "      <td>153.721352</td>\n",
              "      <td>166.302447</td>\n",
              "      <td>168.816659</td>\n",
              "      <td>168.959562</td>\n",
              "      <td>169.501042</td>\n",
              "      <td>-0.662971</td>\n",
              "      <td>1.107631</td>\n",
              "      <td>-0.544458</td>\n",
              "      <td>0.071001</td>\n",
              "      <td>10.191489</td>\n",
              "      <td>176.053191</td>\n",
              "      <td>-24.065188</td>\n",
              "      <td>-117.103836</td>\n",
              "      <td>-213.618083</td>\n",
              "      <td>3.093624</td>\n",
              "      <td>...</td>\n",
              "      <td>19.739869</td>\n",
              "      <td>0.858255</td>\n",
              "      <td>32</td>\n",
              "      <td>42</td>\n",
              "      <td>46</td>\n",
              "      <td>53</td>\n",
              "      <td>54</td>\n",
              "      <td>50</td>\n",
              "      <td>46</td>\n",
              "      <td>39</td>\n",
              "      <td>433</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>3.496508</td>\n",
              "      <td>3.761200</td>\n",
              "      <td>3.850148</td>\n",
              "      <td>3.988984</td>\n",
              "      <td>4.007333</td>\n",
              "      <td>3.931826</td>\n",
              "      <td>3.850148</td>\n",
              "      <td>3.688879</td>\n",
              "      <td>3.258097</td>\n",
              "      <td>6.073045</td>\n",
              "      <td>1</td>\n",
              "      <td>0.059295</td>\n",
              "      <td>5.556828</td>\n",
              "      <td>6.424869</td>\n",
              "      <td>7.295056</td>\n",
              "      <td>8.170469</td>\n",
              "      <td>9.046762</td>\n",
              "      <td>9.925200</td>\n",
              "      <td>10.803954</td>\n",
              "      <td>11.683857</td>\n",
              "      <td>119.616526</td>\n",
              "      <td>6.688355</td>\n",
              "      <td>8.303752</td>\n",
              "      <td>9.968198</td>\n",
              "      <td>7.321955</td>\n",
              "      <td>39</td>\n",
              "      <td>129.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>428.000000</td>\n",
              "      <td>676.361111</td>\n",
              "      <td>663.638889</td>\n",
              "      <td>1160.0</td>\n",
              "      <td>4571.202999</td>\n",
              "      <td>8468.693766</td>\n",
              "      <td>51.212754</td>\n",
              "      <td>2.851064</td>\n",
              "      <td>2.492063</td>\n",
              "      <td>2.137681</td>\n",
              "      <td>24.680851</td>\n",
              "      <td>21.144578</td>\n",
              "      <td>97.259638</td>\n",
              "      <td>90.798347</td>\n",
              "      <td>174.649175</td>\n",
              "      <td>226.166478</td>\n",
              "      <td>191.396631</td>\n",
              "      <td>150.356217</td>\n",
              "      <td>129.443088</td>\n",
              "      <td>1.089633</td>\n",
              "      <td>1.421628</td>\n",
              "      <td>1.231107</td>\n",
              "      <td>0.986749</td>\n",
              "      <td>0.878757</td>\n",
              "      <td>170.202555</td>\n",
              "      <td>153.721352</td>\n",
              "      <td>166.259059</td>\n",
              "      <td>170.120488</td>\n",
              "      <td>171.211079</td>\n",
              "      <td>170.466790</td>\n",
              "      <td>-0.662283</td>\n",
              "      <td>1.126649</td>\n",
              "      <td>-0.537403</td>\n",
              "      <td>0.032920</td>\n",
              "      <td>9.191489</td>\n",
              "      <td>176.053191</td>\n",
              "      <td>15.739701</td>\n",
              "      <td>73.310736</td>\n",
              "      <td>47.808010</td>\n",
              "      <td>3.069908</td>\n",
              "      <td>...</td>\n",
              "      <td>19.723213</td>\n",
              "      <td>0.857531</td>\n",
              "      <td>32</td>\n",
              "      <td>41</td>\n",
              "      <td>42</td>\n",
              "      <td>45</td>\n",
              "      <td>43</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>392</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>3.496508</td>\n",
              "      <td>3.737670</td>\n",
              "      <td>3.761200</td>\n",
              "      <td>3.828641</td>\n",
              "      <td>3.784190</td>\n",
              "      <td>3.663562</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.526361</td>\n",
              "      <td>5.973810</td>\n",
              "      <td>1</td>\n",
              "      <td>0.060855</td>\n",
              "      <td>5.549076</td>\n",
              "      <td>6.405228</td>\n",
              "      <td>7.261927</td>\n",
              "      <td>8.122371</td>\n",
              "      <td>8.983314</td>\n",
              "      <td>9.846017</td>\n",
              "      <td>10.709137</td>\n",
              "      <td>11.573409</td>\n",
              "      <td>119.160011</td>\n",
              "      <td>6.680855</td>\n",
              "      <td>8.283747</td>\n",
              "      <td>9.932901</td>\n",
              "      <td>7.321955</td>\n",
              "      <td>38</td>\n",
              "      <td>128.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>92.000000</td>\n",
              "      <td>219.916667</td>\n",
              "      <td>185.666667</td>\n",
              "      <td>410.0</td>\n",
              "      <td>1611.089128</td>\n",
              "      <td>1966.301776</td>\n",
              "      <td>18.174545</td>\n",
              "      <td>2.222222</td>\n",
              "      <td>1.743590</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>22.777778</td>\n",
              "      <td>17.214286</td>\n",
              "      <td>89.504952</td>\n",
              "      <td>78.741107</td>\n",
              "      <td>159.470453</td>\n",
              "      <td>205.761349</td>\n",
              "      <td>164.089267</td>\n",
              "      <td>119.448125</td>\n",
              "      <td>92.036166</td>\n",
              "      <td>1.009697</td>\n",
              "      <td>1.326141</td>\n",
              "      <td>1.109793</td>\n",
              "      <td>0.836084</td>\n",
              "      <td>0.684056</td>\n",
              "      <td>172.119949</td>\n",
              "      <td>156.072281</td>\n",
              "      <td>170.501551</td>\n",
              "      <td>176.216465</td>\n",
              "      <td>182.379170</td>\n",
              "      <td>184.917652</td>\n",
              "      <td>-0.219335</td>\n",
              "      <td>0.378624</td>\n",
              "      <td>-0.175020</td>\n",
              "      <td>-0.012729</td>\n",
              "      <td>1.888889</td>\n",
              "      <td>74.641975</td>\n",
              "      <td>19.555556</td>\n",
              "      <td>93.749126</td>\n",
              "      <td>132.198175</td>\n",
              "      <td>0.994598</td>\n",
              "      <td>...</td>\n",
              "      <td>6.798694</td>\n",
              "      <td>0.849837</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>2.197225</td>\n",
              "      <td>1.609438</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>0</td>\n",
              "      <td>0.046875</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.875197</td>\n",
              "      <td>5.609472</td>\n",
              "      <td>6.347389</td>\n",
              "      <td>7.085901</td>\n",
              "      <td>7.825245</td>\n",
              "      <td>8.564649</td>\n",
              "      <td>9.304286</td>\n",
              "      <td>72.189262</td>\n",
              "      <td>5.209486</td>\n",
              "      <td>6.642487</td>\n",
              "      <td>8.103192</td>\n",
              "      <td>6.780995</td>\n",
              "      <td>8</td>\n",
              "      <td>31.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1189.000000</td>\n",
              "      <td>1302.611111</td>\n",
              "      <td>1463.708333</td>\n",
              "      <td>2580.0</td>\n",
              "      <td>10150.424456</td>\n",
              "      <td>24297.097283</td>\n",
              "      <td>144.232646</td>\n",
              "      <td>3.293103</td>\n",
              "      <td>3.174263</td>\n",
              "      <td>2.707368</td>\n",
              "      <td>22.241379</td>\n",
              "      <td>20.792373</td>\n",
              "      <td>87.503659</td>\n",
              "      <td>89.054234</td>\n",
              "      <td>188.393973</td>\n",
              "      <td>244.945856</td>\n",
              "      <td>211.245372</td>\n",
              "      <td>178.576482</td>\n",
              "      <td>150.884097</td>\n",
              "      <td>1.243385</td>\n",
              "      <td>1.627610</td>\n",
              "      <td>1.433857</td>\n",
              "      <td>1.251932</td>\n",
              "      <td>1.107180</td>\n",
              "      <td>165.960067</td>\n",
              "      <td>147.856207</td>\n",
              "      <td>157.989833</td>\n",
              "      <td>161.973644</td>\n",
              "      <td>164.175074</td>\n",
              "      <td>162.077837</td>\n",
              "      <td>-0.793969</td>\n",
              "      <td>1.616018</td>\n",
              "      <td>-0.948455</td>\n",
              "      <td>0.252029</td>\n",
              "      <td>37.854935</td>\n",
              "      <td>284.355364</td>\n",
              "      <td>478.282996</td>\n",
              "      <td>2270.460414</td>\n",
              "      <td>2757.360945</td>\n",
              "      <td>8.048439</td>\n",
              "      <td>...</td>\n",
              "      <td>33.463807</td>\n",
              "      <td>0.597568</td>\n",
              "      <td>99</td>\n",
              "      <td>146</td>\n",
              "      <td>199</td>\n",
              "      <td>271</td>\n",
              "      <td>347</td>\n",
              "      <td>431</td>\n",
              "      <td>544</td>\n",
              "      <td>691</td>\n",
              "      <td>3670</td>\n",
              "      <td>4.174387</td>\n",
              "      <td>4.644391</td>\n",
              "      <td>5.036953</td>\n",
              "      <td>5.342334</td>\n",
              "      <td>5.659482</td>\n",
              "      <td>5.908083</td>\n",
              "      <td>6.146329</td>\n",
              "      <td>6.378426</td>\n",
              "      <td>6.626718</td>\n",
              "      <td>6.797940</td>\n",
              "      <td>8.279190</td>\n",
              "      <td>7</td>\n",
              "      <td>0.065662</td>\n",
              "      <td>6.700731</td>\n",
              "      <td>7.653969</td>\n",
              "      <td>8.595080</td>\n",
              "      <td>9.554852</td>\n",
              "      <td>10.503395</td>\n",
              "      <td>11.468294</td>\n",
              "      <td>12.421914</td>\n",
              "      <td>13.391032</td>\n",
              "      <td>204.066919</td>\n",
              "      <td>7.893945</td>\n",
              "      <td>9.631219</td>\n",
              "      <td>11.421851</td>\n",
              "      <td>6.934293</td>\n",
              "      <td>123</td>\n",
              "      <td>406.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>624.000000</td>\n",
              "      <td>443.500000</td>\n",
              "      <td>375.611111</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>3967.930590</td>\n",
              "      <td>8249.957008</td>\n",
              "      <td>51.671283</td>\n",
              "      <td>4.176471</td>\n",
              "      <td>3.894118</td>\n",
              "      <td>3.446809</td>\n",
              "      <td>29.411765</td>\n",
              "      <td>29.459016</td>\n",
              "      <td>116.703841</td>\n",
              "      <td>113.596930</td>\n",
              "      <td>242.367468</td>\n",
              "      <td>289.569200</td>\n",
              "      <td>277.713676</td>\n",
              "      <td>233.015563</td>\n",
              "      <td>196.601563</td>\n",
              "      <td>1.519744</td>\n",
              "      <td>1.814733</td>\n",
              "      <td>1.743045</td>\n",
              "      <td>1.481888</td>\n",
              "      <td>1.313979</td>\n",
              "      <td>159.384887</td>\n",
              "      <td>146.123753</td>\n",
              "      <td>152.777264</td>\n",
              "      <td>156.625280</td>\n",
              "      <td>157.196804</td>\n",
              "      <td>166.617489</td>\n",
              "      <td>-0.292867</td>\n",
              "      <td>0.954611</td>\n",
              "      <td>-0.445755</td>\n",
              "      <td>-0.510073</td>\n",
              "      <td>10.622837</td>\n",
              "      <td>97.434845</td>\n",
              "      <td>74.820069</td>\n",
              "      <td>339.920780</td>\n",
              "      <td>-63.761998</td>\n",
              "      <td>0.384910</td>\n",
              "      <td>...</td>\n",
              "      <td>13.023861</td>\n",
              "      <td>0.591994</td>\n",
              "      <td>40</td>\n",
              "      <td>58</td>\n",
              "      <td>83</td>\n",
              "      <td>117</td>\n",
              "      <td>143</td>\n",
              "      <td>176</td>\n",
              "      <td>205</td>\n",
              "      <td>212</td>\n",
              "      <td>1296</td>\n",
              "      <td>3.465736</td>\n",
              "      <td>4.158883</td>\n",
              "      <td>4.753590</td>\n",
              "      <td>5.343530</td>\n",
              "      <td>5.930586</td>\n",
              "      <td>6.239301</td>\n",
              "      <td>6.609981</td>\n",
              "      <td>7.006667</td>\n",
              "      <td>7.293188</td>\n",
              "      <td>7.589012</td>\n",
              "      <td>8.797272</td>\n",
              "      <td>4</td>\n",
              "      <td>0.067077</td>\n",
              "      <td>5.789960</td>\n",
              "      <td>6.741701</td>\n",
              "      <td>7.679251</td>\n",
              "      <td>8.636752</td>\n",
              "      <td>9.583351</td>\n",
              "      <td>10.543366</td>\n",
              "      <td>11.494711</td>\n",
              "      <td>12.455885</td>\n",
              "      <td>124.800175</td>\n",
              "      <td>6.976348</td>\n",
              "      <td>8.697346</td>\n",
              "      <td>10.469965</td>\n",
              "      <td>8.942891</td>\n",
              "      <td>44</td>\n",
              "      <td>163.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>888.000000</td>\n",
              "      <td>882.000000</td>\n",
              "      <td>984.916667</td>\n",
              "      <td>1902.0</td>\n",
              "      <td>7513.229457</td>\n",
              "      <td>14646.475593</td>\n",
              "      <td>99.421995</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.010101</td>\n",
              "      <td>2.703704</td>\n",
              "      <td>25.360000</td>\n",
              "      <td>23.250000</td>\n",
              "      <td>100.176393</td>\n",
              "      <td>98.174860</td>\n",
              "      <td>206.950327</td>\n",
              "      <td>257.270623</td>\n",
              "      <td>222.407481</td>\n",
              "      <td>181.278366</td>\n",
              "      <td>161.255642</td>\n",
              "      <td>1.325627</td>\n",
              "      <td>1.657321</td>\n",
              "      <td>1.450887</td>\n",
              "      <td>1.196369</td>\n",
              "      <td>1.094295</td>\n",
              "      <td>164.092877</td>\n",
              "      <td>148.096863</td>\n",
              "      <td>160.321959</td>\n",
              "      <td>162.815138</td>\n",
              "      <td>165.029645</td>\n",
              "      <td>160.623030</td>\n",
              "      <td>-0.445318</td>\n",
              "      <td>0.276465</td>\n",
              "      <td>0.826667</td>\n",
              "      <td>-1.015005</td>\n",
              "      <td>15.364800</td>\n",
              "      <td>217.888889</td>\n",
              "      <td>94.528889</td>\n",
              "      <td>450.127543</td>\n",
              "      <td>656.856109</td>\n",
              "      <td>1.712591</td>\n",
              "      <td>...</td>\n",
              "      <td>25.901187</td>\n",
              "      <td>0.631736</td>\n",
              "      <td>64</td>\n",
              "      <td>85</td>\n",
              "      <td>106</td>\n",
              "      <td>130</td>\n",
              "      <td>144</td>\n",
              "      <td>155</td>\n",
              "      <td>182</td>\n",
              "      <td>210</td>\n",
              "      <td>1395</td>\n",
              "      <td>3.951244</td>\n",
              "      <td>4.477337</td>\n",
              "      <td>4.930870</td>\n",
              "      <td>5.358942</td>\n",
              "      <td>5.757718</td>\n",
              "      <td>5.883845</td>\n",
              "      <td>5.989588</td>\n",
              "      <td>6.298834</td>\n",
              "      <td>6.549293</td>\n",
              "      <td>6.845946</td>\n",
              "      <td>8.237694</td>\n",
              "      <td>4</td>\n",
              "      <td>0.058219</td>\n",
              "      <td>6.244167</td>\n",
              "      <td>7.134891</td>\n",
              "      <td>8.012018</td>\n",
              "      <td>8.905851</td>\n",
              "      <td>9.788245</td>\n",
              "      <td>10.684440</td>\n",
              "      <td>11.570147</td>\n",
              "      <td>12.468218</td>\n",
              "      <td>165.187873</td>\n",
              "      <td>7.389564</td>\n",
              "      <td>9.026538</td>\n",
              "      <td>10.711057</td>\n",
              "      <td>7.762598</td>\n",
              "      <td>73</td>\n",
              "      <td>257.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>1232.000000</td>\n",
              "      <td>1379.402778</td>\n",
              "      <td>1485.451389</td>\n",
              "      <td>2780.0</td>\n",
              "      <td>10916.498070</td>\n",
              "      <td>25526.984494</td>\n",
              "      <td>168.447097</td>\n",
              "      <td>3.179104</td>\n",
              "      <td>3.016317</td>\n",
              "      <td>2.595463</td>\n",
              "      <td>20.746269</td>\n",
              "      <td>19.458484</td>\n",
              "      <td>81.466404</td>\n",
              "      <td>85.189437</td>\n",
              "      <td>186.380100</td>\n",
              "      <td>243.193604</td>\n",
              "      <td>203.839236</td>\n",
              "      <td>171.607948</td>\n",
              "      <td>147.581898</td>\n",
              "      <td>1.257068</td>\n",
              "      <td>1.649722</td>\n",
              "      <td>1.413913</td>\n",
              "      <td>1.228548</td>\n",
              "      <td>1.107113</td>\n",
              "      <td>165.466335</td>\n",
              "      <td>146.804006</td>\n",
              "      <td>158.644010</td>\n",
              "      <td>161.943831</td>\n",
              "      <td>163.959398</td>\n",
              "      <td>161.257464</td>\n",
              "      <td>-0.738217</td>\n",
              "      <td>1.387151</td>\n",
              "      <td>-0.824367</td>\n",
              "      <td>0.209871</td>\n",
              "      <td>39.714413</td>\n",
              "      <td>257.034204</td>\n",
              "      <td>160.862553</td>\n",
              "      <td>786.583802</td>\n",
              "      <td>1673.961801</td>\n",
              "      <td>7.068197</td>\n",
              "      <td>...</td>\n",
              "      <td>32.032179</td>\n",
              "      <td>0.516648</td>\n",
              "      <td>108</td>\n",
              "      <td>156</td>\n",
              "      <td>207</td>\n",
              "      <td>277</td>\n",
              "      <td>337</td>\n",
              "      <td>408</td>\n",
              "      <td>515</td>\n",
              "      <td>638</td>\n",
              "      <td>3536</td>\n",
              "      <td>4.276666</td>\n",
              "      <td>4.736198</td>\n",
              "      <td>5.129899</td>\n",
              "      <td>5.455321</td>\n",
              "      <td>5.777652</td>\n",
              "      <td>6.023448</td>\n",
              "      <td>6.222576</td>\n",
              "      <td>6.492240</td>\n",
              "      <td>6.732211</td>\n",
              "      <td>6.924612</td>\n",
              "      <td>8.388905</td>\n",
              "      <td>8</td>\n",
              "      <td>0.058707</td>\n",
              "      <td>6.783325</td>\n",
              "      <td>7.716461</td>\n",
              "      <td>8.641709</td>\n",
              "      <td>9.578380</td>\n",
              "      <td>10.509469</td>\n",
              "      <td>11.449549</td>\n",
              "      <td>12.384758</td>\n",
              "      <td>13.328009</td>\n",
              "      <td>217.263779</td>\n",
              "      <td>7.959625</td>\n",
              "      <td>9.666435</td>\n",
              "      <td>11.424193</td>\n",
              "      <td>6.600574</td>\n",
              "      <td>130</td>\n",
              "      <td>441.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>313.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1116.0</td>\n",
              "      <td>4536.565946</td>\n",
              "      <td>4095.105547</td>\n",
              "      <td>1887.903189</td>\n",
              "      <td>3.789474</td>\n",
              "      <td>3.222222</td>\n",
              "      <td>2.517241</td>\n",
              "      <td>58.736842</td>\n",
              "      <td>36.866667</td>\n",
              "      <td>238.766629</td>\n",
              "      <td>175.379072</td>\n",
              "      <td>643.641543</td>\n",
              "      <td>327.497999</td>\n",
              "      <td>284.005017</td>\n",
              "      <td>230.107412</td>\n",
              "      <td>189.305687</td>\n",
              "      <td>99.363326</td>\n",
              "      <td>3.646473</td>\n",
              "      <td>1.992587</td>\n",
              "      <td>1.596274</td>\n",
              "      <td>1.288434</td>\n",
              "      <td>152.149026</td>\n",
              "      <td>138.058750</td>\n",
              "      <td>152.721268</td>\n",
              "      <td>161.694523</td>\n",
              "      <td>173.412139</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.789474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>93.975467</td>\n",
              "      <td>466.566813</td>\n",
              "      <td>-0.264950</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>35</td>\n",
              "      <td>37</td>\n",
              "      <td>27</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>227</td>\n",
              "      <td>2.995732</td>\n",
              "      <td>3.676301</td>\n",
              "      <td>4.154969</td>\n",
              "      <td>4.735101</td>\n",
              "      <td>5.146404</td>\n",
              "      <td>5.072827</td>\n",
              "      <td>5.319804</td>\n",
              "      <td>5.182836</td>\n",
              "      <td>5.290474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.051450</td>\n",
              "      <td>2</td>\n",
              "      <td>0.110340</td>\n",
              "      <td>5.068904</td>\n",
              "      <td>5.998937</td>\n",
              "      <td>6.886532</td>\n",
              "      <td>7.815611</td>\n",
              "      <td>8.711608</td>\n",
              "      <td>9.637371</td>\n",
              "      <td>10.538025</td>\n",
              "      <td>11.460885</td>\n",
              "      <td>96.322565</td>\n",
              "      <td>6.251904</td>\n",
              "      <td>7.918265</td>\n",
              "      <td>9.630169</td>\n",
              "      <td>11.735292</td>\n",
              "      <td>18</td>\n",
              "      <td>79.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>691.000000</td>\n",
              "      <td>878.208333</td>\n",
              "      <td>966.486111</td>\n",
              "      <td>1894.0</td>\n",
              "      <td>7411.887956</td>\n",
              "      <td>16562.874924</td>\n",
              "      <td>129.187884</td>\n",
              "      <td>2.980392</td>\n",
              "      <td>3.022293</td>\n",
              "      <td>2.511312</td>\n",
              "      <td>18.568627</td>\n",
              "      <td>17.945813</td>\n",
              "      <td>72.665568</td>\n",
              "      <td>76.510883</td>\n",
              "      <td>182.092801</td>\n",
              "      <td>238.428751</td>\n",
              "      <td>202.929059</td>\n",
              "      <td>179.413977</td>\n",
              "      <td>147.494620</td>\n",
              "      <td>1.266548</td>\n",
              "      <td>1.678534</td>\n",
              "      <td>1.458997</td>\n",
              "      <td>1.342982</td>\n",
              "      <td>1.167861</td>\n",
              "      <td>165.020469</td>\n",
              "      <td>145.950967</td>\n",
              "      <td>154.622192</td>\n",
              "      <td>159.688818</td>\n",
              "      <td>161.688365</td>\n",
              "      <td>161.974403</td>\n",
              "      <td>0.042240</td>\n",
              "      <td>0.256828</td>\n",
              "      <td>-0.278276</td>\n",
              "      <td>0.042584</td>\n",
              "      <td>34.093426</td>\n",
              "      <td>178.163739</td>\n",
              "      <td>305.111111</td>\n",
              "      <td>1463.319545</td>\n",
              "      <td>1997.089896</td>\n",
              "      <td>0.682797</td>\n",
              "      <td>...</td>\n",
              "      <td>16.208659</td>\n",
              "      <td>0.368379</td>\n",
              "      <td>76</td>\n",
              "      <td>102</td>\n",
              "      <td>139</td>\n",
              "      <td>189</td>\n",
              "      <td>247</td>\n",
              "      <td>310</td>\n",
              "      <td>385</td>\n",
              "      <td>464</td>\n",
              "      <td>2541</td>\n",
              "      <td>3.931826</td>\n",
              "      <td>4.418841</td>\n",
              "      <td>4.709530</td>\n",
              "      <td>5.023881</td>\n",
              "      <td>5.323010</td>\n",
              "      <td>5.613128</td>\n",
              "      <td>5.849325</td>\n",
              "      <td>6.061457</td>\n",
              "      <td>6.278521</td>\n",
              "      <td>6.464588</td>\n",
              "      <td>7.959276</td>\n",
              "      <td>4</td>\n",
              "      <td>0.069208</td>\n",
              "      <td>6.401917</td>\n",
              "      <td>7.362011</td>\n",
              "      <td>8.291797</td>\n",
              "      <td>9.261699</td>\n",
              "      <td>10.212405</td>\n",
              "      <td>11.189644</td>\n",
              "      <td>12.153974</td>\n",
              "      <td>13.136469</td>\n",
              "      <td>174.519304</td>\n",
              "      <td>7.614312</td>\n",
              "      <td>9.341982</td>\n",
              "      <td>11.134370</td>\n",
              "      <td>6.102040</td>\n",
              "      <td>88</td>\n",
              "      <td>301.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153 rows  242 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d23b0324-35bf-42a2-9078-6f7cbf48ac08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d23b0324-35bf-42a2-9078-6f7cbf48ac08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d23b0324-35bf-42a2-9078-6f7cbf48ac08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          ATS2dv        ATS3s        ATS4s  ...  WPol  Zagreb2  Sweet\n",
              "0     264.666667   321.879630   375.703704  ...    27    128.0   True\n",
              "1     434.000000   654.250000   643.888889  ...    39    129.0   True\n",
              "2     428.000000   676.361111   663.638889  ...    38    128.0   True\n",
              "3      92.000000   219.916667   185.666667  ...     8     31.0   True\n",
              "4    1189.000000  1302.611111  1463.708333  ...   123    406.0   True\n",
              "..           ...          ...          ...  ...   ...      ...    ...\n",
              "148   624.000000   443.500000   375.611111  ...    44    163.0   True\n",
              "149   888.000000   882.000000   984.916667  ...    73    257.0   True\n",
              "150  1232.000000  1379.402778  1485.451389  ...   130    441.0   True\n",
              "151   313.333333     0.000000     0.000000  ...    18     79.0   True\n",
              "152   691.000000   878.208333   966.486111  ...    88    301.0   True\n",
              "\n",
              "[153 rows x 242 columns]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYfsMq95QEnD"
      },
      "outputs": [],
      "source": [
        "df_test.to_csv('M_sweet_test_boruta.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSOTh-0cjb9H"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EFaOKYRjcMj"
      },
      "source": [
        "Reading Padel Data :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-WW3guWjcMj"
      },
      "outputs": [],
      "source": [
        "bitter_train_P = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Boruta/Padel/padel_bitter_train_boruta.csv\")\n",
        "bitter_test_P = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Boruta/Padel/padel_bitter_test_boruta.csv\")\n",
        "sweet_train_P = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Boruta/Padel/sweet_train_boruta.csv\")\n",
        "sweet_test_P = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Boruta/Padel/sweet_test_boruta.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szOkN3D3jcMk"
      },
      "source": [
        "Reading Mordred Data :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyWzeu3IjcMk"
      },
      "outputs": [],
      "source": [
        "bitter_train_M = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Boruta/Modred/M_bitter_train_boruta.csv\")\n",
        "bitter_test_M = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Boruta/Modred/M_bitter_test_boruta.csv\")\n",
        "sweet_train_M = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Boruta/Modred/M_sweet_train_boruta.csv\")\n",
        "sweet_test_M = pd.read_csv(\"/content/drive/MyDrive/Capstone/Features Extracted DataSets/Boruta/Modred/M_sweet_test_boruta.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "NRDQQpJ4kRLq",
        "outputId": "6a0f2e8e-9f16-4334-ffea-aeccf1ac98f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bb742678-d588-4f1f-b7ad-5678bb814313\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ATS2dv</th>\n",
              "      <th>ATS3s</th>\n",
              "      <th>ATS4s</th>\n",
              "      <th>ATS0Z</th>\n",
              "      <th>ATS0m</th>\n",
              "      <th>ATS3m</th>\n",
              "      <th>ATS0p</th>\n",
              "      <th>AATS0d</th>\n",
              "      <th>AATS3d</th>\n",
              "      <th>AATS4d</th>\n",
              "      <th>AATS0Z</th>\n",
              "      <th>AATS2Z</th>\n",
              "      <th>AATS0m</th>\n",
              "      <th>AATS1m</th>\n",
              "      <th>AATS0v</th>\n",
              "      <th>AATS1v</th>\n",
              "      <th>AATS2v</th>\n",
              "      <th>AATS3v</th>\n",
              "      <th>AATS4v</th>\n",
              "      <th>AATS0p</th>\n",
              "      <th>AATS1p</th>\n",
              "      <th>AATS2p</th>\n",
              "      <th>AATS3p</th>\n",
              "      <th>AATS4p</th>\n",
              "      <th>AATS0i</th>\n",
              "      <th>AATS1i</th>\n",
              "      <th>AATS3i</th>\n",
              "      <th>AATS4i</th>\n",
              "      <th>AATS5i</th>\n",
              "      <th>AATS7i</th>\n",
              "      <th>ATSC2c</th>\n",
              "      <th>ATSC3c</th>\n",
              "      <th>ATSC4c</th>\n",
              "      <th>ATSC5c</th>\n",
              "      <th>ATSC1d</th>\n",
              "      <th>ATSC0s</th>\n",
              "      <th>ATSC6Z</th>\n",
              "      <th>ATSC6m</th>\n",
              "      <th>ATSC6v</th>\n",
              "      <th>ATSC3se</th>\n",
              "      <th>...</th>\n",
              "      <th>MID_O</th>\n",
              "      <th>AMID_O</th>\n",
              "      <th>MPC2</th>\n",
              "      <th>MPC3</th>\n",
              "      <th>MPC4</th>\n",
              "      <th>MPC5</th>\n",
              "      <th>MPC6</th>\n",
              "      <th>MPC7</th>\n",
              "      <th>MPC8</th>\n",
              "      <th>MPC9</th>\n",
              "      <th>TMPC10</th>\n",
              "      <th>piPC1</th>\n",
              "      <th>piPC2</th>\n",
              "      <th>piPC3</th>\n",
              "      <th>piPC4</th>\n",
              "      <th>piPC5</th>\n",
              "      <th>piPC6</th>\n",
              "      <th>piPC7</th>\n",
              "      <th>piPC8</th>\n",
              "      <th>piPC9</th>\n",
              "      <th>piPC10</th>\n",
              "      <th>TpiPC10</th>\n",
              "      <th>nRing</th>\n",
              "      <th>JGI3</th>\n",
              "      <th>MWC03</th>\n",
              "      <th>MWC04</th>\n",
              "      <th>MWC05</th>\n",
              "      <th>MWC06</th>\n",
              "      <th>MWC07</th>\n",
              "      <th>MWC08</th>\n",
              "      <th>MWC09</th>\n",
              "      <th>MWC10</th>\n",
              "      <th>TMWC10</th>\n",
              "      <th>SRW06</th>\n",
              "      <th>SRW08</th>\n",
              "      <th>SRW10</th>\n",
              "      <th>AMW</th>\n",
              "      <th>WPol</th>\n",
              "      <th>Zagreb2</th>\n",
              "      <th>Sweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>532.000000</td>\n",
              "      <td>652.500000</td>\n",
              "      <td>629.083333</td>\n",
              "      <td>1158.0</td>\n",
              "      <td>4569.170871</td>\n",
              "      <td>9413.865359</td>\n",
              "      <td>50.323528</td>\n",
              "      <td>3.155556</td>\n",
              "      <td>2.830645</td>\n",
              "      <td>2.541353</td>\n",
              "      <td>25.733333</td>\n",
              "      <td>23.192771</td>\n",
              "      <td>101.537130</td>\n",
              "      <td>96.335918</td>\n",
              "      <td>181.029861</td>\n",
              "      <td>233.387037</td>\n",
              "      <td>201.265826</td>\n",
              "      <td>160.826674</td>\n",
              "      <td>144.999343</td>\n",
              "      <td>1.118301</td>\n",
              "      <td>1.445816</td>\n",
              "      <td>1.258039</td>\n",
              "      <td>1.017477</td>\n",
              "      <td>0.952669</td>\n",
              "      <td>169.548550</td>\n",
              "      <td>153.042175</td>\n",
              "      <td>166.058828</td>\n",
              "      <td>167.454386</td>\n",
              "      <td>169.891248</td>\n",
              "      <td>168.161237</td>\n",
              "      <td>-0.652482</td>\n",
              "      <td>1.204605</td>\n",
              "      <td>-0.670753</td>\n",
              "      <td>0.228861</td>\n",
              "      <td>12.975309</td>\n",
              "      <td>160.554938</td>\n",
              "      <td>-5.453827</td>\n",
              "      <td>-19.969966</td>\n",
              "      <td>125.602063</td>\n",
              "      <td>3.369352</td>\n",
              "      <td>...</td>\n",
              "      <td>20.160229</td>\n",
              "      <td>0.876532</td>\n",
              "      <td>36</td>\n",
              "      <td>51</td>\n",
              "      <td>62</td>\n",
              "      <td>73</td>\n",
              "      <td>74</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>68</td>\n",
              "      <td>608</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.951244</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.304065</td>\n",
              "      <td>4.317488</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.234107</td>\n",
              "      <td>4.060443</td>\n",
              "      <td>6.411818</td>\n",
              "      <td>2</td>\n",
              "      <td>0.082526</td>\n",
              "      <td>5.686975</td>\n",
              "      <td>6.602588</td>\n",
              "      <td>7.513709</td>\n",
              "      <td>8.434464</td>\n",
              "      <td>9.350189</td>\n",
              "      <td>10.272738</td>\n",
              "      <td>11.190528</td>\n",
              "      <td>12.113908</td>\n",
              "      <td>122.960890</td>\n",
              "      <td>6.849066</td>\n",
              "      <td>8.525360</td>\n",
              "      <td>10.247042</td>\n",
              "      <td>7.602582</td>\n",
              "      <td>43</td>\n",
              "      <td>147.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>477.111111</td>\n",
              "      <td>509.601852</td>\n",
              "      <td>424.106996</td>\n",
              "      <td>1830.0</td>\n",
              "      <td>7568.326176</td>\n",
              "      <td>11909.663100</td>\n",
              "      <td>61.317277</td>\n",
              "      <td>3.309524</td>\n",
              "      <td>2.895652</td>\n",
              "      <td>2.603306</td>\n",
              "      <td>43.571429</td>\n",
              "      <td>27.100000</td>\n",
              "      <td>180.198242</td>\n",
              "      <td>118.231375</td>\n",
              "      <td>212.281739</td>\n",
              "      <td>255.059582</td>\n",
              "      <td>215.170710</td>\n",
              "      <td>179.685807</td>\n",
              "      <td>165.227306</td>\n",
              "      <td>1.459935</td>\n",
              "      <td>1.669930</td>\n",
              "      <td>1.435949</td>\n",
              "      <td>1.191106</td>\n",
              "      <td>1.173424</td>\n",
              "      <td>167.215625</td>\n",
              "      <td>150.288731</td>\n",
              "      <td>164.818253</td>\n",
              "      <td>165.667994</td>\n",
              "      <td>168.181859</td>\n",
              "      <td>166.072550</td>\n",
              "      <td>-0.461902</td>\n",
              "      <td>0.767067</td>\n",
              "      <td>-0.461966</td>\n",
              "      <td>0.177657</td>\n",
              "      <td>10.282880</td>\n",
              "      <td>111.512642</td>\n",
              "      <td>-8.217687</td>\n",
              "      <td>-35.280625</td>\n",
              "      <td>-9.450500</td>\n",
              "      <td>2.211955</td>\n",
              "      <td>...</td>\n",
              "      <td>14.925656</td>\n",
              "      <td>0.648942</td>\n",
              "      <td>36</td>\n",
              "      <td>51</td>\n",
              "      <td>62</td>\n",
              "      <td>73</td>\n",
              "      <td>74</td>\n",
              "      <td>70</td>\n",
              "      <td>70</td>\n",
              "      <td>68</td>\n",
              "      <td>608</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.951244</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.304065</td>\n",
              "      <td>4.317488</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.262680</td>\n",
              "      <td>4.234107</td>\n",
              "      <td>4.060443</td>\n",
              "      <td>6.411818</td>\n",
              "      <td>2</td>\n",
              "      <td>0.082526</td>\n",
              "      <td>5.686975</td>\n",
              "      <td>6.602588</td>\n",
              "      <td>7.513709</td>\n",
              "      <td>8.434464</td>\n",
              "      <td>9.350189</td>\n",
              "      <td>10.272738</td>\n",
              "      <td>11.190528</td>\n",
              "      <td>12.113908</td>\n",
              "      <td>122.960890</td>\n",
              "      <td>6.849066</td>\n",
              "      <td>8.525360</td>\n",
              "      <td>10.247042</td>\n",
              "      <td>9.428918</td>\n",
              "      <td>43</td>\n",
              "      <td>147.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>348.000000</td>\n",
              "      <td>327.027778</td>\n",
              "      <td>372.666667</td>\n",
              "      <td>940.0</td>\n",
              "      <td>3710.218949</td>\n",
              "      <td>5232.341659</td>\n",
              "      <td>52.683652</td>\n",
              "      <td>2.923077</td>\n",
              "      <td>2.697674</td>\n",
              "      <td>2.467391</td>\n",
              "      <td>24.102564</td>\n",
              "      <td>20.676923</td>\n",
              "      <td>95.133819</td>\n",
              "      <td>92.739769</td>\n",
              "      <td>206.598109</td>\n",
              "      <td>251.559891</td>\n",
              "      <td>206.377537</td>\n",
              "      <td>173.668198</td>\n",
              "      <td>157.736959</td>\n",
              "      <td>1.350863</td>\n",
              "      <td>1.675350</td>\n",
              "      <td>1.429224</td>\n",
              "      <td>1.235235</td>\n",
              "      <td>1.107106</td>\n",
              "      <td>165.471161</td>\n",
              "      <td>150.112578</td>\n",
              "      <td>161.777305</td>\n",
              "      <td>165.699596</td>\n",
              "      <td>164.954150</td>\n",
              "      <td>163.395314</td>\n",
              "      <td>0.145983</td>\n",
              "      <td>0.338385</td>\n",
              "      <td>-0.698717</td>\n",
              "      <td>0.537398</td>\n",
              "      <td>4.692308</td>\n",
              "      <td>117.287749</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>316.956515</td>\n",
              "      <td>387.214257</td>\n",
              "      <td>-0.360156</td>\n",
              "      <td>...</td>\n",
              "      <td>8.731863</td>\n",
              "      <td>0.415803</td>\n",
              "      <td>27</td>\n",
              "      <td>30</td>\n",
              "      <td>33</td>\n",
              "      <td>37</td>\n",
              "      <td>32</td>\n",
              "      <td>31</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>301</td>\n",
              "      <td>3.332205</td>\n",
              "      <td>3.749504</td>\n",
              "      <td>4.020877</td>\n",
              "      <td>4.312476</td>\n",
              "      <td>4.722398</td>\n",
              "      <td>4.452165</td>\n",
              "      <td>4.599529</td>\n",
              "      <td>4.819273</td>\n",
              "      <td>4.884694</td>\n",
              "      <td>4.627421</td>\n",
              "      <td>6.767271</td>\n",
              "      <td>1</td>\n",
              "      <td>0.043981</td>\n",
              "      <td>5.351858</td>\n",
              "      <td>6.175867</td>\n",
              "      <td>6.978214</td>\n",
              "      <td>7.805882</td>\n",
              "      <td>8.618485</td>\n",
              "      <td>9.447229</td>\n",
              "      <td>10.264966</td>\n",
              "      <td>11.093995</td>\n",
              "      <td>112.311208</td>\n",
              "      <td>6.447306</td>\n",
              "      <td>7.951207</td>\n",
              "      <td>9.493487</td>\n",
              "      <td>7.541579</td>\n",
              "      <td>27</td>\n",
              "      <td>105.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>254.000000</td>\n",
              "      <td>393.500000</td>\n",
              "      <td>344.166667</td>\n",
              "      <td>612.0</td>\n",
              "      <td>2413.585500</td>\n",
              "      <td>4575.372616</td>\n",
              "      <td>25.927979</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.460317</td>\n",
              "      <td>1.772727</td>\n",
              "      <td>25.500000</td>\n",
              "      <td>23.047619</td>\n",
              "      <td>100.566063</td>\n",
              "      <td>92.993879</td>\n",
              "      <td>175.518792</td>\n",
              "      <td>227.079812</td>\n",
              "      <td>198.191463</td>\n",
              "      <td>153.270562</td>\n",
              "      <td>114.014016</td>\n",
              "      <td>1.080332</td>\n",
              "      <td>1.407855</td>\n",
              "      <td>1.237989</td>\n",
              "      <td>0.975734</td>\n",
              "      <td>0.796130</td>\n",
              "      <td>170.520236</td>\n",
              "      <td>154.381429</td>\n",
              "      <td>166.741525</td>\n",
              "      <td>172.134683</td>\n",
              "      <td>178.032893</td>\n",
              "      <td>184.993831</td>\n",
              "      <td>-0.307929</td>\n",
              "      <td>0.683571</td>\n",
              "      <td>-0.379936</td>\n",
              "      <td>-0.025630</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>95.268229</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>176.254520</td>\n",
              "      <td>243.836186</td>\n",
              "      <td>1.606344</td>\n",
              "      <td>...</td>\n",
              "      <td>10.677995</td>\n",
              "      <td>0.889833</td>\n",
              "      <td>18</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>135</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>2.944439</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>3.135494</td>\n",
              "      <td>3.178054</td>\n",
              "      <td>2.890372</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.912655</td>\n",
              "      <td>1</td>\n",
              "      <td>0.065625</td>\n",
              "      <td>4.962845</td>\n",
              "      <td>5.849325</td>\n",
              "      <td>6.722630</td>\n",
              "      <td>7.610358</td>\n",
              "      <td>8.487764</td>\n",
              "      <td>9.375092</td>\n",
              "      <td>10.253827</td>\n",
              "      <td>11.140687</td>\n",
              "      <td>92.513402</td>\n",
              "      <td>6.163315</td>\n",
              "      <td>7.845024</td>\n",
              "      <td>9.569063</td>\n",
              "      <td>7.502641</td>\n",
              "      <td>20</td>\n",
              "      <td>71.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>518.000000</td>\n",
              "      <td>682.541667</td>\n",
              "      <td>614.847222</td>\n",
              "      <td>1158.0</td>\n",
              "      <td>4569.170871</td>\n",
              "      <td>9127.853377</td>\n",
              "      <td>50.323528</td>\n",
              "      <td>3.155556</td>\n",
              "      <td>2.661290</td>\n",
              "      <td>2.270677</td>\n",
              "      <td>25.733333</td>\n",
              "      <td>23.192771</td>\n",
              "      <td>101.537130</td>\n",
              "      <td>96.335918</td>\n",
              "      <td>181.029861</td>\n",
              "      <td>233.387037</td>\n",
              "      <td>201.265826</td>\n",
              "      <td>157.905783</td>\n",
              "      <td>132.343321</td>\n",
              "      <td>1.118301</td>\n",
              "      <td>1.445816</td>\n",
              "      <td>1.258039</td>\n",
              "      <td>1.008267</td>\n",
              "      <td>0.897097</td>\n",
              "      <td>169.548550</td>\n",
              "      <td>153.042175</td>\n",
              "      <td>166.015110</td>\n",
              "      <td>169.040621</td>\n",
              "      <td>171.734788</td>\n",
              "      <td>166.939623</td>\n",
              "      <td>-0.628096</td>\n",
              "      <td>1.224730</td>\n",
              "      <td>-0.715289</td>\n",
              "      <td>0.159067</td>\n",
              "      <td>10.975309</td>\n",
              "      <td>160.554938</td>\n",
              "      <td>87.169383</td>\n",
              "      <td>415.124614</td>\n",
              "      <td>512.973197</td>\n",
              "      <td>3.182088</td>\n",
              "      <td>...</td>\n",
              "      <td>20.110824</td>\n",
              "      <td>0.874384</td>\n",
              "      <td>36</td>\n",
              "      <td>49</td>\n",
              "      <td>56</td>\n",
              "      <td>62</td>\n",
              "      <td>58</td>\n",
              "      <td>53</td>\n",
              "      <td>58</td>\n",
              "      <td>67</td>\n",
              "      <td>557</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.912023</td>\n",
              "      <td>4.043051</td>\n",
              "      <td>4.143135</td>\n",
              "      <td>4.077537</td>\n",
              "      <td>3.988984</td>\n",
              "      <td>4.077537</td>\n",
              "      <td>4.219508</td>\n",
              "      <td>4.276666</td>\n",
              "      <td>6.324359</td>\n",
              "      <td>2</td>\n",
              "      <td>0.077405</td>\n",
              "      <td>5.673323</td>\n",
              "      <td>6.575076</td>\n",
              "      <td>7.467942</td>\n",
              "      <td>8.371242</td>\n",
              "      <td>9.267193</td>\n",
              "      <td>10.170725</td>\n",
              "      <td>11.068184</td>\n",
              "      <td>11.971710</td>\n",
              "      <td>122.361186</td>\n",
              "      <td>6.836259</td>\n",
              "      <td>8.493105</td>\n",
              "      <td>10.192007</td>\n",
              "      <td>7.602582</td>\n",
              "      <td>41</td>\n",
              "      <td>145.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2162</th>\n",
              "      <td>123.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>77.166667</td>\n",
              "      <td>374.0</td>\n",
              "      <td>1471.157473</td>\n",
              "      <td>1698.267489</td>\n",
              "      <td>25.377020</td>\n",
              "      <td>2.722222</td>\n",
              "      <td>2.468750</td>\n",
              "      <td>2.068966</td>\n",
              "      <td>20.777778</td>\n",
              "      <td>18.068966</td>\n",
              "      <td>81.730971</td>\n",
              "      <td>83.733809</td>\n",
              "      <td>205.782053</td>\n",
              "      <td>249.208791</td>\n",
              "      <td>199.761175</td>\n",
              "      <td>172.007401</td>\n",
              "      <td>139.293359</td>\n",
              "      <td>1.409834</td>\n",
              "      <td>1.732770</td>\n",
              "      <td>1.435561</td>\n",
              "      <td>1.283351</td>\n",
              "      <td>1.117860</td>\n",
              "      <td>163.806151</td>\n",
              "      <td>147.310599</td>\n",
              "      <td>163.635093</td>\n",
              "      <td>161.168289</td>\n",
              "      <td>162.830109</td>\n",
              "      <td>184.917652</td>\n",
              "      <td>-0.044889</td>\n",
              "      <td>0.081225</td>\n",
              "      <td>-0.072734</td>\n",
              "      <td>0.023068</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>24.989198</td>\n",
              "      <td>26.666667</td>\n",
              "      <td>134.419914</td>\n",
              "      <td>397.674863</td>\n",
              "      <td>0.021610</td>\n",
              "      <td>...</td>\n",
              "      <td>1.727010</td>\n",
              "      <td>0.191890</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>3.068053</td>\n",
              "      <td>3.504055</td>\n",
              "      <td>3.944006</td>\n",
              "      <td>4.328263</td>\n",
              "      <td>3.840795</td>\n",
              "      <td>3.056357</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.583496</td>\n",
              "      <td>1</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>4.465908</td>\n",
              "      <td>5.262690</td>\n",
              "      <td>6.033086</td>\n",
              "      <td>6.834109</td>\n",
              "      <td>7.608374</td>\n",
              "      <td>8.409831</td>\n",
              "      <td>9.185125</td>\n",
              "      <td>9.986495</td>\n",
              "      <td>79.499191</td>\n",
              "      <td>5.556828</td>\n",
              "      <td>7.062192</td>\n",
              "      <td>8.606851</td>\n",
              "      <td>6.837134</td>\n",
              "      <td>9</td>\n",
              "      <td>43.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2163</th>\n",
              "      <td>128.000000</td>\n",
              "      <td>112.111111</td>\n",
              "      <td>95.500000</td>\n",
              "      <td>388.0</td>\n",
              "      <td>1529.913361</td>\n",
              "      <td>1732.115297</td>\n",
              "      <td>24.365611</td>\n",
              "      <td>2.823529</td>\n",
              "      <td>2.437500</td>\n",
              "      <td>1.766667</td>\n",
              "      <td>22.823529</td>\n",
              "      <td>20.038462</td>\n",
              "      <td>89.994904</td>\n",
              "      <td>88.180785</td>\n",
              "      <td>214.474695</td>\n",
              "      <td>260.148487</td>\n",
              "      <td>225.702851</td>\n",
              "      <td>173.980851</td>\n",
              "      <td>117.158084</td>\n",
              "      <td>1.433271</td>\n",
              "      <td>1.761870</td>\n",
              "      <td>1.584842</td>\n",
              "      <td>1.283753</td>\n",
              "      <td>0.936417</td>\n",
              "      <td>161.047311</td>\n",
              "      <td>146.079470</td>\n",
              "      <td>155.014611</td>\n",
              "      <td>165.020611</td>\n",
              "      <td>173.254972</td>\n",
              "      <td>185.050964</td>\n",
              "      <td>0.017422</td>\n",
              "      <td>0.040603</td>\n",
              "      <td>-0.074446</td>\n",
              "      <td>-0.044465</td>\n",
              "      <td>1.941176</td>\n",
              "      <td>40.392157</td>\n",
              "      <td>-2.373702</td>\n",
              "      <td>-13.886239</td>\n",
              "      <td>-30.988205</td>\n",
              "      <td>-0.191351</td>\n",
              "      <td>...</td>\n",
              "      <td>3.480679</td>\n",
              "      <td>0.386742</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>2.564949</td>\n",
              "      <td>3.068053</td>\n",
              "      <td>3.504055</td>\n",
              "      <td>3.899444</td>\n",
              "      <td>4.385925</td>\n",
              "      <td>3.876396</td>\n",
              "      <td>2.784239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.579258</td>\n",
              "      <td>1</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>4.465908</td>\n",
              "      <td>5.252273</td>\n",
              "      <td>6.028279</td>\n",
              "      <td>6.816736</td>\n",
              "      <td>7.598399</td>\n",
              "      <td>8.386401</td>\n",
              "      <td>9.169831</td>\n",
              "      <td>9.957265</td>\n",
              "      <td>79.388664</td>\n",
              "      <td>5.556828</td>\n",
              "      <td>7.055313</td>\n",
              "      <td>8.590258</td>\n",
              "      <td>7.297202</td>\n",
              "      <td>9</td>\n",
              "      <td>43.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2164</th>\n",
              "      <td>244.000000</td>\n",
              "      <td>156.333333</td>\n",
              "      <td>158.666667</td>\n",
              "      <td>554.0</td>\n",
              "      <td>2192.478078</td>\n",
              "      <td>3088.803862</td>\n",
              "      <td>39.321520</td>\n",
              "      <td>3.347826</td>\n",
              "      <td>3.086957</td>\n",
              "      <td>2.756098</td>\n",
              "      <td>24.086957</td>\n",
              "      <td>22.432432</td>\n",
              "      <td>95.325134</td>\n",
              "      <td>98.698891</td>\n",
              "      <td>253.115716</td>\n",
              "      <td>294.149276</td>\n",
              "      <td>259.728419</td>\n",
              "      <td>210.713375</td>\n",
              "      <td>190.455121</td>\n",
              "      <td>1.709631</td>\n",
              "      <td>2.020918</td>\n",
              "      <td>1.823509</td>\n",
              "      <td>1.518599</td>\n",
              "      <td>1.366621</td>\n",
              "      <td>155.760108</td>\n",
              "      <td>140.845633</td>\n",
              "      <td>152.012987</td>\n",
              "      <td>155.402614</td>\n",
              "      <td>155.365994</td>\n",
              "      <td>165.115362</td>\n",
              "      <td>-0.084842</td>\n",
              "      <td>0.048049</td>\n",
              "      <td>-0.037491</td>\n",
              "      <td>0.021029</td>\n",
              "      <td>2.918715</td>\n",
              "      <td>34.637681</td>\n",
              "      <td>-40.049149</td>\n",
              "      <td>-193.673897</td>\n",
              "      <td>-379.304122</td>\n",
              "      <td>0.004051</td>\n",
              "      <td>...</td>\n",
              "      <td>1.785574</td>\n",
              "      <td>0.127541</td>\n",
              "      <td>19</td>\n",
              "      <td>24</td>\n",
              "      <td>28</td>\n",
              "      <td>32</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>20</td>\n",
              "      <td>16</td>\n",
              "      <td>228</td>\n",
              "      <td>3.135494</td>\n",
              "      <td>3.663562</td>\n",
              "      <td>4.226834</td>\n",
              "      <td>4.711780</td>\n",
              "      <td>5.192262</td>\n",
              "      <td>5.029621</td>\n",
              "      <td>5.364222</td>\n",
              "      <td>5.432903</td>\n",
              "      <td>5.614496</td>\n",
              "      <td>5.731874</td>\n",
              "      <td>7.380791</td>\n",
              "      <td>2</td>\n",
              "      <td>0.048611</td>\n",
              "      <td>5.043425</td>\n",
              "      <td>5.866468</td>\n",
              "      <td>6.693324</td>\n",
              "      <td>7.524561</td>\n",
              "      <td>8.356790</td>\n",
              "      <td>9.191056</td>\n",
              "      <td>10.025307</td>\n",
              "      <td>10.860786</td>\n",
              "      <td>96.795823</td>\n",
              "      <td>6.137727</td>\n",
              "      <td>7.690286</td>\n",
              "      <td>9.282754</td>\n",
              "      <td>7.959496</td>\n",
              "      <td>18</td>\n",
              "      <td>77.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2165</th>\n",
              "      <td>139.000000</td>\n",
              "      <td>133.861111</td>\n",
              "      <td>100.500000</td>\n",
              "      <td>464.0</td>\n",
              "      <td>1822.505859</td>\n",
              "      <td>1810.708633</td>\n",
              "      <td>31.721863</td>\n",
              "      <td>2.695652</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>2.119048</td>\n",
              "      <td>20.173913</td>\n",
              "      <td>17.300000</td>\n",
              "      <td>79.239385</td>\n",
              "      <td>81.560434</td>\n",
              "      <td>200.758200</td>\n",
              "      <td>246.659266</td>\n",
              "      <td>187.961032</td>\n",
              "      <td>153.975425</td>\n",
              "      <td>135.422656</td>\n",
              "      <td>1.379211</td>\n",
              "      <td>1.725728</td>\n",
              "      <td>1.348699</td>\n",
              "      <td>1.156479</td>\n",
              "      <td>1.093426</td>\n",
              "      <td>162.220157</td>\n",
              "      <td>143.993713</td>\n",
              "      <td>161.301195</td>\n",
              "      <td>161.379540</td>\n",
              "      <td>163.145897</td>\n",
              "      <td>166.400287</td>\n",
              "      <td>0.081851</td>\n",
              "      <td>-0.146009</td>\n",
              "      <td>-0.116511</td>\n",
              "      <td>0.206536</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>37.637681</td>\n",
              "      <td>-15.939509</td>\n",
              "      <td>-72.856945</td>\n",
              "      <td>-16.437701</td>\n",
              "      <td>-1.550203</td>\n",
              "      <td>...</td>\n",
              "      <td>3.688551</td>\n",
              "      <td>0.335323</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>2.740840</td>\n",
              "      <td>3.228826</td>\n",
              "      <td>3.522677</td>\n",
              "      <td>3.962003</td>\n",
              "      <td>3.852804</td>\n",
              "      <td>3.610918</td>\n",
              "      <td>3.725693</td>\n",
              "      <td>3.725693</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.698142</td>\n",
              "      <td>1</td>\n",
              "      <td>0.063272</td>\n",
              "      <td>4.672829</td>\n",
              "      <td>5.484797</td>\n",
              "      <td>6.255750</td>\n",
              "      <td>7.069023</td>\n",
              "      <td>7.854381</td>\n",
              "      <td>8.666130</td>\n",
              "      <td>9.459619</td>\n",
              "      <td>10.269900</td>\n",
              "      <td>85.664256</td>\n",
              "      <td>5.739793</td>\n",
              "      <td>7.172425</td>\n",
              "      <td>8.645235</td>\n",
              "      <td>6.612336</td>\n",
              "      <td>9</td>\n",
              "      <td>53.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2166</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>530.0</td>\n",
              "      <td>2120.214214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>522.015634</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>424.042843</td>\n",
              "      <td>16.126992</td>\n",
              "      <td>632.176246</td>\n",
              "      <td>82.013631</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>104.403127</td>\n",
              "      <td>0.534768</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.621720</td>\n",
              "      <td>185.184277</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.480000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.793614</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2167 rows  242 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb742678-d588-4f1f-b7ad-5678bb814313')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb742678-d588-4f1f-b7ad-5678bb814313 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb742678-d588-4f1f-b7ad-5678bb814313');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          ATS2dv       ATS3s       ATS4s  ...  WPol  Zagreb2  Sweet\n",
              "0     532.000000  652.500000  629.083333  ...    43    147.0   True\n",
              "1     477.111111  509.601852  424.106996  ...    43    147.0   True\n",
              "2     348.000000  327.027778  372.666667  ...    27    105.0   True\n",
              "3     254.000000  393.500000  344.166667  ...    20     71.0   True\n",
              "4     518.000000  682.541667  614.847222  ...    41    145.0   True\n",
              "...          ...         ...         ...  ...   ...      ...    ...\n",
              "2162  123.000000  103.000000   77.166667  ...     9     43.0  False\n",
              "2163  128.000000  112.111111   95.500000  ...     9     43.0  False\n",
              "2164  244.000000  156.333333  158.666667  ...    18     77.0  False\n",
              "2165  139.000000  133.861111  100.500000  ...     9     53.0  False\n",
              "2166    0.000000    0.000000    0.000000  ...     0      0.0  False\n",
              "\n",
              "[2167 rows x 242 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sweet_train_M"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLyfrZpXMCFw"
      },
      "source": [
        "# **CHEM_TASTE_DB**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nZNuFgwOn5H"
      },
      "outputs": [],
      "source": [
        "def findPredictionsModred(x_Train, x_Test, y_Train, y_Test):\n",
        "\n",
        "  #Preparing data for PCA\n",
        "  pca2 = PCA(n_components=2)\n",
        "  x_pca2_data_train = pca2.fit_transform(x_Train)\n",
        "  x_pca2_data_test = pca2.fit_transform(x_Test)\n",
        "\n",
        "  pca10 = PCA(n_components=10)\n",
        "  x_pca10_data_train = pca10.fit_transform(x_Train)\n",
        "  x_pca10_data_test = pca10.fit_transform(x_Test)\n",
        "\n",
        "  \n",
        "  \n",
        "  #Preparing data for Correlation matrix on features\n",
        "  train_data = pd.concat([x_Train,y_Train],axis=1)\n",
        "  test_data = pd.concat([x_Test,y_Test],axis=1)\n",
        "  train_corr , test_corr = correlation_check(train_data, test_data,0.8)\n",
        "\n",
        "  \n",
        "  x_Train_corr = train_corr.drop(['Class taste'],axis=1)\n",
        "  x_Test_corr = test_corr.drop(['Class taste'],axis=1)\n",
        "\n",
        "  \n",
        "  \n",
        "  #Preparing data for Correlation matrix on features and Labels\n",
        "\n",
        "  a = x_Train_corr.corr(method ='pearson').abs()\n",
        "  df_temp = a.head(1)\n",
        "  df_temp.fillna(0,inplace = True)\n",
        "\n",
        "  colList = []\n",
        "  for i in df_temp.columns:\n",
        "    if(df_temp[i].item() < 0.1):\n",
        "      colList.append(i)\n",
        "\n",
        "  for i in colList:\n",
        "    new_x_train_corr = x_Train_corr.drop(i,axis = 1)\n",
        "\n",
        "  for i in colList:\n",
        "    new_x_test_corr = x_Test_corr.drop(i,axis = 1)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #Preparing data for selectkBest\n",
        "  from sklearn.feature_selection import SelectKBest, f_classif\n",
        "  \n",
        "  X_new = SelectKBest(f_classif, k=200).fit(x_Train, y_Train)\n",
        "  cols = X_new.get_support(indices=True)\n",
        "  features_df_new_train = x_Train.iloc[:,cols]\n",
        "  features_df_new_test = x_Test.iloc[:,cols]\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  #Applying Models : \n",
        "  #---------------------\n",
        "\n",
        "  #1. Logistic Regression :\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "  clfLR1 = LogisticRegression(random_state=0)\n",
        "  \n",
        "  print(\"Logistic Regression : \")\n",
        "  print(\"------------------------\")\n",
        "  print()\n",
        "\n",
        "  \n",
        "  clfLR_Basic = clfLR1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfLR_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic,average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_Basic,average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  clfLR2 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLRpca2 = clfLR2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfLRpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca2, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca2, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  clfLR3 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLRpca10 = clfLR3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfLRpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca10, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca10, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "  clfLR4 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_CMF = clfLR4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfLR_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMF, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  clfLR5 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_CMFL = clfLR5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfLR_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMFL, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "  clfLR6 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_selectK = clfLR6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfLR_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_selectK, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "  #=====================================================================================================================================================\n",
        "\n",
        "  #2. Random forgest :\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "  clfRF1 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=20, criterion='entropy', random_state=30)\n",
        "  \n",
        "  print(\"Random Forest : \")\n",
        "  print(\"----------------\")\n",
        "  print()\n",
        "\n",
        "  clfRF_Basic = clfRF1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfRF_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic,average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_Basic,average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  clfRF2 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=20, criterion='entropy', random_state=30)\n",
        "\n",
        "\n",
        "  clfRFpca2 = clfRF2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfRFpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca2, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca2, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  clfRF3 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=20, criterion='entropy', random_state=30)\n",
        "\n",
        "\n",
        "  clfRFpca10 = clfRF3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfRFpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca10, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca10, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "\n",
        "  clfRF4 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=20, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfRF_CMF = clfRF4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfRF_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMF, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  clfRF5 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=20, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfLR_CMFL = clfRF5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfLR_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMFL, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "\n",
        "  clfRF6 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=20, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfRF_selectK = clfRF6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfRF_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_selectK, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #3. Adaboost\n",
        "  from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "  clfAB1 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  print(\"AdaBoost : \")\n",
        "  print(\"----------------\")\n",
        "  print()\n",
        "\n",
        "  clfAB_Basic = clfAB1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfAB_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic,average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_Basic,average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  clfAB2 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfABpca2 = clfAB2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfABpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca2, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca2, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  clfAB3 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfABpca10 = clfAB3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfABpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca10, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca10, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "\n",
        "  clfAB4 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfAB_CMF = clfAB4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfAB_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMF, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  clfAB5 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfAB_CMFL = clfAB5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfAB_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMFL, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "  clfAB6 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "\n",
        "  clfAB_selectK = clfAB6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfAB_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_selectK, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  #4. XGBoostClassifier\n",
        "  import xgboost as xg\n",
        "\n",
        "  xgb_r1 = xg.XGBClassifier(max_depth=10)\n",
        "\n",
        "  print(\"XGBoostClassifier : \")\n",
        "  print(\"----------------\")\n",
        "  print()\n",
        "\n",
        "  clfXGB_Basic = xgb_r1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfXGB_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic,average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_Basic,average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  xgb_r2 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  clfXGBpca2 = xgb_r2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfXGBpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca2, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca2, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  xgb_r3 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "\n",
        "  clfXGBpca10 = xgb_r3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfXGBpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca10, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca10, average='macro'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "\n",
        "  xgb_r4 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  clfXGB_CMF = xgb_r4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfXGB_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMF, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  xgb_r5 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  clfXGB_CMFL = xgb_r5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfXGB_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMFL, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "  xgb_r6 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  clfXGB_selectK = xgb_r6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfXGB_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_selectK, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDkgNkB662_t"
      },
      "outputs": [],
      "source": [
        "def findPredictionsPadel(x_Train, x_Test, y_Train, y_Test):\n",
        "\n",
        "  #Preparing data for PCA\n",
        "  pca2 = PCA(n_components=2)\n",
        "  x_pca2_data_train = pca2.fit_transform(x_Train)\n",
        "  x_pca2_data_test = pca2.fit_transform(x_Test)\n",
        "\n",
        "  pca10 = PCA(n_components=10)\n",
        "  x_pca10_data_train = pca10.fit_transform(x_Train)\n",
        "  x_pca10_data_test = pca10.fit_transform(x_Test)\n",
        "\n",
        "  \n",
        "  \n",
        "  #Preparing data for Correlation matrix on features\n",
        "  train_data = pd.concat([x_Train,y_Train],axis=1)\n",
        "  test_data = pd.concat([x_Test,y_Test],axis=1)\n",
        "  train_corr , test_corr = correlation_check(train_data, test_data,0.8)\n",
        "\n",
        "  \n",
        "  x_Train_corr = train_corr.drop(['Class Taste'],axis=1)\n",
        "  x_Test_corr = test_corr.drop(['Class Taste'],axis=1)\n",
        "\n",
        "  \n",
        "  \n",
        "  #Preparing data for Correlation matrix on features and Labels\n",
        "\n",
        "  a = x_Train_corr.corr(method ='pearson').abs()\n",
        "  df_temp = a.head(1)\n",
        "  df_temp.fillna(0,inplace = True)\n",
        "\n",
        "  colList = []\n",
        "  for i in df_temp.columns:\n",
        "    if(df_temp[i].item() < 0.1):\n",
        "      colList.append(i)\n",
        "\n",
        "  for i in colList:\n",
        "    new_x_train_corr = x_Train_corr.drop(i,axis = 1)\n",
        "\n",
        "  for i in colList:\n",
        "    new_x_test_corr = x_Test_corr.drop(i,axis = 1)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #Preparing data for selectkBest\n",
        "  from sklearn.feature_selection import SelectKBest, f_classif\n",
        "  \n",
        "  X_new = SelectKBest(f_classif, k=200).fit(x_Train, y_Train)\n",
        "  cols = X_new.get_support(indices=True)\n",
        "  features_df_new_train = x_Train.iloc[:,cols]\n",
        "  features_df_new_test = x_Test.iloc[:,cols]\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  #Applying Models : \n",
        "  #---------------------\n",
        "\n",
        "  #1. Logistic Regression :\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "  clfLR1 = LogisticRegression(random_state=0)\n",
        "  \n",
        "  print(\"Logistic Regression : \")\n",
        "  print(\"------------------------\")\n",
        "  print()\n",
        "\n",
        "  \n",
        "  clfLR_Basic = clfLR1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfLR_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic,average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_Basic,average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  clfLR2 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLRpca2 = clfLR2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfLRpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca2, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca2, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  clfLR3 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLRpca10 = clfLR3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfLRpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca10, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca10, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "  clfLR4 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_CMF = clfLR4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfLR_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMF, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  clfLR5 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_CMFL = clfLR5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfLR_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMFL, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "  clfLR6 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_selectK = clfLR6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfLR_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_selectK, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "  #=====================================================================================================================================================\n",
        "\n",
        "  #2. Random forgest :\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "  clfRF1 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "  \n",
        "  print(\"Random Forest : \")\n",
        "  print(\"----------------\")\n",
        "  print()\n",
        "\n",
        "  clfRF_Basic = clfRF1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfRF_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic,average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_Basic,average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  clfRF2 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "\n",
        "  clfRFpca2 = clfRF2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfRFpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca2, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca2, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  clfRF3 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "\n",
        "  clfRFpca10 = clfRF3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfRFpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca10, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca10, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "\n",
        "  clfRF4 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfRF_CMF = clfRF4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfRF_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMF, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  clfRF5 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfLR_CMFL = clfRF5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfLR_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMFL, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "\n",
        "  clfRF6 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfRF_selectK = clfRF6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfRF_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_selectK, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #3. Adaboost\n",
        "  from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "  clfAB1 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  print(\"AdaBoost : \")\n",
        "  print(\"----------------\")\n",
        "  print()\n",
        "\n",
        "  clfAB_Basic = clfAB1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfAB_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic,average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_Basic,average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  clfAB2 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfABpca2 = clfAB2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfABpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca2, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca2, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  clfAB3 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfABpca10 = clfAB3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfABpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca10, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca10, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "\n",
        "  clfAB4 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfAB_CMF = clfAB4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfAB_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMF, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  clfAB5 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfAB_CMFL = clfAB5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfAB_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMFL, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "  clfAB6 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "\n",
        "  clfAB_selectK = clfAB6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfAB_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_selectK, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  #4. XGBoostClassifier\n",
        "  import xgboost as xg\n",
        "\n",
        "  xgb_r1 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  print(\"XGBoostClassifier : \")\n",
        "  print(\"----------------\")\n",
        "  print()\n",
        "\n",
        "  clfXGB_Basic = xgb_r1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfXGB_Basic.predict(x_Test)\n",
        "  print(\"Basic ==>                          Precision: \",precision_score(y_Test, y_pred_Basic,average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_Basic,average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_Basic, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_Basic))\n",
        "  print()\n",
        "\n",
        "  xgb_r2 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  clfXGBpca2 = xgb_r2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfXGBpca2.predict(x_pca2_data_test)\n",
        "  print(\"PCA with n = 2 ==>                 Precision: \",precision_score(y_Test, y_predPca2, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca2, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca2, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_predPca2))\n",
        "  print()\n",
        "\n",
        "  xgb_r3 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "\n",
        "  clfXGBpca10 = xgb_r3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfXGBpca10.predict(x_pca10_data_test)\n",
        "  print(\"PCA with n = 10 ==>                Precision: \",precision_score(y_Test, y_predPca10, average='weighted'),\" Recall: \",recall_score(y_Test, y_predPca10, average='weighted'),\"  F1: \",f1_score(y_Test, y_predPca10, average='macro'),\" Accuracy: \",accuracy_score(y_Test, y_predPca10))\n",
        "  print()\n",
        "\n",
        "\n",
        "  xgb_r4 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  clfXGB_CMF = xgb_r4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfXGB_CMF.predict(x_Test_corr)\n",
        "  print(\"Correlation Matrix on Features ==> Precision: \",precision_score(y_Test, y_pred_CMF, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMF, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMF, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMF))\n",
        "  print()\n",
        "\n",
        "  xgb_r5 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  clfXGB_CMFL = xgb_r5.fit(new_x_train_corr, y_Train)\n",
        "  y_pred_CMFL = clfXGB_CMFL.predict(new_x_test_corr)\n",
        "  print(\"CorMatrix on Features & Labels ==> Precision: \",precision_score(y_Test, y_pred_CMFL, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_CMFL, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_CMFL, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_CMFL))\n",
        "  print()\n",
        "\n",
        "  xgb_r6 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  clfXGB_selectK = xgb_r6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfXGB_selectK.predict(features_df_new_test)\n",
        "  print(\"SelectK best with k = 200 ==>      Precision: \",precision_score(y_Test, y_pred_selectK, average='weighted'),\" Recall: \",recall_score(y_Test, y_pred_selectK, average='weighted'),\"  F1: \",f1_score(y_Test, y_pred_selectK, average='weighted'),\" Accuracy: \",accuracy_score(y_Test, y_pred_selectK))\n",
        "  print()\n",
        "\n",
        "\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ9SNjTWOn5k"
      },
      "outputs": [],
      "source": [
        "def correlation_check(traindata,testdata,thresh): # drop columns above certain threshold    \n",
        "        corr_matrix = traindata.corr()\n",
        "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "        to_drop = [column for column in upper.columns if any(upper[column] >thresh)]\n",
        "        trainset=traindata.drop(traindata[to_drop], axis=1)\n",
        "        testset=testdata.drop(testdata[to_drop],axis=1)\n",
        "        return trainset,testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tnPCZHVOn5l"
      },
      "outputs": [],
      "source": [
        "def gridSearchOnLogReg(x, y):\n",
        "  grid={\n",
        "        \"C\":np.logspace(-3,3,7,1,0),\n",
        "        \"penalty\":[\"l1\",\"l2\",\"elasticnet\",\"none\"],\n",
        "        \"max_iter\":[50,80,100],\n",
        "        \"solver\":[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
        "        }\n",
        "  logreg=LogisticRegression()\n",
        "  logreg_cv=GridSearchCV(logreg,grid)\n",
        "  logreg_cv.fit(x,y)\n",
        "  return logreg_cv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ8cltfosPDN"
      },
      "source": [
        "**MORDRED DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoQBeDGAMJoF"
      },
      "outputs": [],
      "source": [
        "chemTasteDB = pd.read_csv(\"/content/drive/MyDrive/Capstone/chemTasteDB/Mordred Cleaned/chemTasteDBCleaned.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uojPMEuFMj5b"
      },
      "outputs": [],
      "source": [
        "y = chemTasteDB['Class taste']\n",
        "x = chemTasteDB.drop(['Class taste','Name','Taste'],axis=1)\n",
        "y=y.to_frame()\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NISOCrb0PsKj",
        "outputId": "f86ba329-43d4-4536-8b8c-6f5cf79d9be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression : \n",
            "------------------------\n",
            "\n",
            "Basic ==>                          Precision:  0.29935297681348005  Recall:  0.37907608695652173   F1:  0.3277825252691276  Accuracy:  0.37907608695652173\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.22755819947655007  Recall:  0.35054347826086957   F1:  0.2448037247309764  Accuracy:  0.35054347826086957\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.2283682870397116  Recall:  0.3491847826086957   F1:  0.24636972180176422  Accuracy:  0.3491847826086957\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.24888978403450093  Recall:  0.35597826086956524   F1:  0.25339010682190904  Accuracy:  0.35597826086956524\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.24888978403450093  Recall:  0.35597826086956524   F1:  0.25339010682190904  Accuracy:  0.35597826086956524\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.14784860881379963  Recall:  0.3845108695652174   F1:  0.21357522293808937  Accuracy:  0.3845108695652174\n",
            "\n",
            "Random Forest : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.7140473708019428  Recall:  0.720108695652174   F1:  0.7022225198643011  Accuracy:  0.720108695652174\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.11496089650869282  Recall:  0.07744565217391304   F1:  0.08022699366472683  Accuracy:  0.07744565217391304\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.2733184908094456  Recall:  0.38315217391304346   F1:  0.23538599171649763  Accuracy:  0.38315217391304346\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.6971093126409992  Recall:  0.7092391304347826   F1:  0.682906144123476  Accuracy:  0.7092391304347826\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.6917637844611528  Recall:  0.7051630434782609   F1:  0.679230464794358  Accuracy:  0.7051630434782609\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.6867701548709395  Recall:  0.7078804347826086   F1:  0.688030255012285  Accuracy:  0.7078804347826086\n",
            "\n",
            "AdaBoost : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.4560927962165532  Recall:  0.5067934782608695   F1:  0.4684218395257308  Accuracy:  0.5067934782608695\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.14825146605852388  Recall:  0.3845108695652174   F1:  0.21399523320935404  Accuracy:  0.3845108695652174\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.4985937011243391  Recall:  0.19293478260869565   F1:  0.16262202126450365  Accuracy:  0.19293478260869565\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.40140113046445913  Recall:  0.5380434782608695   F1:  0.45309473481504176  Accuracy:  0.5380434782608695\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.40140113046445913  Recall:  0.5380434782608695   F1:  0.45309473481504176  Accuracy:  0.5380434782608695\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.4005827248495418  Recall:  0.5380434782608695   F1:  0.4526717385122711  Accuracy:  0.5380434782608695\n",
            "\n",
            "XGBoostClassifier : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.7055053707170653  Recall:  0.720108695652174   F1:  0.7052840390766209  Accuracy:  0.720108695652174\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.11308719579089913  Recall:  0.07608695652173914   F1:  0.07860541107950697  Accuracy:  0.07608695652173914\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.3499748287128159  Recall:  0.37771739130434784   F1:  0.1201153060483829  Accuracy:  0.37771739130434784\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.7103187827107498  Recall:  0.7228260869565217   F1:  0.7082989420742115  Accuracy:  0.7228260869565217\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.6942281106073339  Recall:  0.7092391304347826   F1:  0.6931113652197698  Accuracy:  0.7092391304347826\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.6947878746595212  Recall:  0.7146739130434783   F1:  0.6971345507795766  Accuracy:  0.7146739130434783\n",
            "\n"
          ]
        }
      ],
      "source": [
        "findPredictionsModred(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ5wJTYDvHQ7"
      },
      "source": [
        "**PADEL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiuU9X1BvHQ8"
      },
      "outputs": [],
      "source": [
        "chemTasteDB = pd.read_csv(\"/content/drive/MyDrive/Capstone/chemTasteDB/Padel/ChemTasteDBFeatures.csv\", encoding='unicode_escape')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqbpyA2d3pY5"
      },
      "outputs": [],
      "source": [
        "data =chemTasteDB[~chemTasteDB.isin([np.nan, np.inf, -np.inf]).any(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWFRCXzLvHQ9"
      },
      "outputs": [],
      "source": [
        "y = data['Class Taste']\n",
        "x = data.drop(['Class Taste','Name','Taste', 'ID'],axis=1)\n",
        "y=y.to_frame()\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lznhMil2vHQ-",
        "outputId": "3808627d-51a4-41ca-ad91-c2035bde0854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression : \n",
            "------------------------\n",
            "\n",
            "Basic ==>                          Precision:  0.39645203218505093  Recall:  0.44613259668508287   F1:  0.3361711367998856  Accuracy:  0.44613259668508287\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.4935509694154198  Recall:  0.356353591160221   F1:  0.2118467725171207  Accuracy:  0.356353591160221\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.5244689464659935  Recall:  0.35359116022099446   F1:  0.20682172274119687  Accuracy:  0.35359116022099446\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.3552551486075432  Recall:  0.4488950276243094   F1:  0.36711142410101555  Accuracy:  0.4488950276243094\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.35809962510540566  Recall:  0.4530386740331492   F1:  0.37078868259970044  Accuracy:  0.4530386740331492\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.5424095455082724  Recall:  0.6077348066298343   F1:  0.5649914516379849  Accuracy:  0.6077348066298343\n",
            "\n",
            "Random Forest : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.7247363568547492  Recall:  0.7472375690607734   F1:  0.7279254963417474  Accuracy:  0.7472375690607734\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.28151316261758624  Recall:  0.0649171270718232   F1:  0.044612972870773676  Accuracy:  0.0649171270718232\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.34873258986024075  Recall:  0.35911602209944754   F1:  0.2281360644847834  Accuracy:  0.35911602209944754\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.7270226360479282  Recall:  0.7417127071823204   F1:  0.7253473716876941  Accuracy:  0.7417127071823204\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.7192556555607392  Recall:  0.7361878453038674   F1:  0.7161309625427832  Accuracy:  0.7361878453038674\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.7315146557667728  Recall:  0.7417127071823204   F1:  0.7264172714254226  Accuracy:  0.7417127071823204\n",
            "\n",
            "AdaBoost : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.4354074043646637  Recall:  0.5483425414364641   F1:  0.47257771483290867  Accuracy:  0.5483425414364641\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.2234549689846045  Recall:  0.026243093922651933   F1:  0.02632807304265761  Accuracy:  0.026243093922651933\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.32153121586823247  Recall:  0.35359116022099446   F1:  0.21457895025873994  Accuracy:  0.35359116022099446\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.380701220847982  Recall:  0.40607734806629836   F1:  0.33581561730131837  Accuracy:  0.40607734806629836\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.380701220847982  Recall:  0.40607734806629836   F1:  0.33581561730131837  Accuracy:  0.40607734806629836\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.46607152665049545  Recall:  0.5662983425414365   F1:  0.4968315255953377  Accuracy:  0.5662983425414365\n",
            "\n",
            "XGBoostClassifier : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.7484433730729756  Recall:  0.761049723756906   F1:  0.7495034482643288  Accuracy:  0.761049723756906\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.3964051466895146  Recall:  0.36049723756906077   F1:  0.21844916655625285  Accuracy:  0.36049723756906077\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.2978843614604074  Recall:  0.38812154696132595   F1:  0.10743724396952145  Accuracy:  0.38812154696132595\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.7227795802273086  Recall:  0.7417127071823204   F1:  0.7263264984013622  Accuracy:  0.7417127071823204\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.7272307529432976  Recall:  0.7458563535911602   F1:  0.7300358938035926  Accuracy:  0.7458563535911602\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.7414927665400327  Recall:  0.7513812154696132   F1:  0.7418471765213478  Accuracy:  0.7513812154696132\n",
            "\n"
          ]
        }
      ],
      "source": [
        "findPredictionsPadel(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJzAxBt7PrUx"
      },
      "source": [
        "# **Extended chemTasteDB**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XdGT6EW0_mt"
      },
      "source": [
        "### **MODRED**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgsGdO_T05YH"
      },
      "source": [
        "**Without K-fold**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mXTHZwo1WjQ"
      },
      "outputs": [],
      "source": [
        "chemTasteDB = pd.read_csv(\"/content/drive/MyDrive/Capstone/ChemTasteDB + Sweet_Bitter/chemTasteDBModredMerged.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWR9GOlG1NaY"
      },
      "outputs": [],
      "source": [
        "y = chemTasteDB['Class taste']\n",
        "x = chemTasteDB.drop(['Class taste'],axis=1)\n",
        "y=y.to_frame()\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPnGdjnn1NaY",
        "outputId": "530f33af-640e-4684-f12b-92dc23b809a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression : \n",
            "------------------------\n",
            "\n",
            "Basic ==>                          Precision:  0.3629957962000359  Recall:  0.41112828438948995   F1:  0.30287245823650744  Accuracy:  0.41112828438948995\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.42208043381705734  Recall:  0.38330757341576505   F1:  0.260667500329973  Accuracy:  0.38330757341576505\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.36282044203696795  Recall:  0.3894899536321484   F1:  0.2732927308956863  Accuracy:  0.3894899536321484\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.35928689489160176  Recall:  0.4428129829984544   F1:  0.3441086036665524  Accuracy:  0.4428129829984544\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.37029925965203453  Recall:  0.4435857805255023   F1:  0.34555284822529764  Accuracy:  0.4435857805255023\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.16223428734680023  Recall:  0.4026275115919629   F1:  0.2312777657545895  Accuracy:  0.4026275115919629\n",
            "\n",
            "Random Forest : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.7532413844665177  Recall:  0.7666151468315301   F1:  0.7540613331160193  Accuracy:  0.7666151468315301\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.3218329127616552  Recall:  0.15301391035548687   F1:  0.11904990535080202  Accuracy:  0.15301391035548687\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.32697329596473285  Recall:  0.41035548686244205   F1:  0.29908131664383747  Accuracy:  0.41035548686244205\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.7544655430579467  Recall:  0.7666151468315301   F1:  0.7541898405445657  Accuracy:  0.7666151468315301\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.74636693675519  Recall:  0.7635239567233385   F1:  0.7484018378175076  Accuracy:  0.7635239567233385\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.7544547655219737  Recall:  0.7658423493044823   F1:  0.7545158721232946  Accuracy:  0.7658423493044823\n",
            "\n",
            "AdaBoost : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.46056620642288854  Recall:  0.5239567233384853   F1:  0.4712541510953171  Accuracy:  0.5239567233384853\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.34731964672211624  Recall:  0.43044822256568777   F1:  0.32786356021646723  Accuracy:  0.43044822256568777\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.28704651682464016  Recall:  0.3547140649149923   F1:  0.2846407786570092  Accuracy:  0.3547140649149923\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.4681675973475595  Recall:  0.5556414219474498   F1:  0.5059182865792758  Accuracy:  0.5556414219474498\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.4681675973475595  Recall:  0.5556414219474498   F1:  0.5059182865792758  Accuracy:  0.5556414219474498\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.46939145923178177  Recall:  0.5641421947449768   F1:  0.5099714618994062  Accuracy:  0.5641421947449768\n",
            "\n",
            "XGBoostClassifier : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.7615417301381363  Recall:  0.7727975270479135   F1:  0.7608874245924347  Accuracy:  0.7727975270479135\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.16180066020530395  Recall:  0.40030911901081917   F1:  0.23045420000512354  Accuracy:  0.40030911901081917\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.35750969744100125  Recall:  0.3384853168469861   F1:  0.10140027473030787  Accuracy:  0.3384853168469861\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.7552611662022428  Recall:  0.768160741885626   F1:  0.7559121019593883  Accuracy:  0.768160741885626\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.7570015346307141  Recall:  0.7689335394126738   F1:  0.7568323647191005  Accuracy:  0.7689335394126738\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.7571984057949862  Recall:  0.7658423493044823   F1:  0.7565221582413127  Accuracy:  0.7658423493044823\n",
            "\n"
          ]
        }
      ],
      "source": [
        "findPredictionsModred(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2Ts-pRFFjPy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsEuiFMQFj-N"
      },
      "source": [
        "### **PADEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8MfciuKFj-O"
      },
      "source": [
        "**Without K-fold**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJunC66FFj-Q"
      },
      "outputs": [],
      "source": [
        "chemTasteDB = pd.read_csv(\"/content/drive/MyDrive/Capstone/ChemTasteDB + Sweet_Bitter/chemTasteDBPadelMerged.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o258dIayGUzd"
      },
      "outputs": [],
      "source": [
        "chemTasteDB = chemTasteDB.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8Me3omaFj-R"
      },
      "outputs": [],
      "source": [
        "y = chemTasteDB['Class Taste']\n",
        "x = chemTasteDB.drop(['Class Taste'],axis=1)\n",
        "y=y.to_frame()\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_pvAchgFj-S",
        "outputId": "12972ff2-da8e-4f19-8b21-ed4b07a2f472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression : \n",
            "------------------------\n",
            "\n",
            "Basic ==>                          Precision:  0.5360074196262363  Recall:  0.592280701754386   F1:  0.5376832577431835  Accuracy:  0.592280701754386\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.4080666983173854  Recall:  0.44280701754385965   F1:  0.2919552964746166  Accuracy:  0.44280701754385965\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.3080519034069522  Recall:  0.42105263157894735   F1:  0.28302906915842246  Accuracy:  0.42105263157894735\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.48369354904616535  Recall:  0.5347368421052632   F1:  0.48409065234754733  Accuracy:  0.5347368421052632\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.45660340023848794  Recall:  0.5228070175438596   F1:  0.47845932032512906  Accuracy:  0.5228070175438596\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.5905194047299355  Recall:  0.6133333333333333   F1:  0.5851614459771779  Accuracy:  0.6133333333333333\n",
            "\n",
            "Random Forest : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8288544514717242  Recall:  0.8301754385964912   F1:  0.8209780251927784  Accuracy:  0.8301754385964912\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.26752170642958684  Recall:  0.25894736842105265   F1:  0.1802554934353883  Accuracy:  0.25894736842105265\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.39596913021381897  Recall:  0.447719298245614   F1:  0.4006358310324223  Accuracy:  0.447719298245614\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8396403497617881  Recall:  0.8428070175438597   F1:  0.8349408107691891  Accuracy:  0.8428070175438597\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.8472386976769836  Recall:  0.8463157894736842   F1:  0.8385640461698433  Accuracy:  0.8463157894736842\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.838225949399363  Recall:  0.8392982456140351   F1:  0.8333620284008776  Accuracy:  0.8392982456140351\n",
            "\n",
            "AdaBoost : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.46834907420990474  Recall:  0.5642105263157895   F1:  0.5112139775155742  Accuracy:  0.5642105263157895\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.34775774685756533  Recall:  0.047719298245614036   F1:  0.06221207197528126  Accuracy:  0.047719298245614036\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.41343132966702767  Recall:  0.48912280701754385   F1:  0.43602896639910843  Accuracy:  0.48912280701754385\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.504249131556217  Recall:  0.5656140350877193   F1:  0.5319620260204707  Accuracy:  0.5656140350877193\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.504249131556217  Recall:  0.5656140350877193   F1:  0.5319620260204707  Accuracy:  0.5656140350877193\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.46804493633882766  Recall:  0.5607017543859649   F1:  0.5096455699172829  Accuracy:  0.5607017543859649\n",
            "\n",
            "XGBoostClassifier : \n",
            "----------------\n",
            "\n",
            "Basic ==>                          Precision:  0.8406459134722185  Recall:  0.8449122807017544   F1:  0.8385587432218604  Accuracy:  0.8449122807017544\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.34882576712128166  Recall:  0.10736842105263159   F1:  0.06276932504106955  Accuracy:  0.10736842105263159\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.365271323631013  Recall:  0.35017543859649125   F1:  0.08323163027075642  Accuracy:  0.35017543859649125\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8432498911908338  Recall:  0.848421052631579   F1:  0.841945341567579  Accuracy:  0.848421052631579\n",
            "\n",
            "CorMatrix on Features & Labels ==> Precision:  0.8394122128999338  Recall:  0.847719298245614   F1:  0.8401477443165373  Accuracy:  0.847719298245614\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.8467908808287938  Recall:  0.8505263157894737   F1:  0.8447171107487601  Accuracy:  0.8505263157894737\n",
            "\n"
          ]
        }
      ],
      "source": [
        "findPredictionsPadel(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddaxxdBQ1Qtb"
      },
      "source": [
        "### **With K-fold**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mordred**"
      ],
      "metadata": {
        "id": "VCmn8diOPyYo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHRhesXpQDax"
      },
      "outputs": [],
      "source": [
        "chemTasteDBM = pd.read_csv(\"/content/drive/MyDrive/Capstone/ChemTasteDB + Sweet_Bitter/chemTasteDBModredMerged.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG43GKirQ-Ht",
        "outputId": "fd7f3d53-050c-4a46-d493-23ee6345bfbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5175 entries, 0 to 5174\n",
            "Columns: 1614 entries, ABC to Class taste\n",
            "dtypes: bool(2), float64(1301), int64(310), object(1)\n",
            "memory usage: 63.7+ MB\n"
          ]
        }
      ],
      "source": [
        "chemTasteDBM.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2o1gxE4SgSB"
      },
      "outputs": [],
      "source": [
        "Y = chemTasteDBM['Class taste']\n",
        "X = chemTasteDBM.drop(['Class taste'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlQmsZ_dphBV",
        "outputId": "c1b2a633-bbed-4131-c727-e93dc5e3ac8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5175 entries, 0 to 5174\n",
            "Columns: 1613 entries, ABC to mZagreb2\n",
            "dtypes: bool(2), float64(1301), int64(310)\n",
            "memory usage: 63.6 MB\n"
          ]
        }
      ],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5l1xCz0h8qA"
      },
      "outputs": [],
      "source": [
        "Y=Y.to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pI3BuLbeiSwU",
        "outputId": "8287275e-705b-4c8e-bc29-9b866323c35c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Class taste\n",
              "0         Sweetness\n",
              "1         Sweetness\n",
              "2         Sweetness\n",
              "3         Sweetness\n",
              "4     Miscellaneous\n",
              "...             ...\n",
              "5170     Bitterness\n",
              "5171     Bitterness\n",
              "5172      Sweetness\n",
              "5173     Bitterness\n",
              "5174     Bitterness\n",
              "\n",
              "[5175 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e14d887f-69ec-4e3f-87f4-88d87700c0af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class taste</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sweetness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sweetness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sweetness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sweetness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5170</th>\n",
              "      <td>Bitterness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5171</th>\n",
              "      <td>Bitterness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5172</th>\n",
              "      <td>Sweetness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5173</th>\n",
              "      <td>Bitterness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5174</th>\n",
              "      <td>Bitterness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5175 rows  1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e14d887f-69ec-4e3f-87f4-88d87700c0af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e14d887f-69ec-4e3f-87f4-88d87700c0af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e14d887f-69ec-4e3f-87f4-88d87700c0af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0266y6eQU5sL"
      },
      "outputs": [],
      "source": [
        "x = X.to_numpy()\n",
        "y = Y.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C4Kk0oePsU-",
        "outputId": "6c1194c5-2d65-4443-f4ca-2212483d353a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "list_LR_Pre_Basic = []\n",
        "list_LR_f1_Basic = []\n",
        "list_LR_Acc_Basic = []\n",
        "\n",
        "list_LR_Pre_PCA2 = []\n",
        "list_LR_f1_PCA2 = []\n",
        "list_LR_Acc_PCA2 = []\n",
        "\n",
        "list_LR_Pre_PCA10 = []\n",
        "list_LR_f1_PCA10 = []\n",
        "list_LR_Acc_PCA10 = []\n",
        "\n",
        "list_LR_Pre_CM = []\n",
        "list_LR_f1_CM = []\n",
        "list_LR_Acc_CM = []\n",
        "\n",
        "list_LR_Pre_CMFL = []\n",
        "list_LR_f1_CMFL = []\n",
        "list_LR_Acc_CMFL = []\n",
        "\n",
        "list_LR_Pre_SK = []\n",
        "list_LR_f1_SK = []\n",
        "list_LR_Acc_SK = []\n",
        "\n",
        "#==============================\n",
        "\n",
        "list_RF_Pre_Basic = []\n",
        "list_RF_f1_Basic = []\n",
        "list_RF_Acc_Basic = []\n",
        "\n",
        "list_RF_Pre_PCA2 = []\n",
        "list_RF_f1_PCA2 = []\n",
        "list_RF_Acc_PCA2 = []\n",
        "\n",
        "list_RF_Pre_PCA10 = []\n",
        "list_RF_f1_PCA10 = []\n",
        "list_RF_Acc_PCA10 = []\n",
        "\n",
        "list_RF_Pre_CM = []\n",
        "list_RF_f1_CM = []\n",
        "list_RF_Acc_CM = []\n",
        "\n",
        "list_RF_Pre_CMFL = []\n",
        "list_RF_f1_CMFL = []\n",
        "list_RF_Acc_CMFL = []\n",
        "\n",
        "list_RF_Pre_SK = []\n",
        "list_RF_f1_SK = []\n",
        "list_RF_Acc_SK = []\n",
        "\n",
        "\n",
        "#==============================\n",
        "\n",
        "list_AB_Pre_Basic = []\n",
        "list_AB_f1_Basic = []\n",
        "list_AB_Acc_Basic = []\n",
        "\n",
        "list_AB_Pre_PCA2 = []\n",
        "list_AB_f1_PCA2 = []\n",
        "list_AB_Acc_PCA2 = []\n",
        "\n",
        "list_AB_Pre_PCA10 = []\n",
        "list_AB_f1_PCA10 = []\n",
        "list_AB_Acc_PCA10 = []\n",
        "\n",
        "list_AB_Pre_CM = []\n",
        "list_AB_f1_CM = []\n",
        "list_AB_Acc_CM = []\n",
        "\n",
        "list_AB_Pre_CMFL = []\n",
        "list_AB_f1_CMFL = []\n",
        "list_AB_Acc_CMFL = []\n",
        "\n",
        "list_AB_Pre_SK = []\n",
        "list_AB_f1_SK = []\n",
        "list_AB_Acc_SK = []\n",
        "\n",
        "\n",
        "#==============================\n",
        "\n",
        "list_XG_Pre_Basic = []\n",
        "list_XG_f1_Basic = []\n",
        "list_XG_Acc_Basic = []\n",
        "\n",
        "list_XG_Pre_PCA2 = []\n",
        "list_XG_f1_PCA2 = []\n",
        "list_XG_Acc_PCA2 = []\n",
        "\n",
        "list_XG_Pre_PCA10 = []\n",
        "list_XG_f1_PCA10 = []\n",
        "list_XG_Acc_PCA10 = []\n",
        "\n",
        "list_XG_Pre_CM = []\n",
        "list_XG_f1_CM = []\n",
        "list_XG_Acc_CM = []\n",
        "\n",
        "list_XG_Pre_CMFL = []\n",
        "list_XG_f1_CMFL = []\n",
        "list_XG_Acc_CMFL = []\n",
        "\n",
        "list_XG_Pre_SK = []\n",
        "list_XG_f1_SK = []\n",
        "list_XG_Acc_SK = []\n",
        "\n",
        "\n",
        "for train_index, test_index in kf.split(x):\n",
        "  x_Train, x_Test = x[train_index], x[test_index]\n",
        "  y_Train, y_Test = y[train_index], y[test_index]\n",
        "\n",
        "\n",
        "  #Preparing data for PCA\n",
        "  pca2 = PCA(n_components=2)\n",
        "  x_pca2_data_train = pca2.fit_transform(x_Train)\n",
        "  x_pca2_data_test = pca2.fit_transform(x_Test)\n",
        "\n",
        "  pca10 = PCA(n_components=10)\n",
        "  x_pca10_data_train = pca10.fit_transform(x_Train)\n",
        "  x_pca10_data_test = pca10.fit_transform(x_Test)\n",
        "\n",
        "  \n",
        "  #Preparing data for Correlation matrix on features\n",
        "  x_Train = pd.DataFrame(x_Train,columns = X.columns)\n",
        "  y_Train = pd.DataFrame(y_Train,columns = Y.columns)\n",
        "  x_Test = pd.DataFrame(x_Test,columns = X.columns)\n",
        "  y_Test = pd.DataFrame(y_Test,columns = Y.columns)\n",
        "\n",
        "  train_data = pd.concat([x_Train,y_Train],axis=1)\n",
        "  test_data = pd.concat([x_Test,y_Test],axis=1)\n",
        "  train_corr , test_corr = correlation_check(train_data, test_data,0.8)\n",
        "\n",
        "\n",
        "  x_Train_corr = train_corr.drop(['Class taste'],axis=1)\n",
        "  x_Test_corr = test_corr.drop(['Class taste'],axis=1)\n",
        "\n",
        "  \n",
        "  \n",
        "  #Preparing data for Correlation matrix on features and Labels\n",
        "\n",
        "  a = x_Train_corr.corr(method ='pearson').abs()\n",
        "  df_temp = a.head(1)\n",
        "  df_temp.fillna(0,inplace = True)\n",
        "\n",
        "  colList = []\n",
        "  for i in df_temp.columns:\n",
        "    if(df_temp[i].item() < 0.2):\n",
        "      colList.append(i)\n",
        "\n",
        "  for i in colList:\n",
        "    new_x_train_corr = x_Train_corr.drop(i,axis = 1)\n",
        "    new_x_test_corr = x_Test_corr.drop(i,axis = 1)\n",
        "  \n",
        "\n",
        "  #Preparing data for selectkBest\n",
        "  from sklearn.feature_selection import SelectKBest, f_classif\n",
        "  \n",
        "  X_new = SelectKBest(f_classif, k=200).fit(x_Train, y_Train)\n",
        "  cols = X_new.get_support(indices=True)\n",
        "  features_df_new_train = x_Train.iloc[:,cols]\n",
        "  features_df_new_test = x_Test.iloc[:,cols]\n",
        "\n",
        "\n",
        "  x_Train = x_Train.to_numpy()\n",
        "  x_Test = x_Test.to_numpy()\n",
        "  y_Train = y_Train.to_numpy()\n",
        "  y_Test = y_Test.to_numpy()\n",
        "\n",
        "  # Logistic Regression\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "  clfLR1 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_Basic = clfLR1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfLR_Basic.predict(x_Test)\n",
        "\n",
        "  list_LR_Pre_Basic.append(precision_score(y_Test, y_pred_Basic,average='weighted'))\n",
        "  list_LR_f1_Basic.append(f1_score(y_Test, y_pred_Basic, average='weighted'))\n",
        "  list_LR_Acc_Basic.append(accuracy_score(y_Test, y_pred_Basic))\n",
        "  \n",
        "  clfLR2 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLRpca2 = clfLR2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfLRpca2.predict(x_pca2_data_test)\n",
        "\n",
        "  list_LR_Pre_PCA2.append(precision_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_LR_f1_PCA2.append(f1_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_LR_Acc_PCA2.append(accuracy_score(y_Test, y_predPca2))\n",
        "\n",
        "\n",
        "  clfLR3 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLRpca10 = clfLR3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfLRpca10.predict(x_pca10_data_test)\n",
        " \n",
        "  list_LR_Pre_PCA10.append(precision_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_LR_f1_PCA10.append(f1_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_LR_Acc_PCA10.append(accuracy_score(y_Test, y_predPca10))\n",
        "\n",
        "\n",
        "  clfLR4 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_CMF = clfLR4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfLR_CMF.predict(x_Test_corr)\n",
        "  \n",
        "  list_LR_Pre_CM.append(precision_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_LR_f1_CM.append(f1_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_LR_Acc_CM.append(accuracy_score(y_Test, y_pred_CMF))\n",
        "\n",
        "  clfLR5 = LogisticRegression(random_state=0)\n",
        "\n",
        "  # clfLR_CMFL = clfLR5.fit(new_x_train_corr, y_Train)\n",
        "  # y_pred_CMFL = clfLR_CMFL.predict(new_x_test_corr)\n",
        "  \n",
        "  # list_LR_Pre_CMFL.append(precision_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_LR_f1_CMFL.append(f1_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_LR_Acc_CMFL.append(accuracy_score(y_Test, y_pred_CMFL))\n",
        "\n",
        "  clfLR6 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_selectK = clfLR6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfLR_selectK.predict(features_df_new_test)\n",
        "\n",
        "  list_LR_Pre_SK.append(precision_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_LR_f1_SK.append(f1_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_LR_Acc_SK.append(accuracy_score(y_Test, y_pred_selectK))\n",
        "\n",
        "  #=====================================================================================================================================================\n",
        "\n",
        "  #2. Random forgest :\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "  clfRF1 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "  \n",
        "  \n",
        "\n",
        "  clfRF_Basic = clfRF1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfRF_Basic.predict(x_Test)\n",
        "  list_RF_Pre_Basic.append(precision_score(y_Test, y_pred_Basic,average='weighted'))\n",
        "  list_RF_f1_Basic.append(f1_score(y_Test, y_pred_Basic, average='weighted'))\n",
        "  list_RF_Acc_Basic.append(accuracy_score(y_Test, y_pred_Basic))\n",
        "\n",
        "  clfRF2 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "\n",
        "  clfRFpca2 = clfRF2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfRFpca2.predict(x_pca2_data_test)\n",
        "  list_RF_Pre_PCA2.append(precision_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_RF_f1_PCA2.append(f1_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_RF_Acc_PCA2.append(accuracy_score(y_Test, y_predPca2))\n",
        "\n",
        "  clfRF3 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "\n",
        "  clfRFpca10 = clfRF3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfRFpca10.predict(x_pca10_data_test)\n",
        "  list_RF_Pre_PCA10.append(precision_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_RF_f1_PCA10.append(f1_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_RF_Acc_PCA10.append(accuracy_score(y_Test, y_predPca10))\n",
        "\n",
        "\n",
        "  clfRF4 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfRF_CMF = clfRF4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfRF_CMF.predict(x_Test_corr)\n",
        "  list_RF_Pre_CM.append(precision_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_RF_f1_CM.append(f1_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_RF_Acc_CM.append(accuracy_score(y_Test, y_pred_CMF))\n",
        "\n",
        "  clfRF5 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "  # clfLR_CMFL = clfRF5.fit(new_x_train_corr, y_Train)\n",
        "  # y_pred_CMFL = clfLR_CMFL.predict(new_x_test_corr)\n",
        "  # list_RF_Pre_CMFL.append(precision_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_RF_f1_CMFL.append(f1_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_RF_Acc_CMFL.append(accuracy_score(y_Test, y_pred_CMFL))\n",
        "\n",
        "  clfRF6 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfRF_selectK = clfRF6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfRF_selectK.predict(features_df_new_test)\n",
        "  list_RF_Pre_SK.append(precision_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_RF_f1_SK.append(f1_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_RF_Acc_SK.append(accuracy_score(y_Test, y_pred_selectK))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #3. Adaboost\n",
        "  from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "  clfAB1 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  \n",
        "\n",
        "  clfAB_Basic = clfAB1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfAB_Basic.predict(x_Test)\n",
        "  list_AB_Pre_Basic.append(precision_score(y_Test, y_pred_Basic,average='weighted'))\n",
        "  list_AB_f1_Basic.append(f1_score(y_Test, y_pred_Basic, average='weighted'))\n",
        "  list_AB_Acc_Basic.append(accuracy_score(y_Test, y_pred_Basic))\n",
        "\n",
        "  clfAB2 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfABpca2 = clfAB2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfABpca2.predict(x_pca2_data_test)\n",
        "  list_AB_Pre_PCA2.append(precision_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_AB_f1_PCA2.append(f1_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_AB_Acc_PCA2.append(accuracy_score(y_Test, y_predPca2))\n",
        "\n",
        "  clfAB3 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfABpca10 = clfAB3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfABpca10.predict(x_pca10_data_test)\n",
        "  list_AB_Pre_PCA10.append(precision_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_AB_f1_PCA10.append(f1_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_AB_Acc_PCA10.append(accuracy_score(y_Test, y_predPca10))\n",
        "\n",
        "\n",
        "  clfAB4 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfAB_CMF = clfAB4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfAB_CMF.predict(x_Test_corr)\n",
        "  list_AB_Pre_CM.append(precision_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_AB_f1_CM.append(f1_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_AB_Acc_CM.append(accuracy_score(y_Test, y_pred_CMF))\n",
        "\n",
        "  clfAB5 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  # clfAB_CMFL = clfAB5.fit(new_x_train_corr, y_Train)\n",
        "  # y_pred_CMFL = clfAB_CMFL.predict(new_x_test_corr)\n",
        "  # list_AB_Pre_CMFL.append(precision_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_AB_f1_CMFL.append(f1_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_AB_Acc_CMFL.append(accuracy_score(y_Test, y_pred_CMFL))\n",
        "\n",
        "\n",
        "  clfAB6 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "\n",
        "  clfAB_selectK = clfAB6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfAB_selectK.predict(features_df_new_test)\n",
        "  list_AB_Pre_SK.append(precision_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_AB_f1_SK.append(f1_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_AB_Acc_SK.append(accuracy_score(y_Test, y_pred_selectK))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  #4. XGBoostClassifier\n",
        "  import xgboost as xg\n",
        "\n",
        "  xgb_r1 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  \n",
        "\n",
        "  clfXGB_Basic = xgb_r1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfXGB_Basic.predict(x_Test)\n",
        "  list_XG_Pre_Basic.append(precision_score(y_Test, y_pred_Basic,average='weighted'))\n",
        "  list_XG_f1_Basic.append(f1_score(y_Test, y_pred_Basic, average='weighted'))\n",
        "  list_XG_Acc_Basic.append(accuracy_score(y_Test, y_pred_Basic))\n",
        "\n",
        "  xgb_r2 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  clfXGBpca2 = xgb_r2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfXGBpca2.predict(x_pca2_data_test)\n",
        "  list_XG_Pre_PCA2.append(precision_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_XG_f1_PCA2.append(f1_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_XG_Acc_PCA2.append(accuracy_score(y_Test, y_predPca2))\n",
        "\n",
        "  xgb_r3 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "\n",
        "  clfXGBpca10 = xgb_r3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfXGBpca10.predict(x_pca10_data_test)\n",
        "  list_XG_Pre_PCA10.append(precision_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_XG_f1_PCA10.append(f1_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_XG_Acc_PCA10.append(accuracy_score(y_Test, y_predPca10))\n",
        "\n",
        "\n",
        "  xgb_r4 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  x_Train_corr = x_Train_corr.to_numpy()\n",
        "  x_Test_corr = x_Test_corr.to_numpy()\n",
        "\n",
        "  clfXGB_CMF = xgb_r4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfXGB_CMF.predict(x_Test_corr)\n",
        "  list_XG_Pre_CM.append(precision_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_XG_f1_CM.append(f1_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_XG_Acc_CM.append(accuracy_score(y_Test, y_pred_CMF))\n",
        "\n",
        "  xgb_r5 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  # clfXGB_CMFL = xgb_r5.fit(new_x_train_corr, y_Train)\n",
        "  # y_pred_CMFL = clfXGB_CMFL.predict(new_x_test_corr)\n",
        "  # list_XG_Pre_CMFL.append(precision_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_XG_f1_CMFL.append(f1_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_XG_Acc_CMFL.append(accuracy_score(y_Test, y_pred_CMFL))\n",
        "\n",
        "\n",
        "  xgb_r6 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  features_df_new_train = features_df_new_train.to_numpy()\n",
        "  features_df_new_test = features_df_new_test.to_numpy()\n",
        "  clfXGB_selectK = xgb_r6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfXGB_selectK.predict(features_df_new_test)\n",
        "  list_XG_Pre_SK.append(precision_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_XG_f1_SK.append(f1_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_XG_Acc_SK.append(accuracy_score(y_Test, y_pred_selectK))\n",
        "\n",
        "  print(\"done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wyyn_FLwu6zo"
      },
      "outputs": [],
      "source": [
        "from statistics import mean\n",
        "  \n",
        "def Average(lst):\n",
        "  return mean(lst)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logistic Regression :\")\n",
        "print(\"----------------------\")\n",
        "print(\"Basic ==>                          Precision: \",round(Average(list_LR_Pre_Basic), 4),\"  F1: \",round(Average(list_LR_f1_Basic), 4),\" Accuracy: \",round(Average(list_LR_Acc_Basic), 4))\n",
        "print()\n",
        "print(\"PCA with n = 2 ==>                 Precision: \",round(Average(list_LR_Pre_PCA2), 4),\"  F1: \",round(Average(list_LR_f1_PCA2), 4),\" Accuracy: \",round(Average(list_LR_Acc_PCA2), 4))\n",
        "print()\n",
        "print(\"PCA with n = 10 ==>                Precision: \",round(Average(list_LR_Pre_PCA10), 4),\"  F1: \",round(Average(list_LR_f1_PCA10), 4),\" Accuracy: \",round(Average(list_LR_Acc_PCA10), 4))\n",
        "print()\n",
        "print(\"Correlation Matrix on Features ==> Precision: \",round(Average(list_LR_Pre_CM), 4),\"  F1: \",round(Average(list_LR_f1_CM), 4),\" Accuracy: \",round(Average(list_LR_Acc_CM), 4))\n",
        "print()\n",
        "print(\"SelectK best with k = 200 ==>      Precision: \",round(Average(list_LR_Pre_SK), 4),\"  F1: \",round(Average(list_LR_f1_SK), 4),\" Accuracy: \",round(Average(list_LR_Acc_SK), 4))\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"Radom Forest :\")\n",
        "print(\"----------------------\")\n",
        "print(\"Basic ==>                          Precision: \",round(Average(list_RF_Pre_Basic), 4),\"  F1: \",round(Average(list_RF_f1_Basic), 4),\" Accuracy: \",round(Average(list_RF_Acc_Basic), 4))\n",
        "print()\n",
        "print(\"PCA with n = 2 ==>                 Precision: \",round(Average(list_RF_Pre_PCA2), 4),\"  F1: \",round(Average(list_RF_f1_PCA2), 4),\" Accuracy: \",round(Average(list_RF_Acc_PCA2), 4))\n",
        "print()\n",
        "print(\"PCA with n = 10 ==>                Precision: \",round(Average(list_RF_Pre_PCA10), 4),\"  F1: \",round(Average(list_RF_f1_PCA10), 4),\" Accuracy: \",round(Average(list_RF_Acc_PCA10), 4))\n",
        "print()\n",
        "print(\"Correlation Matrix on Features ==> Precision: \",round(Average(list_RF_Pre_CM), 4),\"  F1: \",round(Average(list_RF_f1_CM), 4),\" Accuracy: \",round(Average(list_RF_Acc_CM), 4))\n",
        "print()\n",
        "print(\"SelectK best with k = 200 ==>      Precision: \",round(Average(list_RF_Pre_SK), 4),\"  F1: \",round(Average(list_RF_f1_SK), 4),\" Accuracy: \",round(Average(list_RF_Acc_SK), 4))\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"Adaboost :\")\n",
        "print(\"----------------------\")\n",
        "print(\"Basic ==>                          Precision: \",round(Average(list_AB_Pre_Basic), 4),\"  F1: \",round(Average(list_AB_f1_Basic), 4),\" Accuracy: \",round(Average(list_AB_Acc_Basic), 4))\n",
        "print()\n",
        "print(\"PCA with n = 2 ==>                 Precision: \",round(Average(list_AB_Pre_PCA2), 4),\"  F1: \",round(Average(list_AB_f1_PCA2), 4),\" Accuracy: \",round(Average(list_AB_Acc_PCA2), 4))\n",
        "print()\n",
        "print(\"PCA with n = 10 ==>                Precision: \",round(Average(list_AB_Pre_PCA10), 4),\"  F1: \",round(Average(list_AB_f1_PCA10), 4),\" Accuracy: \",round(Average(list_AB_Acc_PCA10), 4))\n",
        "print()\n",
        "print(\"Correlation Matrix on Features ==> Precision: \",round(Average(list_AB_Pre_CM), 4),\"  F1: \",round(Average(list_AB_f1_CM), 4),\" Accuracy: \",round(Average(list_AB_Acc_CM), 4))\n",
        "print()\n",
        "print(\"SelectK best with k = 200 ==>      Precision: \",round(Average(list_AB_Pre_SK), 4),\"  F1: \",round(Average(list_AB_f1_SK), 4),\" Accuracy: \",round(Average(list_AB_Acc_SK), 4))\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"XgBoost :\")\n",
        "print(\"----------------------\")\n",
        "print(\"Basic ==>                          Precision: \",round(Average(list_XG_Pre_Basic), 4),\"  F1: \",round(Average(list_XG_f1_Basic), 4),\" Accuracy: \",round(Average(list_XG_Acc_Basic), 4))\n",
        "print()\n",
        "print(\"PCA with n = 2 ==>                 Precision: \",round(Average(list_XG_Pre_PCA2), 4),\"  F1: \",round(Average(list_XG_f1_PCA2), 4),\" Accuracy: \",round(Average(list_XG_Acc_PCA2), 4))\n",
        "print()\n",
        "print(\"PCA with n = 10 ==>                Precision: \",round(Average(list_XG_Pre_PCA10), 4),\"  F1: \",round(Average(list_XG_f1_PCA10), 4),\" Accuracy: \",round(Average(list_XG_Acc_PCA10), 4))\n",
        "print()\n",
        "print(\"Correlation Matrix on Features ==> Precision: \",round(Average(list_XG_Pre_CM), 4),\"  F1: \",round(Average(list_XG_f1_CM), 4),\" Accuracy: \",round(Average(list_XG_Acc_CM), 4))\n",
        "print()\n",
        "print(\"SelectK best with k = 200 ==>      Precision: \",round(Average(list_XG_Pre_SK), 4),\"  F1: \",round(Average(list_XG_f1_SK), 4),\" Accuracy: \",round(Average(list_XG_Acc_SK), 4))\n",
        "print()\n",
        "print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH88HB-kN6gI",
        "outputId": "872d5be6-a56e-4d63-cfe4-2477b3ff50d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression :\n",
            "----------------------\n",
            "Basic ==>                          Precision:  0.3247   F1:  0.3244  Accuracy:  0.3961\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.4372   F1:  0.1931  Accuracy:  0.2686\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.421   F1:  0.194  Accuracy:  0.2682\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.3247   F1:  0.3244  Accuracy:  0.3961\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.1713   F1:  0.2399  Accuracy:  0.4025\n",
            "\n",
            "\n",
            "Radom Forest :\n",
            "----------------------\n",
            "Basic ==>                          Precision:  0.7508   F1:  0.7442  Accuracy:  0.753\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.3482   F1:  0.2046  Accuracy:  0.3055\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.4107   F1:  0.3397  Accuracy:  0.4493\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.7508   F1:  0.7442  Accuracy:  0.753\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.7513   F1:  0.7473  Accuracy:  0.755\n",
            "\n",
            "\n",
            "Adaboost :\n",
            "----------------------\n",
            "Basic ==>                          Precision:  0.4607   F1:  0.4862  Accuracy:  0.5397\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.2149   F1:  0.2185  Accuracy:  0.3382\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.4525   F1:  0.4231  Accuracy:  0.4213\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.4607   F1:  0.4862  Accuracy:  0.5397\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.464   F1:  0.4924  Accuracy:  0.5426\n",
            "\n",
            "\n",
            "XgBoost :\n",
            "----------------------\n",
            "Basic ==>                          Precision:  0.7582   F1:  0.7544  Accuracy:  0.7629\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.2551   F1:  0.1929  Accuracy:  0.2945\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.4382   F1:  0.4135  Accuracy:  0.4369\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.7582   F1:  0.7544  Accuracy:  0.7629\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.7521   F1:  0.7508  Accuracy:  0.759\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Padel**"
      ],
      "metadata": {
        "id": "47Yy_HlbP8gz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fkKkWnWQGS6"
      },
      "outputs": [],
      "source": [
        "chemTasteDB = pd.read_csv(\"/content/drive/MyDrive/Capstone/ChemTasteDB + Sweet_Bitter/chemTasteDBPadelMerged.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9KQxoTgQGS7"
      },
      "outputs": [],
      "source": [
        "chemTasteDB = chemTasteDB.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a98a43-7eff-46ae-91ce-b110580d2200",
        "id": "ObULRrC3QYLC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 5698 entries, 0 to 5727\n",
            "Columns: 1443 entries, Class Taste to Zagreb\n",
            "dtypes: float64(1309), int64(133), object(1)\n",
            "memory usage: 62.8+ MB\n"
          ]
        }
      ],
      "source": [
        "chemTasteDB.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k8DkQNsQYLE"
      },
      "outputs": [],
      "source": [
        "Y = chemTasteDB['Class Taste']\n",
        "X = chemTasteDB.drop(['Class Taste'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5077055-b3a9-4423-dff0-0745f839739a",
        "id": "fXKXSvE8QYLF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 5698 entries, 0 to 5727\n",
            "Columns: 1442 entries, nAcid to Zagreb\n",
            "dtypes: float64(1309), int64(133)\n",
            "memory usage: 62.7 MB\n"
          ]
        }
      ],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_unHTHyfQYLG"
      },
      "outputs": [],
      "source": [
        "Y=Y.to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "bd886abb-e812-434a-fb3d-df98e5edfa53",
        "id": "f1XL24lIQYLH"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Class Taste\n",
              "0      Umaminess\n",
              "1      Sweetness\n",
              "2     Bitterness\n",
              "3      Sweetness\n",
              "4     Bitterness\n",
              "...          ...\n",
              "5723   Sweetness\n",
              "5724   Sweetness\n",
              "5725   Sweetness\n",
              "5726  Bitterness\n",
              "5727  Bitterness\n",
              "\n",
              "[5698 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92c359d0-f88f-4d88-808f-b76056101d5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Taste</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Umaminess</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sweetness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bitterness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sweetness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bitterness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5723</th>\n",
              "      <td>Sweetness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5724</th>\n",
              "      <td>Sweetness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5725</th>\n",
              "      <td>Sweetness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5726</th>\n",
              "      <td>Bitterness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5727</th>\n",
              "      <td>Bitterness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5698 rows  1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92c359d0-f88f-4d88-808f-b76056101d5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92c359d0-f88f-4d88-808f-b76056101d5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92c359d0-f88f-4d88-808f-b76056101d5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmrwnNw6QYLI"
      },
      "outputs": [],
      "source": [
        "x = X.to_numpy()\n",
        "y = Y.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a6cb39a-c37c-4cb3-9422-4c1140671a5d",
        "id": "NipEeLkkQYLJ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n",
            "done\n",
            "done\n",
            "done\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "list_LR_Pre_Basic = []\n",
        "list_LR_f1_Basic = []\n",
        "list_LR_Acc_Basic = []\n",
        "\n",
        "list_LR_Pre_PCA2 = []\n",
        "list_LR_f1_PCA2 = []\n",
        "list_LR_Acc_PCA2 = []\n",
        "\n",
        "list_LR_Pre_PCA10 = []\n",
        "list_LR_f1_PCA10 = []\n",
        "list_LR_Acc_PCA10 = []\n",
        "\n",
        "list_LR_Pre_CM = []\n",
        "list_LR_f1_CM = []\n",
        "list_LR_Acc_CM = []\n",
        "\n",
        "list_LR_Pre_CMFL = []\n",
        "list_LR_f1_CMFL = []\n",
        "list_LR_Acc_CMFL = []\n",
        "\n",
        "list_LR_Pre_SK = []\n",
        "list_LR_f1_SK = []\n",
        "list_LR_Acc_SK = []\n",
        "\n",
        "#==============================\n",
        "\n",
        "list_RF_Pre_Basic = []\n",
        "list_RF_f1_Basic = []\n",
        "list_RF_Acc_Basic = []\n",
        "\n",
        "list_RF_Pre_PCA2 = []\n",
        "list_RF_f1_PCA2 = []\n",
        "list_RF_Acc_PCA2 = []\n",
        "\n",
        "list_RF_Pre_PCA10 = []\n",
        "list_RF_f1_PCA10 = []\n",
        "list_RF_Acc_PCA10 = []\n",
        "\n",
        "list_RF_Pre_CM = []\n",
        "list_RF_f1_CM = []\n",
        "list_RF_Acc_CM = []\n",
        "\n",
        "list_RF_Pre_CMFL = []\n",
        "list_RF_f1_CMFL = []\n",
        "list_RF_Acc_CMFL = []\n",
        "\n",
        "list_RF_Pre_SK = []\n",
        "list_RF_f1_SK = []\n",
        "list_RF_Acc_SK = []\n",
        "\n",
        "\n",
        "#==============================\n",
        "\n",
        "list_AB_Pre_Basic = []\n",
        "list_AB_f1_Basic = []\n",
        "list_AB_Acc_Basic = []\n",
        "\n",
        "list_AB_Pre_PCA2 = []\n",
        "list_AB_f1_PCA2 = []\n",
        "list_AB_Acc_PCA2 = []\n",
        "\n",
        "list_AB_Pre_PCA10 = []\n",
        "list_AB_f1_PCA10 = []\n",
        "list_AB_Acc_PCA10 = []\n",
        "\n",
        "list_AB_Pre_CM = []\n",
        "list_AB_f1_CM = []\n",
        "list_AB_Acc_CM = []\n",
        "\n",
        "list_AB_Pre_CMFL = []\n",
        "list_AB_f1_CMFL = []\n",
        "list_AB_Acc_CMFL = []\n",
        "\n",
        "list_AB_Pre_SK = []\n",
        "list_AB_f1_SK = []\n",
        "list_AB_Acc_SK = []\n",
        "\n",
        "\n",
        "#==============================\n",
        "\n",
        "list_XG_Pre_Basic = []\n",
        "list_XG_f1_Basic = []\n",
        "list_XG_Acc_Basic = []\n",
        "\n",
        "list_XG_Pre_PCA2 = []\n",
        "list_XG_f1_PCA2 = []\n",
        "list_XG_Acc_PCA2 = []\n",
        "\n",
        "list_XG_Pre_PCA10 = []\n",
        "list_XG_f1_PCA10 = []\n",
        "list_XG_Acc_PCA10 = []\n",
        "\n",
        "list_XG_Pre_CM = []\n",
        "list_XG_f1_CM = []\n",
        "list_XG_Acc_CM = []\n",
        "\n",
        "list_XG_Pre_CMFL = []\n",
        "list_XG_f1_CMFL = []\n",
        "list_XG_Acc_CMFL = []\n",
        "\n",
        "list_XG_Pre_SK = []\n",
        "list_XG_f1_SK = []\n",
        "list_XG_Acc_SK = []\n",
        "\n",
        "\n",
        "for train_index, test_index in kf.split(x):\n",
        "  x_Train, x_Test = x[train_index], x[test_index]\n",
        "  y_Train, y_Test = y[train_index], y[test_index]\n",
        "\n",
        "\n",
        "  #Preparing data for PCA\n",
        "  pca2 = PCA(n_components=2)\n",
        "  x_pca2_data_train = pca2.fit_transform(x_Train)\n",
        "  x_pca2_data_test = pca2.fit_transform(x_Test)\n",
        "\n",
        "  pca10 = PCA(n_components=10)\n",
        "  x_pca10_data_train = pca10.fit_transform(x_Train)\n",
        "  x_pca10_data_test = pca10.fit_transform(x_Test)\n",
        "\n",
        "  \n",
        "  #Preparing data for Correlation matrix on features\n",
        "  x_Train = pd.DataFrame(x_Train,columns = X.columns)\n",
        "  y_Train = pd.DataFrame(y_Train,columns = Y.columns)\n",
        "  x_Test = pd.DataFrame(x_Test,columns = X.columns)\n",
        "  y_Test = pd.DataFrame(y_Test,columns = Y.columns)\n",
        "\n",
        "  train_data = pd.concat([x_Train,y_Train],axis=1)\n",
        "  test_data = pd.concat([x_Test,y_Test],axis=1)\n",
        "  train_corr , test_corr = correlation_check(train_data, test_data,0.8)\n",
        "\n",
        "\n",
        "  x_Train_corr = train_corr.drop(['Class Taste'],axis=1)\n",
        "  x_Test_corr = test_corr.drop(['Class Taste'],axis=1)\n",
        "\n",
        "  \n",
        "  \n",
        "  #Preparing data for Correlation matrix on features and Labels\n",
        "\n",
        "  a = x_Train_corr.corr(method ='pearson').abs()\n",
        "  df_temp = a.head(1)\n",
        "  df_temp.fillna(0,inplace = True)\n",
        "\n",
        "  colList = []\n",
        "  for i in df_temp.columns:\n",
        "    if(df_temp[i].item() < 0.2):\n",
        "      colList.append(i)\n",
        "\n",
        "  for i in colList:\n",
        "    new_x_train_corr = x_Train_corr.drop(i,axis = 1)\n",
        "    new_x_test_corr = x_Test_corr.drop(i,axis = 1)\n",
        "  \n",
        "\n",
        "  #Preparing data for selectkBest\n",
        "  from sklearn.feature_selection import SelectKBest, f_classif\n",
        "  \n",
        "  X_new = SelectKBest(f_classif, k=200).fit(x_Train, y_Train)\n",
        "  cols = X_new.get_support(indices=True)\n",
        "  features_df_new_train = x_Train.iloc[:,cols]\n",
        "  features_df_new_test = x_Test.iloc[:,cols]\n",
        "\n",
        "\n",
        "  x_Train = x_Train.to_numpy()\n",
        "  x_Test = x_Test.to_numpy()\n",
        "  y_Train = y_Train.to_numpy()\n",
        "  y_Test = y_Test.to_numpy()\n",
        "\n",
        "  # Logistic Regression\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "  clfLR1 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_Basic = clfLR1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfLR_Basic.predict(x_Test)\n",
        "\n",
        "  list_LR_Pre_Basic.append(precision_score(y_Test, y_pred_Basic,average='weighted'))\n",
        "  list_LR_f1_Basic.append(f1_score(y_Test, y_pred_Basic, average='weighted'))\n",
        "  list_LR_Acc_Basic.append(accuracy_score(y_Test, y_pred_Basic))\n",
        "  \n",
        "  clfLR2 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLRpca2 = clfLR2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfLRpca2.predict(x_pca2_data_test)\n",
        "\n",
        "  list_LR_Pre_PCA2.append(precision_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_LR_f1_PCA2.append(f1_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_LR_Acc_PCA2.append(accuracy_score(y_Test, y_predPca2))\n",
        "\n",
        "\n",
        "  clfLR3 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLRpca10 = clfLR3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfLRpca10.predict(x_pca10_data_test)\n",
        " \n",
        "  list_LR_Pre_PCA10.append(precision_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_LR_f1_PCA10.append(f1_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_LR_Acc_PCA10.append(accuracy_score(y_Test, y_predPca10))\n",
        "\n",
        "\n",
        "  clfLR4 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_CMF = clfLR4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfLR_CMF.predict(x_Test_corr)\n",
        "  \n",
        "  list_LR_Pre_CM.append(precision_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_LR_f1_CM.append(f1_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_LR_Acc_CM.append(accuracy_score(y_Test, y_pred_CMF))\n",
        "\n",
        "  clfLR5 = LogisticRegression(random_state=0)\n",
        "\n",
        "  # clfLR_CMFL = clfLR5.fit(new_x_train_corr, y_Train)\n",
        "  # y_pred_CMFL = clfLR_CMFL.predict(new_x_test_corr)\n",
        "  \n",
        "  # list_LR_Pre_CMFL.append(precision_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_LR_f1_CMFL.append(f1_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_LR_Acc_CMFL.append(accuracy_score(y_Test, y_pred_CMFL))\n",
        "\n",
        "  clfLR6 = LogisticRegression(random_state=0)\n",
        "\n",
        "  clfLR_selectK = clfLR6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfLR_selectK.predict(features_df_new_test)\n",
        "\n",
        "  list_LR_Pre_SK.append(precision_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_LR_f1_SK.append(f1_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_LR_Acc_SK.append(accuracy_score(y_Test, y_pred_selectK))\n",
        "\n",
        "  #=====================================================================================================================================================\n",
        "\n",
        "  #2. Random forgest :\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "  clfRF1 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "  \n",
        "  \n",
        "\n",
        "  clfRF_Basic = clfRF1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfRF_Basic.predict(x_Test)\n",
        "  list_RF_Pre_Basic.append(precision_score(y_Test, y_pred_Basic,average='weighted'))\n",
        "  list_RF_f1_Basic.append(f1_score(y_Test, y_pred_Basic, average='weighted'))\n",
        "  list_RF_Acc_Basic.append(accuracy_score(y_Test, y_pred_Basic))\n",
        "\n",
        "  clfRF2 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "\n",
        "  clfRFpca2 = clfRF2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfRFpca2.predict(x_pca2_data_test)\n",
        "  list_RF_Pre_PCA2.append(precision_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_RF_f1_PCA2.append(f1_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_RF_Acc_PCA2.append(accuracy_score(y_Test, y_predPca2))\n",
        "\n",
        "  clfRF3 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "\n",
        "  clfRFpca10 = clfRF3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfRFpca10.predict(x_pca10_data_test)\n",
        "  list_RF_Pre_PCA10.append(precision_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_RF_f1_PCA10.append(f1_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_RF_Acc_PCA10.append(accuracy_score(y_Test, y_predPca10))\n",
        "\n",
        "\n",
        "  clfRF4 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfRF_CMF = clfRF4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfRF_CMF.predict(x_Test_corr)\n",
        "  list_RF_Pre_CM.append(precision_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_RF_f1_CM.append(f1_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_RF_Acc_CM.append(accuracy_score(y_Test, y_pred_CMF))\n",
        "\n",
        "  clfRF5 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "  # clfLR_CMFL = clfRF5.fit(new_x_train_corr, y_Train)\n",
        "  # y_pred_CMFL = clfLR_CMFL.predict(new_x_test_corr)\n",
        "  # list_RF_Pre_CMFL.append(precision_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_RF_f1_CMFL.append(f1_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_RF_Acc_CMFL.append(accuracy_score(y_Test, y_pred_CMFL))\n",
        "\n",
        "  clfRF6 = RandomForestClassifier(max_features='auto', n_estimators= 200, max_depth=25, criterion='entropy', random_state=30)\n",
        "\n",
        "  clfRF_selectK = clfRF6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfRF_selectK.predict(features_df_new_test)\n",
        "  list_RF_Pre_SK.append(precision_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_RF_f1_SK.append(f1_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_RF_Acc_SK.append(accuracy_score(y_Test, y_pred_selectK))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #3. Adaboost\n",
        "  from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "  clfAB1 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  \n",
        "\n",
        "  clfAB_Basic = clfAB1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfAB_Basic.predict(x_Test)\n",
        "  list_AB_Pre_Basic.append(precision_score(y_Test, y_pred_Basic,average='weighted'))\n",
        "  list_AB_f1_Basic.append(f1_score(y_Test, y_pred_Basic, average='weighted'))\n",
        "  list_AB_Acc_Basic.append(accuracy_score(y_Test, y_pred_Basic))\n",
        "\n",
        "  clfAB2 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfABpca2 = clfAB2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfABpca2.predict(x_pca2_data_test)\n",
        "  list_AB_Pre_PCA2.append(precision_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_AB_f1_PCA2.append(f1_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_AB_Acc_PCA2.append(accuracy_score(y_Test, y_predPca2))\n",
        "\n",
        "  clfAB3 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfABpca10 = clfAB3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfABpca10.predict(x_pca10_data_test)\n",
        "  list_AB_Pre_PCA10.append(precision_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_AB_f1_PCA10.append(f1_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_AB_Acc_PCA10.append(accuracy_score(y_Test, y_predPca10))\n",
        "\n",
        "\n",
        "  clfAB4 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  clfAB_CMF = clfAB4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfAB_CMF.predict(x_Test_corr)\n",
        "  list_AB_Pre_CM.append(precision_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_AB_f1_CM.append(f1_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_AB_Acc_CM.append(accuracy_score(y_Test, y_pred_CMF))\n",
        "\n",
        "  clfAB5 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "  # clfAB_CMFL = clfAB5.fit(new_x_train_corr, y_Train)\n",
        "  # y_pred_CMFL = clfAB_CMFL.predict(new_x_test_corr)\n",
        "  # list_AB_Pre_CMFL.append(precision_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_AB_f1_CMFL.append(f1_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_AB_Acc_CMFL.append(accuracy_score(y_Test, y_pred_CMFL))\n",
        "\n",
        "\n",
        "  clfAB6 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "\n",
        "  clfAB_selectK = clfAB6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfAB_selectK.predict(features_df_new_test)\n",
        "  list_AB_Pre_SK.append(precision_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_AB_f1_SK.append(f1_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_AB_Acc_SK.append(accuracy_score(y_Test, y_pred_selectK))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  #4. XGBoostClassifier\n",
        "  import xgboost as xg\n",
        "\n",
        "  xgb_r1 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  \n",
        "\n",
        "  clfXGB_Basic = xgb_r1.fit(x_Train, y_Train)\n",
        "  y_pred_Basic = clfXGB_Basic.predict(x_Test)\n",
        "  list_XG_Pre_Basic.append(precision_score(y_Test, y_pred_Basic,average='weighted'))\n",
        "  list_XG_f1_Basic.append(f1_score(y_Test, y_pred_Basic, average='weighted'))\n",
        "  list_XG_Acc_Basic.append(accuracy_score(y_Test, y_pred_Basic))\n",
        "\n",
        "  xgb_r2 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  clfXGBpca2 = xgb_r2.fit(x_pca2_data_train, y_Train)\n",
        "  y_predPca2 = clfXGBpca2.predict(x_pca2_data_test)\n",
        "  list_XG_Pre_PCA2.append(precision_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_XG_f1_PCA2.append(f1_score(y_Test, y_predPca2, average='weighted'))\n",
        "  list_XG_Acc_PCA2.append(accuracy_score(y_Test, y_predPca2))\n",
        "\n",
        "  xgb_r3 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "\n",
        "  clfXGBpca10 = xgb_r3.fit(x_pca10_data_train, y_Train)\n",
        "  y_predPca10 = clfXGBpca10.predict(x_pca10_data_test)\n",
        "  list_XG_Pre_PCA10.append(precision_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_XG_f1_PCA10.append(f1_score(y_Test, y_predPca10, average='weighted'))\n",
        "  list_XG_Acc_PCA10.append(accuracy_score(y_Test, y_predPca10))\n",
        "\n",
        "\n",
        "  xgb_r4 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  x_Train_corr = x_Train_corr.to_numpy()\n",
        "  x_Test_corr = x_Test_corr.to_numpy()\n",
        "\n",
        "  clfXGB_CMF = xgb_r4.fit(x_Train_corr, y_Train)\n",
        "  y_pred_CMF = clfXGB_CMF.predict(x_Test_corr)\n",
        "  list_XG_Pre_CM.append(precision_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_XG_f1_CM.append(f1_score(y_Test, y_pred_CMF, average='weighted'))\n",
        "  list_XG_Acc_CM.append(accuracy_score(y_Test, y_pred_CMF))\n",
        "\n",
        "  xgb_r5 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  # clfXGB_CMFL = xgb_r5.fit(new_x_train_corr, y_Train)\n",
        "  # y_pred_CMFL = clfXGB_CMFL.predict(new_x_test_corr)\n",
        "  # list_XG_Pre_CMFL.append(precision_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_XG_f1_CMFL.append(f1_score(y_Test, y_pred_CMFL, average='weighted'))\n",
        "  # list_XG_Acc_CMFL.append(accuracy_score(y_Test, y_pred_CMFL))\n",
        "\n",
        "\n",
        "  xgb_r6 = xg.XGBClassifier(max_depth=20)\n",
        "\n",
        "  features_df_new_train = features_df_new_train.to_numpy()\n",
        "  features_df_new_test = features_df_new_test.to_numpy()\n",
        "  clfXGB_selectK = xgb_r6.fit(features_df_new_train, y_Train)\n",
        "  y_pred_selectK = clfXGB_selectK.predict(features_df_new_test)\n",
        "  list_XG_Pre_SK.append(precision_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_XG_f1_SK.append(f1_score(y_Test, y_pred_selectK, average='weighted'))\n",
        "  list_XG_Acc_SK.append(accuracy_score(y_Test, y_pred_selectK))\n",
        "\n",
        "  print(\"done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logistic Regression :\")\n",
        "print(\"----------------------\")\n",
        "print(\"Basic ==>                          Precision: \",round(Average(list_LR_Pre_Basic), 4),\"  F1: \",round(Average(list_LR_f1_Basic), 4),\" Accuracy: \",round(Average(list_LR_Acc_Basic), 4))\n",
        "print()\n",
        "print(\"PCA with n = 2 ==>                 Precision: \",round(Average(list_LR_Pre_PCA2), 4),\"  F1: \",round(Average(list_LR_f1_PCA2), 4),\" Accuracy: \",round(Average(list_LR_Acc_PCA2), 4))\n",
        "print()\n",
        "print(\"PCA with n = 10 ==>                Precision: \",round(Average(list_LR_Pre_PCA10), 4),\"  F1: \",round(Average(list_LR_f1_PCA10), 4),\" Accuracy: \",round(Average(list_LR_Acc_PCA10), 4))\n",
        "print()\n",
        "print(\"Correlation Matrix on Features ==> Precision: \",round(Average(list_LR_Pre_CM), 4),\"  F1: \",round(Average(list_LR_f1_CM), 4),\" Accuracy: \",round(Average(list_LR_Acc_CM), 4))\n",
        "print()\n",
        "print(\"SelectK best with k = 200 ==>      Precision: \",round(Average(list_LR_Pre_SK), 4),\"  F1: \",round(Average(list_LR_f1_SK), 4),\" Accuracy: \",round(Average(list_LR_Acc_SK), 4))\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"Radom Forest :\")\n",
        "print(\"----------------------\")\n",
        "print(\"Basic ==>                          Precision: \",round(Average(list_RF_Pre_Basic), 4),\"  F1: \",round(Average(list_RF_f1_Basic), 4),\" Accuracy: \",round(Average(list_RF_Acc_Basic), 4))\n",
        "print()\n",
        "print(\"PCA with n = 2 ==>                 Precision: \",round(Average(list_RF_Pre_PCA2), 4),\"  F1: \",round(Average(list_RF_f1_PCA2), 4),\" Accuracy: \",round(Average(list_RF_Acc_PCA2), 4))\n",
        "print()\n",
        "print(\"PCA with n = 10 ==>                Precision: \",round(Average(list_RF_Pre_PCA10), 4),\"  F1: \",round(Average(list_RF_f1_PCA10), 4),\" Accuracy: \",round(Average(list_RF_Acc_PCA10), 4))\n",
        "print()\n",
        "print(\"Correlation Matrix on Features ==> Precision: \",round(Average(list_RF_Pre_CM), 4),\"  F1: \",round(Average(list_RF_f1_CM), 4),\" Accuracy: \",round(Average(list_RF_Acc_CM), 4))\n",
        "print()\n",
        "print(\"SelectK best with k = 200 ==>      Precision: \",round(Average(list_RF_Pre_SK), 4),\"  F1: \",round(Average(list_RF_f1_SK), 4),\" Accuracy: \",round(Average(list_RF_Acc_SK), 4))\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"Adaboost :\")\n",
        "print(\"----------------------\")\n",
        "print(\"Basic ==>                          Precision: \",round(Average(list_AB_Pre_Basic), 4),\"  F1: \",round(Average(list_AB_f1_Basic), 4),\" Accuracy: \",round(Average(list_AB_Acc_Basic), 4))\n",
        "print()\n",
        "print(\"PCA with n = 2 ==>                 Precision: \",round(Average(list_AB_Pre_PCA2), 4),\"  F1: \",round(Average(list_AB_f1_PCA2), 4),\" Accuracy: \",round(Average(list_AB_Acc_PCA2), 4))\n",
        "print()\n",
        "print(\"PCA with n = 10 ==>                Precision: \",round(Average(list_AB_Pre_PCA10), 4),\"  F1: \",round(Average(list_AB_f1_PCA10), 4),\" Accuracy: \",round(Average(list_AB_Acc_PCA10), 4))\n",
        "print()\n",
        "print(\"Correlation Matrix on Features ==> Precision: \",round(Average(list_AB_Pre_CM), 4),\"  F1: \",round(Average(list_AB_f1_CM), 4),\" Accuracy: \",round(Average(list_AB_Acc_CM), 4))\n",
        "print()\n",
        "print(\"SelectK best with k = 200 ==>      Precision: \",round(Average(list_AB_Pre_SK), 4),\"  F1: \",round(Average(list_AB_f1_SK), 4),\" Accuracy: \",round(Average(list_AB_Acc_SK), 4))\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"XgBoost :\")\n",
        "print(\"----------------------\")\n",
        "print(\"Basic ==>                          Precision: \",round(Average(list_XG_Pre_Basic), 4),\"  F1: \",round(Average(list_XG_f1_Basic), 4),\" Accuracy: \",round(Average(list_XG_Acc_Basic), 4))\n",
        "print()\n",
        "print(\"PCA with n = 2 ==>                 Precision: \",round(Average(list_XG_Pre_PCA2), 4),\"  F1: \",round(Average(list_XG_f1_PCA2), 4),\" Accuracy: \",round(Average(list_XG_Acc_PCA2), 4))\n",
        "print()\n",
        "print(\"PCA with n = 10 ==>                Precision: \",round(Average(list_XG_Pre_PCA10), 4),\"  F1: \",round(Average(list_XG_f1_PCA10), 4),\" Accuracy: \",round(Average(list_XG_Acc_PCA10), 4))\n",
        "print()\n",
        "print(\"Correlation Matrix on Features ==> Precision: \",round(Average(list_XG_Pre_CM), 4),\"  F1: \",round(Average(list_XG_f1_CM), 4),\" Accuracy: \",round(Average(list_XG_Acc_CM), 4))\n",
        "print()\n",
        "print(\"SelectK best with k = 200 ==>      Precision: \",round(Average(list_XG_Pre_SK), 4),\"  F1: \",round(Average(list_XG_f1_SK), 4),\" Accuracy: \",round(Average(list_XG_Acc_SK), 4))\n",
        "print()\n",
        "print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKWRFiAORCGq",
        "outputId": "91be4ddb-35c8-4641-8d4d-79be17ca64b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression :\n",
            "----------------------\n",
            "Basic ==>                          Precision:  0.4859   F1:  0.472  Accuracy:  0.5265\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.3844   F1:  0.2939  Accuracy:  0.4314\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.4194   F1:  0.2879  Accuracy:  0.4194\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.4471   F1:  0.4034  Accuracy:  0.476\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.5928   F1:  0.585  Accuracy:  0.6174\n",
            "\n",
            "\n",
            "Radom Forest :\n",
            "----------------------\n",
            "Basic ==>                          Precision:  0.8238   F1:  0.8198  Accuracy:  0.8296\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.2324   F1:  0.1598  Accuracy:  0.2759\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.35   F1:  0.3044  Accuracy:  0.3987\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8255   F1:  0.8211  Accuracy:  0.8322\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.8241   F1:  0.8208  Accuracy:  0.8296\n",
            "\n",
            "\n",
            "Adaboost :\n",
            "----------------------\n",
            "Basic ==>                          Precision:  0.4535   F1:  0.4398  Accuracy:  0.4698\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.2249   F1:  0.1311  Accuracy:  0.1957\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.2063   F1:  0.1065  Accuracy:  0.1604\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.4653   F1:  0.4782  Accuracy:  0.51\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.4583   F1:  0.4699  Accuracy:  0.5058\n",
            "\n",
            "\n",
            "XgBoost :\n",
            "----------------------\n",
            "Basic ==>                          Precision:  0.831   F1:  0.8321  Accuracy:  0.8421\n",
            "\n",
            "PCA with n = 2 ==>                 Precision:  0.2102   F1:  0.1239  Accuracy:  0.2171\n",
            "\n",
            "PCA with n = 10 ==>                Precision:  0.3333   F1:  0.2368  Accuracy:  0.3585\n",
            "\n",
            "Correlation Matrix on Features ==> Precision:  0.8375   F1:  0.8357  Accuracy:  0.8449\n",
            "\n",
            "SelectK best with k = 200 ==>      Precision:  0.8306   F1:  0.8295  Accuracy:  0.8378\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Capstone_Models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}